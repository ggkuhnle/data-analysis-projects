{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frontmatter",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Logistic Regression and Survival Analysis\"\n",
    "output-file: \"04_logistic_and_survival.html\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìä 4.6 Logistic Regression and Survival Analysis\n",
    "\n",
    "This notebook introduces logistic regression and survival analysis for nutrition research, focusing on binary outcomes and time-to-event data.\n",
    "\n",
    "**Objectives**:\n",
    "- Apply logistic regression to predict binary outcomes.\n",
    "- Perform survival analysis to model time-to-event data.\n",
    "- Use `vitamin_trial.csv` to analyse vitamin D trial outcomes.\n",
    "\n",
    "**Context**: Logistic regression predicts outcomes like improved health, while survival analysis models time to events, such as response to treatment, in nutrition studies.\n",
    "\n",
    "<details><summary>Fun Fact</summary>\n",
    "Hippos may not run clinical trials, but their vitamin D data helps us model health outcomes with statistical flair! ü¶õ\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab: Fetch datasets automatically or manually\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Define the module and dataset for this notebook\n",
    "MODULE = '04_data_analysis'  # The module directory in notebooks/\n",
    "DATASET = 'vitamin_trial.csv'  # The dataset file to load\n",
    "BASE_PATH = '/content/data-analysis-toolkit-FNS'  # Base path for the cloned repository\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)  # Path to the module directory\n",
    "DATASET_PATH = os.path.join('data', DATASET)  # Path to the dataset within the module\n",
    "\n",
    "# Step 1: Attempt to clone the repository (automatic method)\n",
    "# Note: If you encounter a cloning error (e.g., 'fatal: destination path already exists'),\n",
    "#       reset the runtime (Runtime > Restart runtime) and run this cell again.\n",
    "try:\n",
    "    print('Attempting to clone repository...')\n",
    "    if os.path.exists(BASE_PATH):\n",
    "        print('Repository already exists, skipping clone.')\n",
    "    else:\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-toolkit-FNS.git\n",
    "    \n",
    "    # Debug: Print directory structure to help with troubleshooting\n",
    "    print('Listing repository contents:')\n",
    "    !ls {BASE_PATH}\n",
    "    print(f'Listing notebooks directory contents:')\n",
    "    !ls {BASE_PATH}/notebooks\n",
    "    \n",
    "    # Check if the module directory exists\n",
    "    if not os.path.exists(MODULE_PATH):\n",
    "        raise FileNotFoundError(f'Module directory {MODULE_PATH} not found. Check the repository structure.')\n",
    "    \n",
    "    # Set working directory to the notebook's folder\n",
    "    os.chdir(MODULE_PATH)\n",
    "    \n",
    "    # Verify dataset is accessible\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        print(f'Dataset found: {DATASET_PATH} ü¶õ')\n",
    "    else:\n",
    "        print(f'Error: Dataset {DATASET} not found after cloning.')\n",
    "        raise FileNotFoundError\n",
    "except Exception as e:\n",
    "    print(f'Cloning failed: {e}')\n",
    "    print('Falling back to manual upload option...')\n",
    "\n",
    "    # Step 2: Manual upload option if cloning fails\n",
    "    print(f'Please upload {DATASET} manually.')\n",
    "    print(f'1. Click the \"Choose Files\" button below.')\n",
    "    print(f'2. Select {DATASET} from your local machine.')\n",
    "    print(f'3. Ensure the file is placed in notebooks/{MODULE}/data/')\n",
    "    \n",
    "    # Create the data directory if it doesn't exist\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Prompt user to upload the dataset\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Check if the dataset was uploaded\n",
    "    if DATASET in uploaded:\n",
    "        with open(DATASET_PATH, 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} to {DATASET_PATH} ü¶õ')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
    "\n",
    "# Install required packages for this notebook\n",
    "%pip install pandas numpy scikit-learn lifelines matplotlib\n",
    "print('Python environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## üì• Data Preparation\n",
    "\n",
    "We‚Äôll load `vitamin_trial.csv`, which contains data from a vitamin D trial. The dataset includes:\n",
    "- `ID`: Participant identifier.\n",
    "- `Group`: Control or Treatment.\n",
    "- `Vitamin_D`: Vitamin D level (ng/mL).\n",
    "- `Time`: Time to outcome (months).\n",
    "- `Outcome`: Normal or Improved.\n",
    "\n",
    "Let‚Äôs load and inspect the data to prepare for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data handling\n",
    "import pandas as pd  # For data manipulation and DataFrame operations\n",
    "import numpy as np   # For numerical operations\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/vitamin_trial.csv')  # Path relative to the current working directory (notebooks/04_data_analysis/)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f'Data shape: {df.shape}')  # Show the number of rows and columns\n",
    "print(f'Sample row: ID={df.iloc[0][\"ID\"]}, Group={df.iloc[0][\"Group\"]}, Vitamin_D={df.iloc[0][\"Vitamin_D\"]}, Time={df.iloc[0][\"Time\"]}, Outcome={df.iloc[0][\"Outcome\"]}')  # Show the first row for inspection\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logistic",
   "metadata": {},
   "source": [
    "## üìà Logistic Regression\n",
    "\n",
    "We‚Äôll use logistic regression to model the probability of the `Outcome` being \"Improved\" (binary outcome) based on predictors `Vitamin_D` and `Group`. Logistic regression is ideal for binary classification tasks, predicting the log-odds of the outcome.\n",
    "\n",
    "**Steps**:\n",
    "1. Encode categorical variables (`Group` and `Outcome`) as numerical values.\n",
    "2. Fit a logistic regression model.\n",
    "3. Interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logistic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression  # Scikit-learn's logistic regression model\n",
    "from sklearn.preprocessing import LabelEncoder      # For encoding categorical variables as numbers\n",
    "\n",
    "# Encode categorical variables\n",
    "# Convert 'Group' (Control/Treatment) to numerical values: Control=0, Treatment=1\n",
    "le_group = LabelEncoder()\n",
    "df['Group_Encoded'] = le_group.fit_transform(df['Group'])\n",
    "\n",
    "# Convert 'Outcome' (Normal/Improved) to numerical values: Normal=0, Improved=1\n",
    "le_outcome = LabelEncoder()\n",
    "df['Outcome_Encoded'] = le_outcome.fit_transform(df['Outcome'])\n",
    "\n",
    "# Prepare features (X) and target (y) for the model\n",
    "X = df[['Vitamin_D', 'Group_Encoded']]  # Features: Vitamin D level and Group\n",
    "y = df['Outcome_Encoded']               # Target: Outcome (0 or 1)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression(random_state=42)  # random_state ensures reproducibility\n",
    "model.fit(X, y)                              # Train the model on the data\n",
    "\n",
    "# Print the coefficients\n",
    "# Positive coefficients indicate an increase in the predictor increases the log-odds of 'Improved'\n",
    "print('Logistic Regression Coefficients:')\n",
    "print(f'- Vitamin_D: {model.coef_[0][0]:.3f}')  # Coefficient for Vitamin_D\n",
    "print(f'- Group (Treatment): {model.coef_[0][1]:.3f}')  # Coefficient for Group (Treatment vs Control)\n",
    "\n",
    "# Interpretation\n",
    "print('\\nInterpretation:')\n",
    "print(f'- A 1-unit increase in Vitamin_D changes the log-odds of \"Improved\" by {model.coef_[0][0]:.3f}.')\n",
    "print(f'- Being in the Treatment group (vs Control) changes the log-odds of \"Improved\" by {model.coef_[0][1]:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "survival",
   "metadata": {},
   "source": [
    "## ‚è≥ Survival Analysis\n",
    "\n",
    "Survival analysis models the time to an event. Here, we‚Äôll estimate Kaplan-Meier survival curves to model the time to `Outcome` = \"Improved\", stratified by `Group`. The Kaplan-Meier method is a non-parametric approach to estimate survival probabilities over time.\n",
    "\n",
    "**Steps**:\n",
    "1. Create an event indicator (1 if Outcome = Improved, 0 otherwise).\n",
    "2. Fit Kaplan-Meier curves for each group.\n",
    "3. Plot the survival curves to compare groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for survival analysis and plotting\n",
    "from lifelines import KaplanMeierFitter  # For Kaplan-Meier survival analysis\n",
    "import matplotlib.pyplot as plt         # For plotting survival curves\n",
    "\n",
    "# Create an event indicator\n",
    "# Event = 1 if Outcome is 'Improved', 0 if 'Normal'\n",
    "df['Event'] = df['Outcome'].apply(lambda x: 1 if x == 'Improved' else 0)\n",
    "\n",
    "# Initialize the Kaplan-Meier fitter\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Fit and plot survival curves for each group\n",
    "for group in ['Control', 'Treatment']:\n",
    "    # Create a mask to filter data for the current group\n",
    "    mask = df['Group'] == group\n",
    "    # Fit the Kaplan-Meier model to the group's data\n",
    "    kmf.fit(df[mask]['Time'], df[mask]['Event'], label=group)\n",
    "    # Plot the survival curve\n",
    "    kmf.plot_survival_function()\n",
    "\n",
    "# Add plot labels and title\n",
    "plt.title('Kaplan-Meier Survival Curves by Group')\n",
    "plt.xlabel('Time (Months)')\n",
    "plt.ylabel('Survival Probability (Not Improved)')\n",
    "plt.grid(True)  # Add a grid for readability\n",
    "plt.show()      # Display the survival curves\n",
    "\n",
    "# Note: In this context, 'survival' means the probability of not having the event (Outcome = Improved).\n",
    "# A lower curve indicates a higher probability of 'Improved' occurring earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise",
   "metadata": {},
   "source": [
    "## üß™ Exercises: Extend the Analysis\n",
    "\n",
    "Let‚Äôs deepen your understanding with two tasks:\n",
    "\n",
    "1. **Extend Logistic Regression**: Add `Time` as a predictor in the logistic regression model and report the new coefficients.\n",
    "2. **Survival Analysis**: Compute the median survival time (time to 50% probability of not having the event) for each group.\n",
    "\n",
    "**Guidance**:\n",
    "- For the logistic regression, include `Time` in the feature matrix `X` and re-fit the model.\n",
    "- For survival analysis, use `kmf.median_survival_time_` after fitting the Kaplan-Meier model to get the median survival time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "your_answer",
   "metadata": {},
   "source": [
    "**Your Answers**:\n",
    "\n",
    "**Exercise 1: Extend Logistic Regression**  \n",
    "Add `Time` as a predictor and report the coefficients.\n",
    "\n",
    "```python\n",
    "# Extend the feature matrix to include Time\n",
    "X_extended = df[['Vitamin_D', 'Group_Encoded', 'Time']]\n",
    "y_extended = df['Outcome_Encoded']\n",
    "\n",
    "# Fit the extended logistic regression model\n",
    "model_extended = LogisticRegression(random_state=42)\n",
    "model_extended.fit(X_extended, y_extended)\n",
    "\n",
    "# Print the coefficients\n",
    "print('Extended Logistic Regression Coefficients:')\n",
    "print(f'- Vitamin_D: {model_extended.coef_[0][0]:.3f}')\n",
    "print(f'- Group (Treatment): {model_extended.coef_[0][1]:.3f}')\n",
    "print(f'- Time: {model_extended.coef_[0][2]:.3f}')\n",
    "```\n",
    "\n",
    "**Coefficients**:\n",
    "- Vitamin_D: [Your Result]\n",
    "- Group (Treatment): [Your Result]\n",
    "- Time: [Your Result]\n",
    "\n",
    "**Exercise 2: Median Survival Times**  \n",
    "Compute the median survival time for each group.\n",
    "\n",
    "```python\n",
    "# Compute median survival times\n",
    "kmf = KaplanMeierFitter()\n",
    "for group in ['Control', 'Treatment']:\n",
    "    mask = df['Group'] == group\n",
    "    kmf.fit(df[mask]['Time'], df[mask]['Event'], label=group)\n",
    "    median_time = kmf.median_survival_time_\n",
    "    print(f'Median survival time for {group}: {median_time:.1f} months')\n",
    "```\n",
    "\n",
    "**Median Survival Times**:\n",
    "- Control: [Your Result] months\n",
    "- Treatment: [Your Result] months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You‚Äôve applied logistic regression and survival analysis to model vitamin D trial outcomes, uncovering predictors of improvement and time-to-event patterns. These techniques are powerful for understanding health outcomes in nutrition research.\n",
    "\n",
    "**Next Steps**: Explore clinical trial analysis in `4.7_clinical_trial_analysis.ipynb` or dive into advanced topics in `notebooks/05_advanced/`.\n",
    "\n",
    "**Resources**:\n",
    "- [Scikit-Learn Documentation](https://scikit-learn.org/)\n",
    "- [Lifelines Documentation](https://lifelines.readthedocs.io/)\n",
    "- Repository: [github.com/ggkuhnle/data-analysis-toolkit-FNS](https://github.com/ggkuhnle/data-analysis-toolkit-FNS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}