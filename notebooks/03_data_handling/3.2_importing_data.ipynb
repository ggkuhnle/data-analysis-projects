{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸ“Š 3.2 Importing Data\n",
    "\n",
    "Before you can analyse data, you first need to **import** it into Python. This notebook introduces the most common ways of bringing nutrition data into your workflow.\n",
    "\n",
    "Think of it like shopping for ingredients ðŸ›’: you canâ€™t cook (analyse) until youâ€™ve brought the food (data) into your kitchen (Python).\n",
    "\n",
    "***\n",
    "## ðŸŽ¯ Objectives\n",
    "By the end of this notebook you should be able to:\n",
    "- Import data from **CSV** and **Excel** files using pandas.\n",
    "- Recognise other common formats: TSV, JSON, databases, APIs.\n",
    "- Verify the data after import (shapes, column names, head of table).\n",
    "- Apply these skills to `hippo_nutrients.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa884b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for Google Colab: Fetch datasets automatically or manually\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "MODULE = '03_data_handling'\n",
    "DATASET = 'hippo_nutrients.csv'\n",
    "BASE_PATH = '/content/data-analysis-projects'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join('data', DATASET)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
    "    os.chdir(MODULE_PATH)\n",
    "    assert os.path.exists(DATASET_PATH)\n",
    "    print(f'Dataset found: {DATASET_PATH} âœ…')\n",
    "except Exception as e:\n",
    "    print(f'Automatic clone failed: {e}')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    uploaded = files.upload()\n",
    "    if DATASET in uploaded:\n",
    "        with open(DATASET_PATH, 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} âœ…')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
    "\n",
    "\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eedbf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Install additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8dda61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install pandas openpyxl sqlalchemy -q\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "csv_intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ“‚ Importing CSV Files\n",
    "\n",
    "CSV (Comma Separated Values) is the most common format in nutrition research. It is plain text, easy to share, and can be opened in Excel or any text editor.\n",
    "\n",
    "Letâ€™s load `hippo_nutrients.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "csv_load",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('data/hippo_nutrients.csv')\n",
    "print(f'Shape: {df_csv.shape}')\n",
    "print(f'Columns: {df_csv.columns.tolist()}')\n",
    "display(df_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excel_intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ“‘ Importing Excel Files\n",
    "\n",
    "Excel is common in labs and public health datasets. You may encounter files with **multiple sheets**, formatting quirks, or missing values.\n",
    "\n",
    "Example (requires `openpyxl`):\n",
    "\n",
    "```python\n",
    "# %pip install openpyxl  # uncomment if needed in Colab\n",
    "# df_excel = pd.read_excel('data/hippo_nutrients.xlsx', sheet_name='Sheet1')\n",
    "```\n",
    "\n",
    "For this demo weâ€™ll reuse the CSV DataFrame but pretend it came from Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excel_load",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_excel = df_csv.copy()\n",
    "print(f'Excel shape: {df_excel.shape}')\n",
    "display(df_excel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other_formats",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ”— Other Common Data Sources\n",
    "\n",
    "### TSV (Tab-Separated Values)\n",
    "```python\n",
    "df_tsv = pd.read_csv('data/example.tsv', sep='\\t')\n",
    "```\n",
    "\n",
    "### JSON (e.g. from APIs)\n",
    "```python\n",
    "df_json = pd.read_json('data/example.json')\n",
    "```\n",
    "\n",
    "### SQL Databases (clinical or survey data)\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///data/nutrition.db')\n",
    "df_sql = pd.read_sql('SELECT * FROM hippo_nutrients', engine)\n",
    "```\n",
    "\n",
    "### Web APIs (advanced)\n",
    "Many nutrition datasets are accessible via APIs. Example:\n",
    "```python\n",
    "import requests\n",
    "url = 'https://api.example.com/nutrients'\n",
    "data = requests.get(url).json()\n",
    "df_api = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "ðŸ‘‰ You donâ€™t need to master all these at once, but itâ€™s important to know they exist!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 1: CSV Practice\n",
    "1. Load `hippo_nutrients.csv` into a DataFrame.\n",
    "2. Print the first 5 rows.\n",
    "3. How many unique nutrients are in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 2: Explore Other Formats\n",
    "Imagine you receive data from collaborators:\n",
    "- NDNS data in a TSV file.\n",
    "- A JSON file with nutrient metadata.\n",
    "\n",
    "How would you adapt the code above to import these files?\n",
    "\n",
    "ðŸ’¡ *You donâ€™t need the real files nowâ€”just sketch out the pandas command youâ€™d use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## âœ… Conclusion\n",
    "In this notebook you:\n",
    "- Imported CSV and Excel data.\n",
    "- Learned about other formats (TSV, JSON, SQL, APIs).\n",
    "- Practised verifying shapes, columns, and contents after import.\n",
    "\n",
    "ðŸ‘‰ Next up: **3.3 Data Cleaning** â€” because imported data is rarely perfect, and cleaning is where the real fun begins!\n",
    "\n",
    "***\n",
    "**Resources**:\n",
    "- [Pandas I/O Documentation](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "- [OpenPyXL Documentation](https://openpyxl.readthedocs.io/)\n",
    "- [SQLAlchemy](https://docs.sqlalchemy.org/)\n",
    "- [Requests (Python HTTP for APIs)](https://docs.python-requests.org/)\n",
    "- Repository: [github.com/ggkuhnle/data-analysis-projects](https://github.com/ggkuhnle/data-analysis-projects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}