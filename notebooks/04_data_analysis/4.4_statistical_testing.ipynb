{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# üß™ 4.4 Statistical Testing ‚Äî From Questions to Evidence\n",
        "\n",
        "In this notebook you‚Äôll practice **hypothesis testing** on `vitamin_trial.csv`. We‚Äôll start with assumption checks, then run parametric and non-parametric tests, include **effect sizes with confidence intervals**, and handle **multiple comparisons**.\n",
        "\n",
        "---\n",
        "## üéØ Objectives\n",
        "- Choose the right test for a research question (one-sample, two-sample, paired, one-way ANOVA).\n",
        "- Check assumptions (approx. normality, variance homogeneity) and use non-parametric alternatives when needed.\n",
        "- Report **p-values** *and* **effect sizes** (Cohen‚Äôs *d*, Hedges‚Äô *g*) with **95% CI**.\n",
        "- Handle **multiple comparisons** (Holm or FDR/Benjamini‚ÄìHochberg).\n",
        "\n",
        "<details><summary>Quick refresher (click)</summary>\n",
        "<ul>\n",
        "<li><b>One-sample</b>: compare a mean to a reference value.</li>\n",
        "<li><b>Two-sample (independent)</b>: compare means of two groups (Welch default for unequal variances).</li>\n",
        "<li><b>Paired</b>: compare means of before/after within the same ID.</li>\n",
        "<li><b>One-way ANOVA</b>: compare means across ‚â•3 groups (plus post-hoc with multiplicity control).</li>\n",
        "<li><b>Non-parametric</b>: Wilcoxon signed-rank (paired), Mann‚ÄìWhitney U (independent), Kruskal‚ÄìWallis (‚â•3 groups).</li>\n",
        "</ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Google Colab: fetch dataset automatically or allow manual upload\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "MODULE = '04_data_analysis'\n",
        "DATASET = 'vitamin_trial.csv'\n",
        "BASE_PATH = '/content/data-analysis-projects'\n",
        "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
        "DATASET_PATH = os.path.join('data', DATASET)\n",
        "\n",
        "try:\n",
        "    print('Attempting to clone repository...')\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
        "    print('Setting working directory...')\n",
        "    os.chdir(MODULE_PATH)\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f'Dataset found: {DATASET_PATH} ‚úÖ')\n",
        "    else:\n",
        "        raise FileNotFoundError('Dataset missing after clone.')\n",
        "except Exception as e:\n",
        "    print(f'Cloning failed: {e}')\n",
        "    print('Falling back to manual upload...')\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "    if DATASET in uploaded:\n",
        "        with open(DATASET_PATH, 'wb') as f:\n",
        "            f.write(uploaded[DATASET])\n",
        "        print(f'Successfully uploaded {DATASET} ‚úÖ')\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Upload failed. Please upload {DATASET}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "libs",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pandas numpy scipy statsmodels seaborn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "sns.set_theme()\n",
        "print('Statistical testing environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_inspect",
      "metadata": {},
      "source": [
        "## 1) Load & Inspect\n",
        "We load the dataset and check what we have. Typical columns: `ID`, `Group` (Control/Treatment), `Vitamin_D` (numeric), `Time` (e.g., 0/1), and possibly `Outcome`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_df",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/vitamin_trial.csv')\n",
        "print('Shape:', df.shape)\n",
        "display(df.head())\n",
        "display(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "assumptions",
      "metadata": {},
      "source": [
        "## 2) Assumption Checks (lightweight)\n",
        "Parametric tests (t-tests/ANOVA) typically assume roughly normal residuals and equal variances (for some tests). We inspect normality with Shapiro‚ÄìWilk and equality of variances with Levene.\n",
        "\n",
        "<details><summary>Good practice</summary>\n",
        "<ul>\n",
        "<li>Use **visuals** (see 4.1/4.2) first; formal tests can be overly sensitive with large *n*.</li>\n",
        "<li>If assumptions look shaky, lean on **Welch t-test** (default below) or **non-parametrics**.</li>\n",
        "</ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "assumption_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: normality of Vitamin_D by Group (if present)\n",
        "if {'Vitamin_D','Group'}.issubset(df.columns):\n",
        "    for g, sub in df.groupby('Group', observed=True):\n",
        "        y = pd.to_numeric(sub['Vitamin_D'], errors='coerce').dropna()\n",
        "        if len(y) >= 3:\n",
        "            stat, p = stats.shapiro(y)\n",
        "            print(f'Shapiro‚ÄìWilk Vitamin_D in Group={g}: W={stat:.3f}, p={p:.3g}, n={len(y)}')\n",
        "else:\n",
        "    print('Columns Vitamin_D and/or Group not available for normality demo.')\n",
        "\n",
        "# Example: equality of variances across groups with Levene (median-centered, robust-ish)\n",
        "if {'Vitamin_D','Group'}.issubset(df.columns):\n",
        "    groups = [pd.to_numeric(sub['Vitamin_D'], errors='coerce').dropna() for _, sub in df.groupby('Group', observed=True)]\n",
        "    if len(groups) >= 2 and all(len(g) >= 2 for g in groups):\n",
        "        stat, p = stats.levene(*groups, center='median')\n",
        "        print(f'Levene (Vitamin_D ~ Group): W={stat:.3f}, p={p:.3g}')\n",
        "else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "helpers",
      "metadata": {},
      "source": [
        "## 3) Helper functions ‚Äî effect sizes & CIs\n",
        "We‚Äôll compute **Cohen‚Äôs d** / **Hedges‚Äô g**, plus 95% CIs for mean differences using Welch‚Äôs t framework. For paired designs, we compute effect sizes on the **difference scores**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "helpers_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cohens_d_independent(x, y):\n",
        "    \"\"\"Cohen's d for independent samples (pooled SD).\"\"\"\n",
        "    x = pd.Series(x).dropna().astype(float)\n",
        "    y = pd.Series(y).dropna().astype(float)\n",
        "    nx, ny = len(x), len(y)\n",
        "    if nx < 2 or ny < 2:\n",
        "        return np.nan\n",
        "    sx2, sy2 = x.var(ddof=1), y.var(ddof=1)\n",
        "    sp = np.sqrt(((nx-1)*sx2 + (ny-1)*sy2) / (nx+ny-2))\n",
        "    if sp == 0:\n",
        "        return np.nan\n",
        "    d = (x.mean() - y.mean()) / sp\n",
        "    return d\n",
        "\n",
        "def hedges_g(d, nx, ny):\n",
        "    \"\"\"Small-sample corrected Cohen's d (Hedges' g).\"\"\"\n",
        "    # J correction\n",
        "    df = nx + ny - 2\n",
        "    if df <= 0 or np.isnan(d):\n",
        "        return np.nan\n",
        "    J = 1 - (3 / (4*df - 1))\n",
        "    return d * J\n",
        "\n",
        "def mean_diff_ci_welch(x, y, alpha=0.05):\n",
        "    \"\"\"95% CI for mean difference (x - y) using Welch's t.\"\"\"\n",
        "    x = pd.Series(x).dropna().astype(float)\n",
        "    y = pd.Series(y).dropna().astype(float)\n",
        "    nx, ny = len(x), len(y)\n",
        "    mx, my = x.mean(), y.mean()\n",
        "    vx, vy = x.var(ddof=1), y.var(ddof=1)\n",
        "    if nx == 0 or ny == 0:\n",
        "        return (np.nan, np.nan, np.nan)\n",
        "    se = np.sqrt(vx/nx + vy/ny)\n",
        "    # Welch‚ÄìSatterthwaite df\n",
        "    df_w = (vx/nx + vy/ny)**2 / ((vx**2)/((nx**2)*(nx-1)) + (vy**2)/((ny**2)*(ny-1))) if nx>1 and ny>1 else np.nan\n",
        "    if se == 0 or not np.isfinite(df_w):\n",
        "        return (mx-my, np.nan, np.nan)\n",
        "    tcrit = stats.t.ppf(1 - alpha/2, df=df_w)\n",
        "    lo, hi = (mx-my) - tcrit*se, (mx-my) + tcrit*se\n",
        "    return (mx-my, lo, hi)\n",
        "\n",
        "def cohens_d_paired(x_pre, x_post):\n",
        "    \"\"\"Cohen's d for paired samples: mean(diff) / sd(diff).\"\"\"\n",
        "    pre = pd.Series(x_pre).astype(float)\n",
        "    post = pd.Series(x_post).astype(float)\n",
        "    # align by index (IDs)\n",
        "    m = pre.notna() & post.notna()\n",
        "    d = post[m] - pre[m]\n",
        "    if len(d) < 2:\n",
        "        return np.nan\n",
        "    return d.mean() / d.std(ddof=1) if d.std(ddof=1) != 0 else np.nan\n",
        "\n",
        "def mean_diff_ci_paired(x_pre, x_post, alpha=0.05):\n",
        "    pre = pd.Series(x_pre).astype(float)\n",
        "    post = pd.Series(x_post).astype(float)\n",
        "    m = pre.notna() & post.notna()\n",
        "    d = post[m] - pre[m]\n",
        "    if len(d) < 2:\n",
        "        return (np.nan, np.nan, np.nan)\n",
        "    md = d.mean()\n",
        "    se = d.std(ddof=1) / np.sqrt(len(d))\n",
        "    tcrit = stats.t.ppf(1 - alpha/2, df=len(d)-1)\n",
        "    return (md, md - tcrit*se, md + tcrit*se)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "one_sample",
      "metadata": {},
      "source": [
        "## 4) One-sample tests\n",
        "**Question**: Is mean Vitamin D (overall) different from a reference value (e.g., 12.5 ¬µg)?\n",
        "\n",
        "<details><summary>Notes</summary>\n",
        "- Parametric: one-sample t-test on the mean.\n",
        "- Non-parametric: sign test or Wilcoxon signed-rank against a hypothesised median (scipy‚Äôs `wilcoxon` needs pairs, so we‚Äôll stick to t here for brevity).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "one_sample_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'Vitamin_D' in df.columns:\n",
        "    y = pd.to_numeric(df['Vitamin_D'], errors='coerce').dropna()\n",
        "    mu0 = 12.5  # reference mean (change to your scientific target)\n",
        "    tstat, pval = stats.ttest_1samp(y, popmean=mu0)\n",
        "    print(f'One-sample t-test: H0: mean={mu0}')\n",
        "    print(f'  t={tstat:.3f}, p={pval:.3g}, n={len(y)}; mean={y.mean():.3f}')\n",
        "else:\n",
        "    print('Vitamin_D not found for one-sample test.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "two_sample",
      "metadata": {},
      "source": [
        "## 5) Two-sample (independent) tests\n",
        "**Question**: Do Control vs Treatment differ in mean Vitamin D?\n",
        "\n",
        "- Parametric: **Welch‚Äôs t-test** (robust to unequal variances; default here).\n",
        "- Non-parametric: **Mann‚ÄìWhitney U**.\n",
        "- Report **effect sizes** + **95% CI** for mean difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "two_sample_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "if {'Vitamin_D','Group'}.issubset(df.columns):\n",
        "    g_levels = df['Group'].dropna().unique().tolist()\n",
        "    if len(g_levels) == 2:\n",
        "        g1, g2 = sorted(g_levels)\n",
        "        x = pd.to_numeric(df.loc[df['Group']==g1, 'Vitamin_D'], errors='coerce').dropna()\n",
        "        y = pd.to_numeric(df.loc[df['Group']==g2, 'Vitamin_D'], errors='coerce').dropna()\n",
        "        # Welch t-test\n",
        "        t, p = stats.ttest_ind(x, y, equal_var=False)\n",
        "        d = cohens_d_independent(x, y)\n",
        "        g = hedges_g(d, len(x), len(y))\n",
        "        md, lo, hi = mean_diff_ci_welch(x, y)\n",
        "        print(f'Welch t-test ({g1} vs {g2}): t={t:.3f}, p={p:.3g}')\n",
        "        print(f'  mean_diff={md:.3f} [{lo:.3f}, {hi:.3f}] (x‚àíy)')\n",
        "        print(f'  Cohen d={d:.3f}, Hedges g={g:.3f}')\n",
        "        # Mann‚ÄìWhitney U\n",
        "        u, p_u = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
        "        print(f'Mann‚ÄìWhitney U: U={u:.1f}, p={p_u:.3g}')\n",
        "    else:\n",
        "        print('Two-sample demo expects exactly 2 groups in Group.')\n",
        "else:\n",
        "    print('Need Vitamin_D and Group columns for two-sample tests.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "paired",
      "metadata": {},
      "source": [
        "## 6) Paired tests (within-ID before/after)\n",
        "If your dataset has repeated measurements per `ID` (e.g., `Time=0` and `Time=1`), use paired tests:\n",
        "- Parametric: **paired t-test** on the difference.\n",
        "- Non-parametric: **Wilcoxon signed-rank** on the difference.\n",
        "\n",
        "We‚Äôll try to form pairs from `Time==0` vs `Time==1` within each `ID` for `Vitamin_D`. If not available, we skip gracefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "paired_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "if {'ID','Time','Vitamin_D'}.issubset(df.columns):\n",
        "    # Wide-style pairing: each row is an ID√óTime; pivot to columns Time0, Time1\n",
        "    tmp = df[['ID','Time','Vitamin_D']].dropna()\n",
        "    # Only keep IDs that have BOTH time points 0 and 1\n",
        "    have_both = tmp.groupby('ID')['Time'].nunique() >= 2\n",
        "    ids = have_both[have_both].index\n",
        "    sub = tmp[tmp['ID'].isin(ids)].copy()\n",
        "    wide = sub.pivot_table(index='ID', columns='Time', values='Vitamin_D', aggfunc='mean')\n",
        "    if 0 in wide.columns and 1 in wide.columns:\n",
        "        pre = wide[0]; post = wide[1]\n",
        "        # Paired t-test\n",
        "        m = pre.notna() & post.notna()\n",
        "        if m.sum() >= 2:\n",
        "            t, p = stats.ttest_rel(pre[m], post[m])\n",
        "            d_pair = cohens_d_paired(pre[m], post[m])\n",
        "            md, lo, hi = mean_diff_ci_paired(pre[m], post[m])\n",
        "            print(f'Paired t-test (Time 0 vs 1): t={t:.3f}, p={p:.3g}, n={m.sum()}')\n",
        "            print(f'  mean_diff={md:.3f} [{lo:.3f}, {hi:.3f}] (post‚àípre)')\n",
        "            print(f'  Cohen d (paired)={d_pair:.3f}')\n",
        "            # Wilcoxon signed-rank\n",
        "            w, p_w = stats.wilcoxon(post[m] - pre[m])\n",
        "            print(f'Wilcoxon signed-rank: W={w:.1f}, p={p_w:.3g}')\n",
        "        else:\n",
        "            print('Not enough paired (non-missing) observations for paired tests.')\n",
        "    else:\n",
        "        print('Could not find both Time=0 and Time=1 columns after pivot.')\n",
        "else:\n",
        "    print('Need ID, Time, Vitamin_D for paired tests.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anova",
      "metadata": {},
      "source": [
        "## 7) ‚â•3 groups ‚Äî ANOVA and Kruskal‚ÄìWallis\n",
        "Compare means across three or more groups:\n",
        "- Parametric: **one-way ANOVA** (we‚Äôll use OLS via statsmodels and Type II ANOVA table).\n",
        "- Non-parametric: **Kruskal‚ÄìWallis** (rank-based). For post-hoc, we‚Äôll do pairwise tests with multiplicity control.\n",
        "\n",
        "<details><summary>Post-hoc choices</summary>\n",
        "- Parametric: **Tukey HSD** is classic (assumes equal variances / balanced design). If design is unbalanced/heteroscedastic, many prefer pairwise Welch t with Holm correction.\n",
        "- Non-parametric: pairwise **Mann‚ÄìWhitney U** with Holm correction is a pragmatic alternative (Dunn‚Äôs test is another option but needs extra packages).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "anova_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "if {'Vitamin_D','Group'}.issubset(df.columns):\n",
        "    # Require ‚â• 3 groups with some data\n",
        "    counts = df.groupby('Group', observed=True)['Vitamin_D'].apply(lambda s: pd.to_numeric(s, errors='coerce').notna().sum())\n",
        "    valid_groups = counts[counts >= 2].index.tolist()\n",
        "    if len(valid_groups) >= 3:\n",
        "        dfa = df[df['Group'].isin(valid_groups)].copy()\n",
        "        dfa['Vitamin_D'] = pd.to_numeric(dfa['Vitamin_D'], errors='coerce')\n",
        "        dfa = dfa.dropna(subset=['Vitamin_D'])\n",
        "        # OLS + ANOVA table\n",
        "        model = smf.ols('Vitamin_D ~ C(Group)', data=dfa).fit()\n",
        "        aov = sm.stats.anova_lm(model, typ=2)\n",
        "        print('One-way ANOVA (Type II):')\n",
        "        display(aov)\n",
        "        # Tukey HSD (if desired)\n",
        "        try:\n",
        "            tuk = pairwise_tukeyhsd(endog=dfa['Vitamin_D'], groups=dfa['Group'], alpha=0.05)\n",
        "            print('\\nTukey HSD (parametric, equal-variance assumption):')\n",
        "            display(pd.DataFrame(data=tuk.summary(data=False)[1:], columns=tuk.summary().data[0]))\n",
        "        except Exception as e:\n",
        "            print('Tukey HSD not available:', e)\n",
        "        # Kruskal‚ÄìWallis\n",
        "        arrays = [pd.to_numeric(dfa.loc[dfa['Group']==g, 'Vitamin_D'], errors='coerce').dropna() for g in valid_groups]\n",
        "        H, pH = stats.kruskal(*arrays)\n",
        "        print(f'\\nKruskal‚ÄìWallis: H={H:.3f}, p={pH:.3g}')\n",
        "        # Pairwise Mann‚ÄìWhitney with Holm correction\n",
        "        pairs, pvals = [], []\n",
        "        for i in range(len(valid_groups)):\n",
        "            for j in range(i+1, len(valid_groups)):\n",
        "                g1, g2 = valid_groups[i], valid_groups[j]\n",
        "                x = pd.to_numeric(dfa.loc[dfa['Group']==g1, 'Vitamin_D'], errors='coerce').dropna()\n",
        "                y = pd.to_numeric(dfa.loc[dfa['Group']==g2, 'Vitamin_D'], errors='coerce').dropna()\n",
        "                if len(x) >= 2 and len(y) >= 2:\n",
        "                    u, p = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
        "                    pairs.append((g1, g2)); pvals.append(p)\n",
        "        if pvals:\n",
        "            rej, p_adj, _, _ = multipletests(pvals, alpha=0.05, method='holm')\n",
        "            out = pd.DataFrame({'pair': pairs, 'p_raw': pvals, 'p_holm': p_adj, 'reject_0.05': rej})\n",
        "            print('\\nPairwise Mann‚ÄìWhitney U with Holm correction:')\n",
        "            display(out.sort_values('p_holm'))\n",
        "    else:\n",
        "        print('Need ‚â•3 groups with data for ANOVA/Kruskal‚ÄìWallis.')\n",
        "else:\n",
        "    print('Need Vitamin_D and Group for ANOVA/Kruskal‚ÄìWallis.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reporting",
      "metadata": {},
      "source": [
        "## 8) Reporting results\n",
        "When reporting, include:\n",
        "- The test used (and why),\n",
        "- The estimate (mean difference or effect size) with **95% CI**,\n",
        "- The test statistic and **p-value**,\n",
        "- Any assumption checks or transformations,\n",
        "- How multiple testing was handled (if applicable).\n",
        "\n",
        "<details><summary>Template sentences</summary>\n",
        "<ul>\n",
        "<li>‚ÄúMean Vitamin D differed between Treatment and Control (Welch‚Äôs t(‚âàdf)=t, p=p). The mean difference was md [lo, hi] ¬µg; Cohen‚Äôs d = d (Hedges‚Äô g = g).‚Äù</li>\n",
        "        <li>‚ÄúAcross the three groups, ANOVA indicated a difference in means (F(df1, df2)=F, p=p). Tukey HSD post-hoc found X>Y (p_adj=‚Ä¶).‚Äù</li>\n",
        "        <li>‚ÄúAssumptions appeared [reasonable/not met]; therefore we used [Welch/non-parametric] tests.‚Äù</li>\n",
        "</ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## üß™ Exercises\n",
        "1) **Set a one-sample target**  \n",
        "   - Choose a clinically meaningful Vitamin_D target (e.g., 12.5 ¬µg).  \n",
        "   - Test whether the overall mean differs; report the mean ¬± 95% CI.\n",
        "\n",
        "2) **Two-sample with assumptions**  \n",
        "   - Compare groups (Control vs Treatment).  \n",
        "   - Show Welch t-test and Mann‚ÄìWhitney; report d, g, mean difference CI.  \n",
        "   - State which you‚Äôd trust if variances differ or distributions are skewed.\n",
        "\n",
        "3) **Paired change**  \n",
        "   - If Time=0/1 exist per ID, test within-ID change (paired t and Wilcoxon).  \n",
        "   - Report mean change ¬± 95% CI and Cohen‚Äôs d (paired).\n",
        "\n",
        "4) **‚â•3 groups**  \n",
        "   - Run one-way ANOVA and Kruskal‚ÄìWallis across Group levels.  \n",
        "   - Perform post-hoc comparisons with multiplicity control (Tukey or Holm-adjusted pairwise tests).  \n",
        "   - Which groups differ meaningfully? Back up with CIs.\n",
        "\n",
        "5) **Multiplicity**  \n",
        "   - If you compare several endpoints (or many pairs), apply Holm or FDR to control false positives.  \n",
        "   - Explain your choice briefly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## ‚úÖ Conclusion\n",
        "You selected appropriate tests, verified assumptions, used non-parametric alternatives when needed, and reported both **p-values** and **effect sizes with CIs**. These practices make your findings more robust and interpretable.\n",
        "\n",
        "<details><summary>Further reading</summary>\n",
        "- SciPy Stats: <https://docs.scipy.org/doc/scipy/reference/stats.html>  \n",
        "- Statsmodels ANOVA & OLS: <https://www.statsmodels.org/>  \n",
        "- Multiple testing: <https://www.statsmodels.org/stable/generated/statsmodels.stats.multitest.multipletests.html>  \n",
        "- Effect sizes (overview): many concise guides are available; pick one you like and stick to a consistent reporting style.\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
