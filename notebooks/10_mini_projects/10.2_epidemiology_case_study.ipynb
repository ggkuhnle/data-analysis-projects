{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"10.2_epidemiology_case_study\"\n",
    "format:\n",
    "  html: default\n",
    "toc: false\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸ¥—ðŸ“Š Epidemiology in Nutrition: Cross-Sectional & Prospective Analyses\n",
    "\n",
    "**Design**: large observational cohort (nâ‰ˆ25,000; age 45â€“80) with baseline + 2/4/6-year follow-up.\n",
    "\n",
    "**Variables**: sex, smoking, physical activity, UK social class (A/B/C1/C2/D/E), BMI (baseline, 2y, 4y, 6y), BP, sugar intake, SFA intake, time-to-CVD and CVD incidence (event), random missingness.\n",
    "\n",
    "**Endpoints**\n",
    "- Cross-sectional: baseline BMI.\n",
    "- Survival: incident CVD.\n",
    "- Prospective: BMI trajectories and prospective CVD prediction.\n",
    "\n",
    "This notebook **loads a CSV if present** or **simulates** a realistic dataset (seed=11088). It then runs frequentist and Bayesian models with compact explanations suitable for reuse in student projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Environment\n",
    "Uncomment installs if running in a fresh environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install pandas numpy matplotlib seaborn scipy statsmodels lifelines pymc arviz\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "sns.set_context('notebook'); sns.set_style('whitegrid')\n",
    "RANDOM_SEED = 11088\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "DATA_DIR = Path('data'); DATA_DIR.mkdir(exist_ok=True)\n",
    "DATA_PATH = DATA_DIR / 'epidemiological_study.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simulate",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Simulate Data\n",
    "If `data/epidemiological_study.csv` is absent, we simulate a cohort with plausible associations:\n",
    "- Higher sugar â†’ BMI up over time; higher SFA â†’ higher CVD hazard; smoking/age â†’ higher CVD hazard; activity â†’ lower BMI/CVD.\n",
    "- Missingness: MCAR ~ 5â€“10% per variable.\n",
    "\n",
    "You can reduce `n` (e.g. 10_000) if RAM is tight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_or_sim",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_epidemiology(n=25_000, seed=RANDOM_SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    age = rng.normal(62, 8.5, n).clip(45, 85)\n",
    "    sex = rng.choice(['Female','Male'], n)\n",
    "    smoking = rng.choice(['Non-smoker','Smoker'], n, p=[0.7,0.3])\n",
    "    activity = rng.choice(['Low','Medium','High'], n, p=[0.3,0.45,0.25])\n",
    "    social = rng.choice(['A','B','C1','C2','D','E'], n, p=[0.08,0.15,0.22,0.22,0.2,0.13])\n",
    "    sugar = rng.normal(90, 35, n).clip(10, 250)  # g/day\n",
    "    sfa = rng.normal(28, 10, n).clip(5, 80)      # g/day\n",
    "\n",
    "    # Baseline BMI influenced by age/sex/activity/sugar\n",
    "    x_smoke = (smoking=='Smoker').astype(int)\n",
    "    x_male = (sex=='Male').astype(int)\n",
    "    x_act = pd.Series(activity).map({'Low':0,'Medium':1,'High':2}).values\n",
    "    baseline_bmi = (rng.normal(27, 3.5, n)\n",
    "                    + 0.08*(age-62) + 0.6*x_male - 0.5*x_act\n",
    "                    + 0.015*(sugar-90))\n",
    "    bp_base = rng.normal(132, 14, n) + 0.12*(age-62) + 3*x_smoke + 1.2*(baseline_bmi-27)\n",
    "\n",
    "    # Longitudinal BMI changes (drift up with sugar, down with activity)\n",
    "    def next_bmi(prev):\n",
    "        drift = 0.04*(sugar-90) - 0.25*x_act + rng.normal(0, 0.9, n)\n",
    "        return prev + drift\n",
    "    bmi_y2 = next_bmi(baseline_bmi)\n",
    "    bmi_y4 = next_bmi(bmi_y2)\n",
    "    bmi_y6 = next_bmi(bmi_y4)\n",
    "\n",
    "    # CVD time-to-event (months), Weibull AFT with covariates; censor at 72 months (6y)\n",
    "    # log(T) = mu + sigma * EVd; encode higher hazard for age/smoke/sfa, protective activity\n",
    "    # Implement via Weibull(scale=lambda, shape=alpha); larger lambda => longer survival\n",
    "    alpha = 1.4  # shape\n",
    "    lp = (3.9  # baseline log-scale\n",
    "          - 0.025*(age-62)\n",
    "          - 0.30*x_smoke\n",
    "          - 0.018*(sfa-28)\n",
    "          + 0.10*x_act\n",
    "          - 0.02*(baseline_bmi-27))\n",
    "    lam = np.exp(lp)  # scale\n",
    "    u = rng.uniform(0,1,n)\n",
    "    t_true = lam * (-np.log(u))**(1/alpha)   # Weibull inverse CDF (months)\n",
    "    censor_time = np.full(n, 72.0)\n",
    "    time_to_cvd = np.minimum(t_true, censor_time)\n",
    "    event = (t_true <= censor_time).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'ID': np.arange(1, n+1),\n",
    "        'Age': age.round(1), 'Sex': sex, 'Smoking': smoking,\n",
    "        'Physical_Activity': activity, 'Social_Class': social,\n",
    "        'Sugar_Intake': sugar.round(1), 'SFA_Intake': sfa.round(1),\n",
    "        'BMI_Baseline': baseline_bmi.round(2),\n",
    "        'BMI_Year2': bmi_y2.round(2), 'BMI_Year4': bmi_y4.round(2), 'BMI_Year6': bmi_y6.round(2),\n",
    "        'BP_Baseline': bp_base.round(1),\n",
    "        'Time_to_CVD': time_to_cvd.round(2), 'CVD_Incidence': event.astype(int)\n",
    "    })\n",
    "    # Inject MCAR missingness 5â€“10%\n",
    "    miss_cols = ['Sugar_Intake','SFA_Intake','Physical_Activity','Social_Class','BMI_Baseline','BMI_Year2','BMI_Year4','BMI_Year6','BP_Baseline']\n",
    "    for c in miss_cols:\n",
    "        m = rng.random(n) < rng.uniform(0.05,0.10)\n",
    "        df.loc[m, c] = np.nan\n",
    "    return df\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    data = simulate_epidemiology()\n",
    "    data.to_csv(DATA_PATH, index=False)\n",
    "    print(f\"Simulated and saved to {DATA_PATH}\")\n",
    "\n",
    "# Light QA\n",
    "assert {'ID','Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake','BMI_Baseline','BMI_Year2','BMI_Year4','BMI_Year6','BP_Baseline','Time_to_CVD','CVD_Incidence'} <= set(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table 1 â€” Baseline Characteristics\n",
    "Overall and (optionally) stratified summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "table1_fn",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def table1(df, group=None):\n",
    "    num_cols = ['Age','BMI_Baseline','BP_Baseline','Sugar_Intake','SFA_Intake']\n",
    "    cat_cols = ['Sex','Smoking','Physical_Activity','Social_Class']\n",
    "    if group is None:\n",
    "        cont = df[num_cols].agg(['mean','std','median','min','max','count']).T.round(2)\n",
    "        cats = {}\n",
    "        for c in cat_cols:\n",
    "            vc = df[c].value_counts(dropna=False)\n",
    "            p = (vc/vc.sum()*100).round(1)\n",
    "            cats[c] = pd.DataFrame({'n': vc, '%': p})\n",
    "        return cont, cats\n",
    "    else:\n",
    "        gvals = df[group].dropna().unique()\n",
    "        cont = df.groupby(group)[num_cols].agg(['mean','std','count']).round(2)\n",
    "        cats = {c: pd.crosstab(df[c], df[group], dropna=False) for c in cat_cols}\n",
    "        cats_pct = {c: (tab / tab.sum(axis=0) * 100).round(1) for c, tab in cats.items()}\n",
    "        return cont, cats, cats_pct\n",
    "\n",
    "cont_overall, cats_overall = table1(data)\n",
    "cont_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missingness",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Missing Data â€” Extent & Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missingness_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "miss_pct = data.isna().mean().sort_values(ascending=False)*100\n",
    "miss_df = miss_pct[miss_pct>0].round(2).to_frame('Missing_%')\n",
    "display(miss_df)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(data.sample(min(2000, len(data))).isna(), cbar=False)\n",
    "plt.title('Missingness heatmap (sample rows)'); plt.xlabel('Variables'); plt.ylabel('Participants'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xsec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-Sectional: Baseline BMI\n",
    "Predictors: age, sex, smoking, physical activity, social class, sugar, SFA.\n",
    "\n",
    "Encoding via one-hot (reference: Female, Non-smoker, Medium activity, Social class C1). Simple **mean imputation** for teaching clarity; consider **multiple imputation** in real analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xsec_prep",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xsec = data[['BMI_Baseline','Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake']].copy()\n",
    "xsec['Physical_Activity'] = xsec['Physical_Activity'].astype('category').cat.set_categories(['Low','Medium','High'])\n",
    "xsec['Social_Class'] = xsec['Social_Class'].astype('category').cat.set_categories(['A','B','C1','C2','D','E'])\n",
    "\n",
    "# Mean impute numeric, mode impute categoricals\n",
    "for c in ['Age','Sugar_Intake','SFA_Intake','BMI_Baseline']:\n",
    "    xsec[c] = xsec[c].fillna(xsec[c].mean())\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    xsec[c] = xsec[c].fillna(xsec[c].mode().iloc[0])\n",
    "\n",
    "# OLS with categorical references\n",
    "formula = 'BMI_Baseline ~ Age + C(Sex) + C(Smoking) + C(Physical_Activity, Treatment(reference=\"Medium\")) + C(Social_Class, Treatment(reference=\"C1\")) + Sugar_Intake + SFA_Intake'\n",
    "ols_xsec = smf.ols(formula, data=xsec).fit()\n",
    "print(ols_xsec.summary())\n",
    "\n",
    "# Tidy table of estimates with 95% CI\n",
    "ci = ols_xsec.conf_int(); ci.columns = ['2.5%','97.5%']\n",
    "est = ols_xsec.params.to_frame('coef').join(ci).round(3)\n",
    "est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xsec_bayes",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bayesian Linear Regression (vectorised)\n",
    "Weakly-informative priors; standardise numeric predictors for better geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xsec_bayes_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_dum = pd.get_dummies(xsec.drop(columns=['BMI_Baseline']), drop_first=True)\n",
    "num_cols = ['Age','Sugar_Intake','SFA_Intake']\n",
    "x_dum[[c for c in num_cols if c in x_dum.columns]] = (x_dum[[c for c in num_cols if c in x_dum.columns]] - x_dum[[c for c in num_cols if c in x_dum.columns]].mean()) / x_dum[[c for c in num_cols if c in x_dum.columns]].std()\n",
    "X = x_dum.astype(float).values\n",
    "y = xsec['BMI_Baseline'].values\n",
    "\n",
    "with pm.Model() as blm:\n",
    "    pm.MutableData('X', X)\n",
    "    pm.MutableData('y', y)\n",
    "    intercept = pm.Normal('Intercept', 0, 5)\n",
    "    beta = pm.Normal('Beta', 0, 1.5, shape=X.shape[1])\n",
    "    sigma = pm.HalfNormal('Sigma', 3)\n",
    "    mu = intercept + pm.math.dot(pm.get_data('X'), beta)\n",
    "    pm.Normal('y_obs', mu=mu, sigma=sigma, observed=pm.get_data('y'))\n",
    "    trace_blm = pm.sample(1500, tune=1000, target_accept=0.9, random_seed=RANDOM_SEED, return_inferencedata=True)\n",
    "\n",
    "names = x_dum.columns.tolist()\n",
    "trace_blm.posterior = trace_blm.posterior.rename({'Beta_dim_0':'coef'})\n",
    "trace_blm.posterior = trace_blm.posterior.assign_coords({'coef': names})\n",
    "az.plot_forest(trace_blm, var_names=['Beta'], combined=True);\n",
    "plt.title('Cross-sectional BMI: posterior 95% HDIs'); plt.show()\n",
    "az.summary(trace_blm, var_names=['Intercept','Beta','Sigma'], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surv",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Survival: Incident CVD (Frequentist & Bayesian)\n",
    "We treat `Time_to_CVD` (months) with event indicator `CVD_Incidence` (1=event, 0=censored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cox",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surv = data[['Time_to_CVD','CVD_Incidence','Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake','BMI_Baseline']].copy()\n",
    "for c in ['Age','Sugar_Intake','SFA_Intake','BMI_Baseline']:\n",
    "    surv[c] = surv[c].fillna(surv[c].mean())\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    surv[c] = surv[c].fillna(surv[c].mode().iloc[0])\n",
    "surv_d = pd.get_dummies(surv, drop_first=True)\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(surv_d, duration_col='Time_to_CVD', event_col='CVD_Incidence')\n",
    "cph.print_summary()\n",
    "\n",
    "# PH assumption check (global test)\n",
    "pht = proportional_hazard_test(cph, surv_d, time_transform='rank')\n",
    "print(pht.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bayes_surv",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bayesian Weibull AFT with Censoring (PyMC)\n",
    "We specify a Weibull(shape=Î±, scale=Î»_i), where log(Î»_i) = Î²Â·x_i. For **events** we use log f(t_i), for **censored** we use log S(t_i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bayes_surv_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Design matrix (standardise continuous predictors)\n",
    "bx = surv.copy()\n",
    "bx_dum = pd.get_dummies(bx[['Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake','BMI_Baseline']], drop_first=True)\n",
    "conts = ['Age','Sugar_Intake','SFA_Intake','BMI_Baseline']\n",
    "for c in conts:\n",
    "    bx_dum[c] = (bx_dum[c]-bx_dum[c].mean())/bx_dum[c].std()\n",
    "X = bx_dum.astype(float).values\n",
    "t = surv['Time_to_CVD'].values\n",
    "d = surv['CVD_Incidence'].values.astype(int)\n",
    "\n",
    "def weibull_logpdf(t, alpha, lam):\n",
    "    # f(t) = (alpha/lam)*(t/lam)^(alpha-1) * exp(-(t/lam)^alpha)\n",
    "    z = (t/lam)**alpha\n",
    "    return np.log(alpha) - np.log(lam) + (alpha-1)*(np.log(t)-np.log(lam)) - z\n",
    "\n",
    "def weibull_logsf(t, alpha, lam):\n",
    "    # S(t) = exp(-(t/lam)^alpha)\n",
    "    z = (t/lam)**alpha\n",
    "    return -z\n",
    "\n",
    "with pm.Model() as wb_aft:\n",
    "    pm.MutableData('X', X)\n",
    "    pm.MutableData('t', t)\n",
    "    pm.MutableData('d', d)\n",
    "    intercept = pm.Normal('Intercept', 0, 2)\n",
    "    beta = pm.Normal('Beta', 0, 1.5, shape=X.shape[1])\n",
    "    alpha = pm.LogNormal('Alpha', np.log(1.2), 0.4)  # shape >0\n",
    "    log_lambda = intercept + pm.math.dot(pm.get_data('X'), beta)\n",
    "    lam = pm.Deterministic('Lambda', pm.math.exp(log_lambda))\n",
    "\n",
    "    # Custom log-likelihood combining events and censored\n",
    "    logf = pm.log(det=weibull_logpdf(pm.get_data('t'), alpha, lam)) if False else None  # placeholder to show intent\n",
    "    # Implement with aesara tensor ops:\n",
    "    import aesara.tensor as at\n",
    "    t_tt = at.as_tensor_variable(pm.get_data('t'))\n",
    "    d_tt = at.as_tensor_variable(pm.get_data('d'))\n",
    "    alpha_tt = alpha\n",
    "    lam_tt = lam\n",
    "    z = (t_tt/lam_tt)**alpha_tt\n",
    "    logf_tt = at.log(alpha_tt) - at.log(lam_tt) + (alpha_tt-1)*(at.log(t_tt)-at.log(lam_tt)) - z\n",
    "    logS_tt = -z\n",
    "    ll = at.sum(d_tt*logf_tt + (1-d_tt)*logS_tt)\n",
    "    pm.Potential('loglike', ll)\n",
    "\n",
    "    trace_wb = pm.sample(1500, tune=1000, target_accept=0.9, random_seed=RANDOM_SEED, return_inferencedata=True)\n",
    "\n",
    "names = bx_dum.columns.tolist()\n",
    "trace_wb.posterior = trace_wb.posterior.rename({'Beta_dim_0':'coef'})\n",
    "trace_wb.posterior = trace_wb.posterior.assign_coords({'coef': names})\n",
    "az.plot_forest(trace_wb, var_names=['Beta'], combined=True);\n",
    "plt.title('Weibull AFT (CVD): posterior 95% HDIs'); plt.show()\n",
    "az.summary(trace_wb, var_names=['Intercept','Beta','Alpha'], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective_prep",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prospective: BMI Trajectories\n",
    "Long format with random intercepts by participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective_long",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['ID','Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake'],\n",
    "    value_vars=['BMI_Baseline','BMI_Year2','BMI_Year4','BMI_Year6'],\n",
    "    var_name='Time', value_name='BMI'\n",
    ")\n",
    "long['Time'] = long['Time'].map({'BMI_Baseline':0,'BMI_Year2':2,'BMI_Year4':4,'BMI_Year6':6})\n",
    "for c in ['Age','Sugar_Intake','SFA_Intake','BMI','Time']:\n",
    "    long[c] = long[c].astype(float)\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    long[c] = long[c].fillna(long[c].mode().iloc[0])\n",
    "for c in ['Age','Sugar_Intake','SFA_Intake','BMI']:\n",
    "    long[c] = long[c].fillna(long[c].mean())\n",
    "\n",
    "# Frequentist mixed effects: random intercept by ID\n",
    "mix = smf.mixedlm('BMI ~ Time + Age + C(Sex) + C(Smoking) + C(Physical_Activity) + C(Social_Class) + Sugar_Intake + SFA_Intake',\n",
    "                  long, groups=long['ID'])\n",
    "mix_res = mix.fit()\n",
    "print(mix_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective_bayes",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bayesian Mixed-Effects (Random Intercepts)\n",
    "Efficient hierarchical model with per-participant intercepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective_bayes_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = long['ID'].astype('category')\n",
    "id_idx = ids.cat.codes.values\n",
    "N_id = ids.cat.categories.size\n",
    "\n",
    "Xd = pd.get_dummies(long[['Sex','Smoking','Physical_Activity','Social_Class']], drop_first=True)\n",
    "Xc = long[['Time','Age','Sugar_Intake','SFA_Intake']].copy()\n",
    "Xc[['Time','Age','Sugar_Intake','SFA_Intake']] = (Xc[['Time','Age','Sugar_Intake','SFA_Intake']] - Xc[['Time','Age','Sugar_Intake','SFA_Intake']].mean())/Xc[['Time','Age','Sugar_Intake','SFA_Intake']].std()\n",
    "X_all = pd.concat([Xc, Xd], axis=1).astype(float)\n",
    "X_mat = X_all.values\n",
    "y_bmi = long['BMI'].values\n",
    "\n",
    "with pm.Model() as hm:\n",
    "    pm.MutableData('X', X_mat)\n",
    "    pm.MutableData('id_idx', id_idx)\n",
    "    pm.MutableData('y', y_bmi)\n",
    "    # Fixed effects\n",
    "    beta = pm.Normal('Beta', 0, 1.5, shape=X_mat.shape[1])\n",
    "    # Random intercepts\n",
    "    mu_a = pm.Normal('mu_a', 0, 5)\n",
    "    sigma_a = pm.HalfNormal('sigma_a', 5)\n",
    "    a = pm.Normal('a', mu_a, sigma_a, shape=N_id)\n",
    "    # Noise\n",
    "    sigma = pm.HalfNormal('Sigma', 5)\n",
    "    mu = a[pm.get_data('id_idx')] + pm.math.dot(pm.get_data('X'), beta)\n",
    "    pm.Normal('y_obs', mu=mu, sigma=sigma, observed=pm.get_data('y'))\n",
    "    trace_hm = pm.sample(1500, tune=1000, target_accept=0.9, random_seed=RANDOM_SEED, return_inferencedata=True)\n",
    "\n",
    "trace_hm.posterior = trace_hm.posterior.rename({'Beta_dim_0':'coef'})\n",
    "trace_hm.posterior = trace_hm.posterior.assign_coords({'coef': X_all.columns.tolist()})\n",
    "az.plot_forest(trace_hm, var_names=['Beta'], combined=True);\n",
    "plt.title('BMI trajectory: fixed-effect posteriors'); plt.show()\n",
    "az.summary(trace_hm, var_names=['mu_a','sigma_a','Beta','Sigma'], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective_cvd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prospective CVD (Logistic)\n",
    "Aggregate BMI over follow-up and predict CVD incidence (teaching-oriented simplification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective_cvd_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg = long.groupby('ID').agg({\n",
    "    'BMI':'mean','Age':'first','Sex':'first','Smoking':'first','Physical_Activity':'first','Social_Class':'first','Sugar_Intake':'first','SFA_Intake':'first'\n",
    "}).merge(data[['ID','CVD_Incidence']], on='ID', how='left')\n",
    "# Impute any residual missing\n",
    "for c in ['BMI','Age','Sugar_Intake','SFA_Intake']:\n",
    "    agg[c] = agg[c].fillna(agg[c].mean())\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    agg[c] = agg[c].fillna(agg[c].mode().iloc[0])\n",
    "\n",
    "logit_df = pd.get_dummies(agg, drop_first=True)\n",
    "y = logit_df['CVD_Incidence'].values\n",
    "X = logit_df.drop(columns=['CVD_Incidence','ID']).astype(float)\n",
    "X = sm.add_constant(X)\n",
    "logit = sm.Logit(y, X).fit(disp=False)\n",
    "or_tab = pd.DataFrame({\n",
    "    'OR': np.exp(logit.params),\n",
    "    '2.5%': np.exp(logit.conf_int()[0]),\n",
    "    '97.5%': np.exp(logit.conf_int()[1])\n",
    "}).round(3)\n",
    "or_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective_cvd_bayes",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bayesian Logistic (Prospective CVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective_cvd_bayes_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xb = logit_df.drop(columns=['CVD_Incidence','ID']).astype(float)\n",
    "Xb = (Xb - Xb.mean())/Xb.std()\n",
    "X_mat = Xb.values\n",
    "y_vec = y\n",
    "with pm.Model() as blog:\n",
    "    pm.MutableData('X', X_mat)\n",
    "    pm.MutableData('y', y_vec)\n",
    "    beta0 = pm.Normal('Intercept', 0, 2)\n",
    "    beta = pm.Normal('Beta', 0, 1.5, shape=X_mat.shape[1])\n",
    "    logit_p = beta0 + pm.math.dot(pm.get_data('X'), beta)\n",
    "    pm.Bernoulli('y_obs', logit_p=logit_p, observed=pm.get_data('y'))\n",
    "    trace_blog = pm.sample(1500, tune=1000, target_accept=0.9, random_seed=RANDOM_SEED, return_inferencedata=True)\n",
    "\n",
    "trace_blog.posterior = trace_blog.posterior.rename({'Beta_dim_0':'coef'})\n",
    "trace_blog.posterior = trace_blog.posterior.assign_coords({'coef': Xb.columns.tolist()})\n",
    "az.plot_forest(trace_blog, var_names=['Beta'], combined=True);\n",
    "plt.title('Prospective CVD: log-odds posteriors'); plt.show()\n",
    "az.summary(trace_blog, var_names=['Intercept','Beta'], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Take-aways (from simulated data)\n",
    "- **Cross-sectional BMI**: increases with sugar, male sex; lower with higher activity; effect sizes align with data-generating process.\n",
    "- **CVD risk**: age, smoking, SFA raise risk; activity protective. Cox and Bayesian AFT agree qualitatively.\n",
    "- **BMI trajectories**: rise with sugar; participant heterogeneity captured via random intercepts.\n",
    "\n",
    "**Teaching notes**: Replace mean/mode imputation with **multiple imputation** for realism; examine **interactions** (e.g., ageÃ—SFA), **non-linearity** (splines), PH diagnostics, and **prior sensitivity**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}