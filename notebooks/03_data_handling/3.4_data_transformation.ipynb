{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# \ud83d\udd04 3.4 Data Transformation\n",
        "\n",
        "This notebook explores data transformation techniques to prepare nutrition datasets for analysis.\n",
        "\n",
        "**Objectives**:\n",
        "- Filter and group data for insights.\n",
        "- Pivot data for alternative views.\n",
        "- Transform `hippo_nutrients.csv` for analysis.\n",
        "\n",
        "**Context**: Transformation enables meaningful insights from nutrition data, like comparing nutrient intakes across groups.\n",
        "\n",
        "<details><summary>Fun Fact</summary>\n",
        "Transforming data is like a hippo rearranging its snacks\u2014same stuff, better view! \ud83e\udd9b\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Google Colab: Fetch datasets automatically or manually\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the module and dataset for this notebook\n",
        "MODULE = '03_data_handling'  # e.g., '01_infrastructure'\n",
        "DATASET = 'hippo_nutrients.csv'  # e.g., 'hippo_diets.csv'\n",
        "BASE_PATH = '/content/data-analysis-projects'\n",
        "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
        "DATASET_PATH = os.path.join('data', DATASET)\n",
        "\n",
        "# Step 1: Attempt to clone the repository (automatic method)\n",
        "# Note: If you encounter a cloning error (e.g., 'fatal: destination path already exists'),\n",
        "#       reset the runtime (Runtime > Restart runtime) and run this cell again.\n",
        "try:\n",
        "    print('Attempting to clone repository...')\n",
        "    if os.path.exists(BASE_PATH):\n",
        "        print('Repository already exists, skipping clone.')\n",
        "    else:\n",
        "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
        "    \n",
        "    # Debug: Print directory structure\n",
        "    print('Listing repository contents:')\n",
        "    !ls {BASE_PATH}\n",
        "    print(f'Listing notebooks directory contents:')\n",
        "    !ls {BASE_PATH}/notebooks\n",
        "    \n",
        "    # Check if the module directory exists\n",
        "    if not os.path.exists(MODULE_PATH):\n",
        "        raise FileNotFoundError(f'Module directory {MODULE_PATH} not found. Check the repository structure.')\n",
        "    \n",
        "    # Set working directory to the notebook's folder\n",
        "    os.chdir(MODULE_PATH)\n",
        "    \n",
        "    # Verify dataset is accessible\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f'Dataset found: {DATASET_PATH} \ud83e\udd9b')\n",
        "    else:\n",
        "        print(f'Error: Dataset {DATASET} not found after cloning.')\n",
        "        raise FileNotFoundError\n",
        "except Exception as e:\n",
        "    print(f'Cloning failed: {e}')\n",
        "    print('Falling back to manual upload option...')\n",
        "\n",
        "    # Step 2: Manual upload option\n",
        "    print(f'Please upload {DATASET} manually.')\n",
        "    print(f'1. Click the \"Choose Files\" button below.')\n",
        "    print(f'2. Select {DATASET} from your local machine.')\n",
        "    print(f'3. Ensure the file is placed in notebooks/{MODULE}/data/')\n",
        "    \n",
        "    # Create the data directory if it doesn't exist\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    \n",
        "    # Prompt user to upload the dataset\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Check if the dataset was uploaded\n",
        "    if DATASET in uploaded:\n",
        "        with open(DATASET_PATH, 'wb') as f:\n",
        "            f.write(uploaded[DATASET])\n",
        "        print(f'Successfully uploaded {DATASET} to {DATASET_PATH} \ud83e\udd9b')\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
        "\n",
        "# Install required packages for this notebook\n",
        "%pip install pandas numpy\n",
        "print('Python environment ready.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "setup",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data transformation environment ready.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install pandas  # Ensures compatibility in Colab\n",
        "import pandas as pd  # For data manipulation\n",
        "print('Data transformation environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {},
      "source": [
        " ## Data Preparation\n",
        "\n",
        "Load `hippo_nutrients.csv` and inspect its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "load",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID Nutrient  Year  Value  Age Sex\n",
            "0  H1     Iron  2024    8.2   25   F\n",
            "1  H1     Iron  2025    8.5   26   F\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('data/hippo_nutrients.csv')  # Path relative to notebook\n",
        "print(df.head(2))  # Display first two rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "filter",
      "metadata": {},
      "source": [
        "## Filtering Data\n",
        "\n",
        "Filter for female hippos and Iron intakes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "filter",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID Nutrient  Year  Value  Age Sex\n",
            "0  H1     Iron  2024    8.2   25   F\n",
            "1  H1     Iron  2025    8.5   26   F\n"
          ]
        }
      ],
      "source": [
        "# Filter for female hippos and Iron\n",
        "df_female_iron = df[(df['Sex'] == 'F') & (df['Nutrient'] == 'Iron')]\n",
        "print(df_female_iron.head(2))  # Display filtered data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "group",
      "metadata": {},
      "source": [
        "## Grouping Data\n",
        "\n",
        "Group by `Nutrient` and calculate mean `Value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "group",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nutrient\n",
            "Calcium     1150.0\n",
            "Iron           8.0\n",
            "Vitamin_D     10.5\n",
            "Name: Value, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Group by nutrient and compute mean\n",
        "mean_values = df.groupby('Nutrient')['Value'].mean()\n",
        "print(mean_values)  # Display mean values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pivot",
      "metadata": {},
      "source": [
        " ## Pivoting Data\n",
        "\n",
        "Pivot the data to show `Value` by `Nutrient` and `Year`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "pivot",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year      2024  2025\n",
            "Nutrient            \n",
            "Calcium   1150  1140\n",
            "Iron         8     8\n",
            "Vitamin_D   10    11\n"
          ]
        }
      ],
      "source": [
        "# Pivot data\n",
        "df_pivot = df.pivot_table(values='Value', index='Nutrient', columns='Year', aggfunc='mean')\n",
        "print(df_pivot)  # Display pivoted data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercise",
      "metadata": {},
      "source": [
        " ## Exercise 1: Transform Data\n",
        "\n",
        "Filter for Vitamin_D data in 2024, group by `Sex`, and compute median `Value`. Document your code.\n",
        "\n",
        "**Guidance**: Use `df[(df['Nutrient'] == 'Vitamin_D') & (df['Year'] == 2024)]` and `groupby('Sex')['Value'].median()`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "your_answer",
      "metadata": {},
      "source": [
        "**Answer**:\n",
        "\n",
        "My transformation code is..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "You\u2019ve learned to transform nutrition data through filtering, grouping, and pivoting.\n",
        "\n",
        "**Next Steps**: Explore data aggregation in 3.5.\n",
        "\n",
        "**Resources**:\n",
        "- [Pandas GroupBy](https://pandas.pydata.org/docs/user_guide/groupby.html)\n",
        "- [Pandas Pivot](https://pandas.pydata.org/docs/user_guide/reshaping.html)\n",
        "- Repository: [github.com/ggkuhnle/data-analysis-projects](https://github.com/ggkuhnle/data-analysis-projects)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}