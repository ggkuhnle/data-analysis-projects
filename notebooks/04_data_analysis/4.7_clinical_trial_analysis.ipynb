{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44feba3b",
   "metadata": {},
   "source": [
    "# ü©∫ 4.7 Analysing a Simulated Clinical Trial\n",
    "\n",
    "In this notebook, we‚Äôll analyse a **simulated clinical trial**, a common method in nutrition research to compare outcomes between groups.\n",
    "\n",
    "You will:\n",
    "- Simulate trial data\n",
    "- Create a baseline summary table (Table 1)\n",
    "- Visualise variable distributions\n",
    "- Calculate effect sizes using frequentist and Bayesian approaches\n",
    "- Interpret results, including visualising posterior chains\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What is a Clinical Trial?\n",
    "\n",
    "A clinical trial is a study where participants are randomly assigned to groups to test the effect of an intervention (e.g. a new diet) on a health outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2b331",
   "metadata": {},
   "source": [
    "## üß™ Step 1: Simulate the Data\n",
    "\n",
    "We simulate a dataset for 100 participants, with two groups:\n",
    "- Control (group = 0)\n",
    "- Intervention (group = 1)\n",
    "\n",
    "We'll generate age, BMI, and a simulated outcome (e.g., biomarker change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "df = pd.DataFrame({\n",
    "    'participant_id': range(1, n+1),\n",
    "    'age': np.random.normal(40, 10, n),\n",
    "    'bmi': np.random.normal(27, 4, n),\n",
    "    'group': np.random.choice([0, 1], size=n)\n",
    "})\n",
    "df['outcome'] = np.where(\n",
    "    df['group'] == 0,\n",
    "    np.random.normal(0, 2, n),\n",
    "    np.random.normal(1, 2, n)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e224816",
   "metadata": {},
   "source": [
    "## üìã Step 2: Baseline Table\n",
    "\n",
    "This shows the average characteristics (age and BMI) in each group, before the intervention's effect is measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = df.groupby('group')[['age', 'bmi']].agg(['mean', 'std']).round(1)\n",
    "table1.columns = ['Age (Mean)', 'Age (SD)', 'BMI (Mean)', 'BMI (SD)']\n",
    "table1.index = ['Control', 'Intervention']\n",
    "table1['Age'] = table1.apply(lambda row: f\"{row['Age (Mean)']} ¬± {row['Age (SD)']}\", axis=1)\n",
    "table1['BMI'] = table1.apply(lambda row: f\"{row['BMI (Mean)']} ¬± {row['BMI (SD)']}\", axis=1)\n",
    "table1[['Age', 'BMI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20452d2",
   "metadata": {},
   "source": [
    "## üìà Step 3: Visualise Distributions\n",
    "\n",
    "We'll use histograms and KDEs to visualise the distributions of each variable by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "variables = ['age', 'bmi', 'outcome']\n",
    "titles = ['Age Distribution', 'BMI Distribution', 'Outcome Distribution']\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    sns.histplot(data=df, x=var, hue='group', kde=True, element=\"step\", stat=\"density\",\n",
    "                 common_norm=False, palette='Set1', ax=axes[i])\n",
    "    axes[i].set_title(titles[i])\n",
    "    axes[i].legend(title='Group', labels=['Control', 'Intervention'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdcb28",
   "metadata": {},
   "source": [
    "## üìè Step 4: Frequentist Analysis\n",
    "\n",
    "We use **Cohen‚Äôs d** to measure the size of the effect, and a t-test to check for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29954583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group0 = df[df['group'] == 0]['outcome']\n",
    "group1 = df[df['group'] == 1]['outcome']\n",
    "\n",
    "mean_diff = group1.mean() - group0.mean()\n",
    "pooled_sd = np.sqrt((group0.var() + group1.var()) / 2)\n",
    "cohens_d = mean_diff / pooled_sd\n",
    "\n",
    "t_stat, p_val = ttest_ind(group1, group0)\n",
    "\n",
    "print(f\"Cohen's d: {cohens_d:.2f}\")\n",
    "print(f\"T-test: t = {t_stat:.2f}, p = {p_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00c861",
   "metadata": {},
   "source": [
    "## üß† Step 5: Bayesian Analysis\n",
    "\n",
    "We use PyMC to estimate the difference in outcome between groups and generate a **posterior distribution**.\n",
    "\n",
    "We will:\n",
    "- Estimate the posterior mean difference\n",
    "- Calculate a 95% HDI (Highest Density Interval)\n",
    "- Visualise the posterior\n",
    "- Plot the sampling chains to assess convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad105090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=10, shape=2)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=2)\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu[df['group']], sigma=sigma, observed=df['outcome'])\n",
    "    diff = pm.Deterministic(\"diff\", mu[1] - mu[0])\n",
    "    trace = pm.sample(1000, tune=1000, return_inferencedata=True, progressbar=True)\n",
    "\n",
    "az.plot_posterior(trace, var_names=[\"diff\"], ref_val=0)\n",
    "plt.title(\"Posterior Difference in Means\")\n",
    "plt.show()\n",
    "\n",
    "# Posterior mean and HDI\n",
    "posterior_diff = trace.posterior['diff'].values.flatten()\n",
    "posterior_mean = posterior_diff.mean()\n",
    "hdi_bounds = az.hdi(posterior_diff, hdi_prob=0.95)\n",
    "\n",
    "print(f\"Posterior mean difference: {posterior_mean:.2f}\")\n",
    "print(f\"95% HDI: [{hdi_bounds[0]:.2f}, {hdi_bounds[1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6368500",
   "metadata": {},
   "source": [
    "### üîÅ Step 5b: Visualise Chains\n",
    "\n",
    "This helps us assess **MCMC convergence** (i.e. did the sampler explore the space thoroughly?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c23322",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace, var_names=[\"diff\"])\n",
    "plt.suptitle(\"Trace Plot for Posterior Difference\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea109d4e",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "You‚Äôve:\n",
    "- Simulated a clinical trial dataset\n",
    "- Analysed it with frequentist and Bayesian methods\n",
    "- Visualised the posterior and trace\n",
    "\n",
    "**Key Insight**:  \n",
    "Bayesian methods offer more nuance, while frequentist methods are simpler and quicker. Both can be valuable.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Optional Exercises\n",
    "1. Change the simulated effect size (e.g., Intervention mean = 2). Re-run and compare.\n",
    "2. Add `age` as a covariate in the Bayesian model.\n",
    "3. Create a scatterplot of `outcome` vs. `bmi`, coloured by group.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
