{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# üß† 5.3 Advanced Bayesian Modelling\n",
        "\n",
        "In this notebook we go beyond basic Bayes and build **hierarchical (multilevel) models** for nutrition data. You‚Äôll see how **partial pooling** stabilises estimates across groups, how **robust likelihoods** handle outliers, and how to do **prior/posterior predictive checks**, **diagnostics**, and **model comparison**.\n",
        "\n",
        "**You will:**\n",
        "- Fit hierarchical models with varying intercepts (and optional slopes).\n",
        "- Compare Normal vs **Student-t** likelihoods for robustness.\n",
        "- Run **prior predictive** and **posterior predictive** checks.\n",
        "- Inspect diagnostics (**R-hat**, **ESS**) and compare models via **WAIC/LOO**.\n",
        "- Use **non-centred** parameterisation for better sampling.\n",
        "\n",
        "<details><summary>When to use hierarchical Bayes?</summary>\n",
        "When you have repeated measures, sites/years/sexes/diets, or any natural grouping where you want to share strength across groups without assuming they‚Äôre identical.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab setup: clone repo and locate data\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "MODULE = '05_advanced'\n",
        "BASE_PATH = '/content/data-analysis-projects'\n",
        "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
        "\n",
        "# We'll read hippo nutrients from the data-handling module\n",
        "DATA_MODULE = '03_data_handling'\n",
        "NUTRIENTS_PATH = os.path.join(BASE_PATH, 'notebooks', DATA_MODULE, 'data', 'hippo_nutrients.csv')\n",
        "\n",
        "try:\n",
        "    print('Attempting to clone repository...')\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
        "    print('Setting working directory...')\n",
        "    os.chdir(MODULE_PATH)\n",
        "    if os.path.exists(NUTRIENTS_PATH):\n",
        "        print(f'Dataset found: {NUTRIENTS_PATH} ‚úÖ')\n",
        "    else:\n",
        "        raise FileNotFoundError('hippo_nutrients.csv missing after clone.')\n",
        "except Exception as e:\n",
        "    print(f'Cloning failed: {e}')\n",
        "    print('You can upload hippo_nutrients.csv manually to notebooks/03_data_handling/data/.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "install_libs",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pandas numpy pymc arviz matplotlib\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "import pymc as pm, arviz as az\n",
        "pd.set_option('display.max_columns', 40)\n",
        "print('Bayesian environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {},
      "source": [
        "## üì• Load & Prepare Data\n",
        "We‚Äôll model **Iron** intake as a function of **Sex** (F/M) and **Year** (2024/2025), using partial pooling across groups *(Sex √ó Year)*. Feel free to switch to Calcium/Vitamin_D later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_df",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUTRIENTS_PATH = '../../03_data_handling/data/hippo_nutrients.csv'  # relative to this notebook\n",
        "df = pd.read_csv(NUTRIENTS_PATH)\n",
        "df = df.dropna(subset=['Nutrient', 'Value', 'Sex', 'Year'])\n",
        "df_iron = df[df['Nutrient']=='Iron'].copy()\n",
        "df_iron['Sex'] = df_iron['Sex'].astype('category')\n",
        "df_iron['Year'] = df_iron['Year'].astype('category')\n",
        "df_iron['group'] = (df_iron['Sex'].astype(str) + '_' + df_iron['Year'].astype(str)).astype('category')\n",
        "print(df_iron[['ID','Nutrient','Year','Sex','Value']].head())\n",
        "print('\\nGroups:', df_iron['group'].cat.categories.tolist())\n",
        "print('Rows:', len(df_iron))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ppc_prior",
      "metadata": {},
      "source": [
        "## üéØ Prior Predictive Check\n",
        "Before seeing data, do our **priors** imply plausible values? We‚Äôll set weakly-informative priors and simulate from the prior predictive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prior_pred",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_iron['Value'].values\n",
        "group_idx = df_iron['group'].cat.codes.values\n",
        "n_groups = df_iron['group'].cat.categories.size\n",
        "\n",
        "with pm.Model() as prior_model:\n",
        "    mu_global = pm.Normal('mu_global', mu=8, sigma=2)  # Iron around ~8 with some spread\n",
        "    tau_group = pm.HalfNormal('tau_group', sigma=1)    # group sd\n",
        "    mu_group = pm.Normal('mu_group', mu=mu_global, sigma=tau_group, shape=n_groups)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
        "    y_like = pm.Normal('y_like', mu=mu_group[group_idx], sigma=sigma, observed=None, shape=y.shape[0])\n",
        "    prior_pred = pm.sample_prior_predictive(samples=1000, random_seed=42)\n",
        "\n",
        "az.plot_dist(prior_pred.prior_predictive['y_like'], kind='kde')\n",
        "plt.title('Prior Predictive: Iron (Value)'); plt.xlabel('Value'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hier_normal",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Hierarchical Model (Normal likelihood)\n",
        "Partial pooling of **group means** (Sex√óYear). This stabilises small groups by sharing information.\n",
        "\n",
        "- Global mean `mu_global`\n",
        "- Group deviations `mu_group ~ Normal(mu_global, tau_group)`\n",
        "- Observation noise `sigma`\n",
        "\n",
        "<details><summary>Tip: non-centred parameterisation</summary>\n",
        "We‚Äôll use a **non-centred** form to help sampling when groups are weakly informed: `mu_group = mu_global + z * tau_group`, `z ~ Normal(0,1)`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fit_normal",
      "metadata": {},
      "outputs": [],
      "source": [
        "coords = {\n",
        "    'group': df_iron['group'].cat.categories.tolist()\n",
        "}\n",
        "\n",
        "with pm.Model(coords=coords) as hier_normal:\n",
        "    pm.Data('group_idx', group_idx)\n",
        "\n",
        "    mu_global = pm.Normal('mu_global', mu=8, sigma=2)\n",
        "    tau_group = pm.HalfNormal('tau_group', sigma=1)\n",
        "    z = pm.Normal('z', mu=0, sigma=1, dims='group')\n",
        "    mu_group = pm.Deterministic('mu_group', mu_global + z * tau_group, dims='group')\n",
        "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
        "\n",
        "    y_obs = pm.Normal('y_obs', mu=mu_group[group_idx], sigma=sigma, observed=y)\n",
        "\n",
        "    idata_normal = pm.sample(1000, tune=1000, target_accept=0.9, chains=4, random_seed=42, return_inferencedata=True)\n",
        "    ppc_normal = pm.sample_posterior_predictive(idata_normal, random_seed=42)\n",
        "\n",
        "az.summary(idata_normal, var_names=['mu_global','tau_group','sigma','mu_group'], round_to=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ppc_normal_plot",
      "metadata": {},
      "source": [
        "### Posterior Predictive Check (Normal)\n",
        "Compare simulated `y_rep` to observed `y`. Look for systematic mismatches (spread, tails, skew)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ppc_normal",
      "metadata": {},
      "outputs": [],
      "source": [
        "az.plot_ppc(az.from_dict(posterior_predictive=ppc_normal, observed_data={'y_obs': y}))\n",
        "plt.title('PPC: Hierarchical Normal'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hier_student",
      "metadata": {},
      "source": [
        "## üß± Robust Hierarchical Model (Student-t likelihood)\n",
        "Outliers/severe tails? Use **Student-t** with unknown degrees of freedom `ŒΩ`.\n",
        "\n",
        "- `y_obs ~ StudentT(ŒΩ, mu_group[group_idx], sigma)`\n",
        "- `ŒΩ` with weakly informative prior (e.g., Exponential) to allow heavy tails when needed.\n",
        "\n",
        "<details><summary>Why t?</summary>\n",
        "It down-weights extreme observations relative to Normal, often yielding more stable inferences in messy nutrition data.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fit_t",
      "metadata": {},
      "outputs": [],
      "source": [
        "with pm.Model(coords=coords) as hier_t:\n",
        "    pm.Data('group_idx', group_idx)\n",
        "\n",
        "    mu_global = pm.Normal('mu_global', mu=8, sigma=2)\n",
        "    tau_group = pm.HalfNormal('tau_group', sigma=1)\n",
        "    z = pm.Normal('z', mu=0, sigma=1, dims='group')\n",
        "    mu_group = pm.Deterministic('mu_group', mu_global + z * tau_group, dims='group')\n",
        "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
        "    nu = pm.Exponential('nu', lam=1/10)  # mean 10, reasonably heavy tails allowed\n",
        "\n",
        "    y_obs = pm.StudentT('y_obs', nu=nu, mu=mu_group[group_idx], sigma=sigma, observed=y)\n",
        "\n",
        "    idata_t = pm.sample(1000, tune=1000, target_accept=0.9, chains=4, random_seed=42, return_inferencedata=True)\n",
        "    ppc_t = pm.sample_posterior_predictive(idata_t, random_seed=42)\n",
        "\n",
        "az.summary(idata_t, var_names=['mu_global','tau_group','sigma','nu','mu_group'], round_to=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ppc_t",
      "metadata": {},
      "outputs": [],
      "source": [
        "az.plot_ppc(az.from_dict(posterior_predictive=ppc_t, observed_data={'y_obs': y}))\n",
        "plt.title('PPC: Hierarchical Student-t'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostics",
      "metadata": {},
      "source": [
        "## üß™ Diagnostics & Model Comparison\n",
        "Check **R-hat** (~1.00), **ESS** (large), and compare models by **WAIC/LOO**. Lower is better (penalises complexity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diag_compare",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('R-hat (Normal):')\n",
        "display(az.rhat(idata_normal).to_dataframe().round(3).head(8))\n",
        "print('\\nR-hat (Student-t):')\n",
        "display(az.rhat(idata_t).to_dataframe().round(3).head(8))\n",
        "\n",
        "cmp = az.compare({'normal': idata_normal, 'student_t': idata_t}, method='BB-pseudo-BMA', ic='waic')\n",
        "cmp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contrasts",
      "metadata": {},
      "source": [
        "## üéØ Group Contrasts (Posterior Differences)\n",
        "You often want contrasts like **Treatment vs Control** or **F_2025 ‚àí F_2024**. We‚Äôll compute differences between selected `mu_group` levels from the robust model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrast_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = df_iron['group'].cat.categories.tolist()\n",
        "print('Groups:', groups)\n",
        "gmap = {g:i for i,g in enumerate(groups)}\n",
        "\n",
        "mu_post = idata_t.posterior['mu_group']  # dims: chain, draw, group\n",
        "\n",
        "# Example contrasts: (F_2025 - F_2024) and (M_2025 - M_2024) if present\n",
        "def posterior_diff(mu, g1, g0):\n",
        "    return (mu.sel(group=g1) - mu.sel(group=g0)).stack(sample=('chain','draw')).values\n",
        "\n",
        "contrast_results = {}\n",
        "if 'F_2025' in groups and 'F_2024' in groups:\n",
        "    d = posterior_diff(mu_post, 'F_2025', 'F_2024')\n",
        "    contrast_results['F_2025 - F_2024'] = d\n",
        "if 'M_2025' in groups and 'M_2024' in groups:\n",
        "    d = posterior_diff(mu_post, 'M_2025', 'M_2024')\n",
        "    contrast_results['M_2025 - M_2024'] = d\n",
        "\n",
        "for name, d in contrast_results.items():\n",
        "    az.plot_posterior(d, ref_val=0)\n",
        "    plt.title(f'Posterior Contrast: {name}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "varying_slope",
      "metadata": {},
      "source": [
        "## üìà (Optional) Varying Intercepts & Slopes\n",
        "If you have a continuous covariate (e.g., **Age** or **BodyWeight_kg**), allow group-specific slopes:\n",
        "\n",
        "```\n",
        "mu_group = mu_global + z_inter[group]*tau_inter\n",
        "beta_group = beta_global + z_slope[group]*tau_slope\n",
        "y ~ Normal(mu_group[group_idx] + beta_group[group_idx]*x, sigma)\n",
        "```\n",
        "\n",
        "<details><summary>Learn more</summary>\n",
        "- PyMC docs: https://www.pymc.io/\n",
        "- ArviZ model comparison: https://python.arviz.org/\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## üß© Exercises\n",
        "1. **Switch nutrient**: Fit the same hierarchical models for **Calcium**. Compare WAIC/LOO to decide between Normal vs Student-t.\n",
        "2. **Add covariate**: If your dataset has `Age` or `BodyWeight_kg`, build a varying-slopes model. Does partial pooling shrink extreme slopes?\n",
        "3. **Prior sensitivity**: Widen/narrow `tau_group` prior and re-run. How do group means change?\n",
        "4. **Predict new group**: Add a new year with few observations and inspect how partial pooling stabilises its estimate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## ‚úÖ Wrap-up\n",
        "You built hierarchical models, used robust likelihoods, checked priors/posteriors, validated diagnostics, and compared models. These tools generalise well to multi-site nutrition studies, repeated measures, and small-sample subgroups.\n",
        "\n",
        "<details><summary>Further reading</summary>\n",
        "- Gelman et al., *Bayesian Data Analysis*\n",
        "- PyMC docs: https://www.pymc.io/\n",
        "- ArviZ: https://python.arviz.org/\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
