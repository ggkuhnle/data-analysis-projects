{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸ¦› 3.1 Data Types and Structures â€” Wide vs Long (Tidy)\n",
    "\n",
    "In this notebook we explore **how data can be structured** in Python using pandas, with a special focus on the concepts of **wide** and **long (tidy)** formats.\n",
    "\n",
    "Good data organisation is the foundation of effective analysis. Just like a hippoâ€™s lunch tray ðŸ¦› needs everything neatly arranged to avoid chaos, your dataset should also be organised so that analyses are clear, reproducible, and easy to extend.\n",
    "\n",
    "---\n",
    "## ðŸŽ¯ Objectives\n",
    "By the end of this notebook, you should be able to:\n",
    "- Understand the distinction between **wide** and **long (tidy)** data formats.\n",
    "- Recognise which form a dataset is currently in.\n",
    "- Transform datasets using pandas functions (`melt` and `pivot`).\n",
    "- Apply tidy principles to nutrition datasets (e.g. hippo nutrient intake logs).\n",
    "\n",
    "---\n",
    "## ðŸ“– Why This Matters\n",
    "Most real-world datasets do not arrive perfectly formatted. Some are *wide* because they come from spreadsheets, others are *long* because they come from experiments or databases. You need to:\n",
    "- Reshape them for analysis and plotting.\n",
    "- Ensure consistency across different datasets.\n",
    "- Follow the principle of **tidy data**: *each variable is a column, each observation is a row, and each type of observational unit is a table.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959b6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for Google Colab: Fetch datasets automatically or manually\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "MODULE = '03_data_handling'\n",
    "DATASET = 'hippo_nutrients.csv'\n",
    "BASE_PATH = '/content/data-analysis-projects'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join('data', DATASET)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
    "    os.chdir(MODULE_PATH)\n",
    "    assert os.path.exists(DATASET_PATH)\n",
    "    print(f'Dataset found: {DATASET_PATH} âœ…')\n",
    "except Exception as e:\n",
    "    print(f'Automatic clone failed: {e}')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    uploaded = files.upload()\n",
    "    if DATASET in uploaded:\n",
    "        with open(DATASET_PATH, 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} âœ…')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
    "\n",
    "%pip install pandas numpy -q\n",
    "import pandas as pd, numpy as np\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concepts",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wide vs Long: Two Ways of Storing the Same Data\n",
    "\n",
    "Imagine you want to record the iron intake of hippos over two years. You could write it in two different ways:\n",
    "\n",
    "**Wide format (spreadsheet-style):**\n",
    "\n",
    "| ID | Age | Sex | Iron_2024 | Iron_2025 |\n",
    "|----|-----|-----|-----------|-----------|\n",
    "| H1 | 25  | F   | 8.2       | 8.5       |\n",
    "\n",
    "Here, each *column* holds a different measurement year. This is common in Excel files, but difficult to analyse with pandas.\n",
    "\n",
    "**Long (tidy) format:**\n",
    "\n",
    "| ID | Age | Sex | Nutrient | Year | Value |\n",
    "|----|-----|-----|----------|------|-------|\n",
    "| H1 | 25  | F   | Iron     | 2024 | 8.2   |\n",
    "| H1 | 26  | F   | Iron     | 2025 | 8.5   |\n",
    "\n",
    "Here, each row is one observation: a hippoâ€™s intake of a nutrient in a specific year. This is tidy data and works seamlessly with pandas and most plotting libraries.\n",
    "\n",
    "ðŸ‘‰ **Summary:**\n",
    "- **Wide data**: easy for humans to read, harder for computers.\n",
    "- **Long/tidy data**: the standard for analysis, modelling, and plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hippo_nutrients.csv')\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our dataset is already **long/tidy**: it has `Nutrient` and `Value` columns, so each row represents a single measurement.\n",
    "\n",
    "Letâ€™s practise converting it into **wide form** and then back to **long form**, to see the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pivot",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ”„ Long â†’ Wide using `pivot`\n",
    "\n",
    "We can make the dataset wider by spreading nutrients into columns. This is useful when we want a table with one row per hippo and year.\n",
    "\n",
    "```python\n",
    "df_wide = df.pivot(\n",
    "    index=['ID','Year','Age','Sex'],\n",
    "    columns='Nutrient',\n",
    "    values='Value'\n",
    ").reset_index()\n",
    "```\n",
    "\n",
    "This produces a DataFrame where nutrients like Iron, Calcium, etc. are each their own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "do_pivot",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_wide = df.pivot(index=['ID','Year','Age','Sex'], columns='Nutrient', values='Value').reset_index()\n",
    "df_wide.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "melt",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ”„ Wide â†’ Long using `melt`\n",
    "\n",
    "If we receive a dataset in wide format (many nutrient columns), we can convert it back to tidy format with `melt`.\n",
    "\n",
    "```python\n",
    "df_long = df_wide.melt(\n",
    "    id_vars=['ID','Year','Age','Sex'],\n",
    "    value_vars=[c for c in df_wide.columns if c not in ['ID','Year','Age','Sex']],\n",
    "    var_name='Nutrient',\n",
    "    value_name='Value'\n",
    ")\n",
    "```\n",
    "\n",
    "This stacks all nutrient columns into two columns: `Nutrient` (the name) and `Value` (the measurement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "do_melt",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_long = df_wide.melt(\n",
    "    id_vars=['ID','Year','Age','Sex'],\n",
    "    var_name='Nutrient',\n",
    "    value_name='Value'\n",
    ")\n",
    "df_long.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 1: Explore Wide Data\n",
    "1. Starting from the tidy `df`, create a **wide** DataFrame with `pivot`.\n",
    "2. Inspect how many columns of nutrients you now have.\n",
    "3. Which format (wide or long) would be easier if you wanted to **plot Iron intake over time**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 2: Work with Long Data\n",
    "1. Take `df_long` and filter it to only include rows where `Nutrient == 'Iron'`.\n",
    "2. Sort by `Year` and describe the pattern.\n",
    "3. Which format (wide or long) would be easier if you wanted to **calculate the mean intake for each nutrient**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## âœ… Conclusion\n",
    "In this notebook you:\n",
    "- Learned the difference between **wide** and **long (tidy)** data.\n",
    "- Practised reshaping with `pivot` and `melt`.\n",
    "- Saw why tidy data is powerful: it makes filtering, grouping, and plotting much simpler.\n",
    "\n",
    "ðŸ‘‰ In the next notebook (3.2), you will learn how to **import data** from different sources (CSV, Excel, databases) and start applying these tidy principles to new datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}