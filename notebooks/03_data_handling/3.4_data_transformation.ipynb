{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸ”„ 3.4 Data Transformation\n",
    "\n",
    "In this notebook youâ€™ll learn how to **transform** data so itâ€™s easy to analyse and model. Weâ€™ll work with `hippo_nutrients.csv` and cover filtering, grouping, reshaping (wide/long), pivoting, and numeric transformations such as **log** and **z-score** standardisation. Weâ€™ll also add **density plots** to visualise how transformations change the distribution.\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "- Filter rows and select columns with expressive, reproducible code.\n",
    "- **Aggregate** groups (what it means, when to use it) using `.groupby(...).agg(...)` with clear syntax.\n",
    "- Reshape between **wide** and **long** formats (melt / pivot).\n",
    "- Pivot-tabulate values for quick comparisons.\n",
    "- Create derived variables and apply **log**, **z-score**, **minâ€“max** scaling.\n",
    "- (Bonus) Group-wise standardisation and rolling transforms over time.\n",
    "- Use **density plots** to see how transformations change distributions.\n",
    "\n",
    "## ðŸ“Œ Context\n",
    "Transformation is the ladder from raw data to insight. In nutrition datasets, youâ€™ll often transform by **group** (e.g., nutrient, sex, year) and reshape between **wide** (one row per ID with many columns) and **long** (one row per measurement).\n",
    "\n",
    "> **Wide vs Long**\n",
    "- **Wide**: Each variable has its own column (e.g., `Iron`, `Calcium`, `Vitamin_D`). Good for humans and some models.\n",
    "- **Long (tidy)**: One row per observation; variables are in *columns*, not headers (e.g., a `Nutrient` column and a `Value` column). Preferred for plotting, grouping, modelling.\n",
    "\n",
    "<details><summary>Fun Fact</summary>\n",
    "Transforming data is like a hippo rearranging its snacks â€” same nutrients, better view! ðŸ¦›\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab_setup",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for Google Colab: Fetch datasets automatically or manually\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "MODULE = '03_data_handling'\n",
    "DATASET = 'hippo_nutrients.csv'\n",
    "BASE_PATH = '/content/data-analysis-projects'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join('data', DATASET)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
    "    os.chdir(MODULE_PATH)\n",
    "    assert os.path.exists(DATASET_PATH)\n",
    "    print(f'Dataset found: {DATASET_PATH} âœ…')\n",
    "except Exception as e:\n",
    "    print(f'Automatic clone failed: {e}')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    uploaded = files.upload()\n",
    "    if DATASET in uploaded:\n",
    "        with open(DATASET_PATH, 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} âœ…')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
    "\n",
    "print('Python environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "libs",
   "metadata": {
    "tags": []
   },
   "source": [
    "Add required libraries (pandas, numpy, matplotlib for density plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_libs",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy matplotlib\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 30)\n",
    "print('Libraries ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) Load and Inspect\n",
    "Letâ€™s load `hippo_nutrients.csv` and inspect the first rows and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hippo_nutrients.csv')\n",
    "print('Shape:', df.shape)\n",
    "print('Dtypes:\\n', df.dtypes)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter_select",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2) Filtering Rows and Selecting Columns\n",
    "Use **boolean masks** to keep the rows you want, and bracket notation to select columns. This is bread-and-butter transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter_select_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: female hippos, Iron only, years â‰¥ 2024\n",
    "mask = (df['Sex'] == 'F') & (df['Nutrient'] == 'Iron') & (df['Year'] >= 2024)\n",
    "cols = ['ID', 'Year', 'Nutrient', 'Value', 'Age', 'Sex']\n",
    "df_female_iron = df.loc[mask, cols].sort_values(['ID', 'Year']).reset_index(drop=True)\n",
    "display(df_female_iron.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agg_concept",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3) Aggregation â€” Concept and `.agg` Syntax\n",
    "**Aggregation** means reducing many rows in a group to **summary values** (e.g., mean iron intake by sex). In pandas, you usually do this with:\n",
    "\n",
    "```python\n",
    "df.groupby(<group-cols>)[<value-col>].agg(<how>)\n",
    "```\n",
    "\n",
    "### What can `<how>` be?\n",
    "1) A **single function**: `'mean'`, `'median'`, `'count'`, `'std'`, or a custom function:\n",
    "```python\n",
    "df.groupby('Nutrient')['Value'].agg('mean')\n",
    "```\n",
    "\n",
    "2) A **list of functions**: returns multiple columns with each statistic:\n",
    "```python\n",
    "df.groupby('Nutrient')['Value'].agg(['mean','median','count'])\n",
    "```\n",
    "\n",
    "3) A **dictionary** mapping column â†’ function(s):\n",
    "```python\n",
    "df.groupby(['Nutrient','Sex']).agg({\n",
    "  'Value': ['mean','median','count'],\n",
    "  'Age': 'mean'  # optional extra summaries\n",
    "})\n",
    "```\n",
    "\n",
    "4) **Named aggregations** (cleaner column names):\n",
    "```python\n",
    "df.groupby(['Nutrient','Sex']).agg(\n",
    "  Mean_Value = ('Value', 'mean'),\n",
    "  Median_Value = ('Value', 'median'),\n",
    "  N = ('Value', 'size')\n",
    ")\n",
    "```\n",
    "\n",
    "### Why aggregate?\n",
    "- To **summarise** groups (e.g., mean intake per nutrient, per sex).\n",
    "- To **compare** across categories (e.g., male vs female, 2024 vs 2025).\n",
    "- To **reduce noise** and **prepare** for plotting or reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "groupby",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Basic aggregations (mean, median, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "groupby_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Value by Nutrient\n",
    "mean_by_nutrient = df.groupby('Nutrient')['Value'].mean().sort_values(ascending=False)\n",
    "display(mean_by_nutrient)\n",
    "\n",
    "# Multiple aggregations by Nutrient and Sex (named aggregations for tidy column names)\n",
    "agg_ns = (\n",
    "    df.groupby(['Nutrient','Sex'])\n",
    "      .agg(Mean_Value=('Value','mean'),\n",
    "           Median_Value=('Value','median'),\n",
    "           N=('Value','size'))\n",
    "      .reset_index()\n",
    ")\n",
    "display(agg_ns.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wide_long_intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4) Reshaping Between Wide and Long\n",
    "Many real datasets arrive in **wide** form; most analyses and plots like **long (tidy)** form.\n",
    "\n",
    "### Long (tidy) â†’ one row per observation\n",
    "- Columns: `ID`, `Year`, `Age`, `Sex`, `Nutrient`, `Value`\n",
    "\n",
    "### Wide â†’ columns are variables (e.g., one column per nutrient)\n",
    "- Columns: `ID`, `Year`, `Age`, `Sex`, `Iron`, `Calcium`, `Vitamin_D`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wide_from_long_explain",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1 Long â†’ Wide (pivot wider)\n",
    "Use `pivot_table` with `index` = identifier columns and `columns` = the variable you want as new columns (`Nutrient`). Values come from `Value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pivot_wider",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_cols = ['ID','Year','Age','Sex']\n",
    "wide = df.pivot_table(index=id_cols, columns='Nutrient', values='Value', aggfunc='mean')\n",
    "wide = wide.reset_index()\n",
    "display(wide.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "long_from_wide_explain",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Wide â†’ Long (melt)\n",
    "Use `melt` to gather nutrient columns back into two columns: `Nutrient` (variable name) and `Value` (measurement). This is the canonical *tidy* structure for plotting, modelling, and faceting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "melt_long",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_vars = [c for c in wide.columns if c not in id_cols]\n",
    "long_again = wide.melt(id_vars=id_cols, value_vars=value_vars,\n",
    "                      var_name='Nutrient', value_name='Value')\n",
    "display(long_again.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pivot_tables",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5) Pivot Tables for Comparisons\n",
    "Cross-tabulate means by two dimensions (e.g., `Nutrient` Ã— `Year`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pivot_table_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pt = df.pivot_table(values='Value', index='Nutrient', columns='Year', aggfunc='mean')\n",
    "display(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived_vars",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6) Derived Variables and Numeric Transformations\n",
    "Real analyses often need **transformed** variables to meet model assumptions or to compare across scales.\n",
    "\n",
    "### 6.1 Log transform\n",
    "Use when data are **right-skewed** (e.g., highly variable intakes). Add a small `Îµ` to avoid `log(0)`.\n",
    "\n",
    "### 6.2 z-score standardisation\n",
    "Convert values to standard units: `(x - mean) / std`. Helpful when combining variables on different scales.\n",
    "\n",
    "### 6.3 Minâ€“max scaling (0â€“1)\n",
    "Maps the minimum to 0 and maximum to 1. Useful for comparability in dashboards.\n",
    "\n",
    "### 6.4 Group-wise transforms\n",
    "Standardise **within** groups (e.g., within each `Nutrient`) so each nutrientâ€™s distribution is centred and scaled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric_transforms",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trans = df.copy()\n",
    "\n",
    "# 6.1 Log transform: add epsilon to avoid log(0) if present\n",
    "eps = 1e-6\n",
    "df_trans['Value_log'] = np.log(df_trans['Value'] + eps)\n",
    "\n",
    "# 6.2 Global z-score\n",
    "mu = df_trans['Value'].mean()\n",
    "sd = df_trans['Value'].std(ddof=0)\n",
    "df_trans['Value_z'] = (df_trans['Value'] - mu) / (sd if sd else 1.0)\n",
    "\n",
    "# 6.3 Minâ€“max scaling\n",
    "vmin, vmax = df_trans['Value'].min(), df_trans['Value'].max()\n",
    "rng = vmax - vmin if vmax > vmin else 1.0\n",
    "df_trans['Value_minmax'] = (df_trans['Value'] - vmin) / rng\n",
    "\n",
    "# 6.4 Group-wise z-score by Nutrient\n",
    "df_trans['Value_z_by_nutrient'] = (\n",
    "    df_trans.groupby('Nutrient')['Value']\n",
    "           .transform(lambda s: (s - s.mean()) / (s.std(ddof=0) if s.std(ddof=0) else 1.0))\n",
    ")\n",
    "\n",
    "display(df_trans.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "density_plots_explain",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7) Density Plots â€” Visualise Transformations\n",
    "Letâ€™s visualise how the distribution changes after transformations. Weâ€™ll use **histograms with density=True** (a simple density estimate) for one nutrient (e.g., Iron). You should see that the **log transform** often makes a right-skewed distribution more symmetric, and **z-scores** centre the data at 0 with unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "density_plots",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose one nutrient to illustrate (fallback to first if Iron absent)\n",
    "nutrient_to_plot = 'Iron' if 'Iron' in df['Nutrient'].unique() else df['Nutrient'].unique()[0]\n",
    "sub = df_trans[df_trans['Nutrient'] == nutrient_to_plot].copy()\n",
    "\n",
    "print(f'Plotting distributions for nutrient: {nutrient_to_plot}')\n",
    "\n",
    "# Original scale density (histogram)\n",
    "plt.figure()\n",
    "sub['Value'].plot(kind='hist', bins=20, density=True, edgecolor='black')\n",
    "plt.title(f'{nutrient_to_plot}: Original Value (density)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Log-transformed density\n",
    "plt.figure()\n",
    "sub['Value_log'].plot(kind='hist', bins=20, density=True, edgecolor='black')\n",
    "plt.title(f'{nutrient_to_plot}: Log(Value) (density)')\n",
    "plt.xlabel('log(Value + Îµ)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Z-score density\n",
    "plt.figure()\n",
    "sub['Value_z'].plot(kind='hist', bins=20, density=True, edgecolor='black')\n",
    "plt.title(f'{nutrient_to_plot}: Z-score (density)')\n",
    "plt.xlabel('Z-score')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolling",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8) (Bonus) Time-based and Rolling Transforms\n",
    "For longitudinal data (e.g., the same `ID` measured across `Year`), compute rolling means or deltas. This is illustrative if your dataset has multiple years per ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolling_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_roll = (\n",
    "    df.sort_values(['ID','Nutrient','Year'])\n",
    "      .groupby(['ID','Nutrient'], as_index=False)\n",
    "      .apply(lambda g: g.assign(\n",
    "          Value_roll_mean=g['Value'].rolling(window=2, min_periods=1).mean(),\n",
    "          Value_delta=g['Value'].diff()\n",
    "      ))\n",
    ")\n",
    "display(df_roll.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 1 â€” Grouped Summary\n",
    "Filter to `Nutrient == 'Vitamin_D'`, then compute **median** `Value` by `Sex` and `Year`. Present the result sorted by `Year` and then `Sex`.\n",
    "\n",
    "**Hints**:\n",
    "- Filter: `df[df['Nutrient'] == 'Vitamin_D']`\n",
    "- Group and aggregate: `.groupby(['Sex','Year'])['Value'].median().reset_index()`\n",
    "- Sort: `.sort_values(['Year','Sex'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise_1_answer_here",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 2 â€” Wide â†” Long\n",
    "1) Create a **wide** table with index `[ID, Year]` and columns as nutrients (values = mean `Value`).  \n",
    "2) Convert that wide table **back to long** using `melt` with `Nutrient` and `Value` columns.\n",
    "\n",
    "**Hints**:\n",
    "- `pivot_table(index=['ID','Year'], columns='Nutrient', values='Value', aggfunc='mean')`\n",
    "- `melt(id_vars=['ID','Year'], var_name='Nutrient', value_name='Value')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise_2_answer_here",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ§ª Exercise 3 â€” Transformations for Modelling\n",
    "Create a dataframe with these new columns on the **Iron** subset only:\n",
    "- `Value_log_iron` â€” log-transformed value with epsilon.\n",
    "- `Value_z_iron_by_sex` â€” z-score **within Sex**.\n",
    "- `Value_minmax_iron_by_year` â€” minâ€“max scaling **within Year**.\n",
    "\n",
    "**Hints**:\n",
    "- Filter: `(df['Nutrient'] == 'Iron')`\n",
    "- Group-wise transforms with `.groupby(...).transform(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise_3_answer_here",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## âœ… Conclusion & Next Steps\n",
    "Youâ€™ve practised the core transformation tools:\n",
    "- Filtering and selecting for clear subsets.\n",
    "- **Aggregation** with `.groupby(...).agg(...)`, including named aggregations and why aggregation matters.\n",
    "- Reshaping between **wide** and **long** for tidy analysis.\n",
    "- Pivot tables for quick comparisons.\n",
    "- Numeric transformations: **log**, **z-score**, **minâ€“max**, and **group-wise** standardisation â€” plus **density plots** to see the changes.\n",
    "\n",
    "ðŸ‘‰ Next: **3.5 Data Aggregation** â€” robust summaries, grouped statistics, and combining pipelines for analysis-ready datasets.\n",
    "\n",
    "**Resources**:\n",
    "- Pandas GroupBy: https://pandas.pydata.org/docs/user_guide/groupby.html\n",
    "- Reshaping (melt/pivot): https://pandas.pydata.org/docs/user_guide/reshaping.html\n",
    "- Working with dtypes: https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}