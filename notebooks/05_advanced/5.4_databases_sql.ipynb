{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üóÑÔ∏è 5.4 Databases and SQL\n",
    "\n",
    "In this notebook you‚Äôll load a nutrition dataset into **SQLite**, write SQL to summarise and join tables, and round it off with **window functions** and **views**.\n",
    "\n",
    "**You will:**\n",
    "- Create a SQLite DB and load `large_food_log.csv`.\n",
    "- Define a clean **schema** (types, constraints) and add **indexes**.\n",
    "- Write core SQL (filter, group, aggregate), **joins**, and **window** functions.\n",
    "- Use **parameterised** queries from Python safely.\n",
    "- Build **views** for reusable analytics.\n",
    "\n",
    "<details><summary>Why SQL for nutrition?</summary>\n",
    "Food-logging datasets can be large and tidy. SQL lets you filter, aggregate, and join efficiently, then hand clean subsets to pandas or modelling code.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab_setup",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for Google Colab: clone the repo so we can read data\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "MODULE = '05_advanced'\n",
    "DATASET = 'large_food_log.csv'\n",
    "BASE_PATH = '/content/data-analysis-projects'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join(MODULE_PATH, 'data', DATASET)\n",
    "\n",
    "try:\n",
    "    print('Attempting to clone repository...')\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
    "    os.chdir(MODULE_PATH)\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        print(f'Dataset found: {DATASET_PATH} ‚úÖ')\n",
    "    else:\n",
    "        raise FileNotFoundError('Dataset missing after clone.')\n",
    "except Exception as e:\n",
    "    print(f'Cloning failed: {e}')\n",
    "    print('Falling back to manual upload...')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    uploaded = files.upload()\n",
    "    if DATASET in uploaded:\n",
    "        with open(os.path.join('data', DATASET), 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} ‚úÖ')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload {DATASET} to continue.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3  # stdlib ‚Äî no pip install needed\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 40)\n",
    "print('SQL environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_csv",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì• Load CSV and Inspect\n",
    "We‚Äôll parse `Date` as a proper date and peek at a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_csv",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = Path('data') / 'large_food_log.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Try to parse date if present\n",
    "\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "display(df.head())\n",
    "print('\\nDtypes:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sqlite_create",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üß± Create SQLite DB + Clean Schema\n",
    "We‚Äôll create a **typed** table instead of relying on default `to_sql` types. This is more explicit and robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_path = Path('nutrition.db')\n",
    "if db_path.exists():\n",
    "    db_path.unlink()  # start fresh for reproducibility\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Drop if exists & create schema with constraints\n",
    "cur.executescript(\n",
    "    \"\"\"\n",
    "    DROP TABLE IF EXISTS food_log;\n",
    "    CREATE TABLE food_log (\n",
    "        ID          TEXT NOT NULL,\n",
    "        Meal        TEXT NOT NULL,\n",
    "        Nutrient    TEXT NOT NULL,\n",
    "        Amount      REAL NOT NULL,\n",
    "        Date        TEXT,              -- ISO8601 string (YYYY-MM-DD)\n",
    "        CHECK (Amount >= 0)\n",
    "    );\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# Insert rows using executemany for speed and explicit typing\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    date_str = None\n",
    "    if 'Date' in df.columns and pd.notna(row['Date']):\n",
    "        # store as ISO string for SQLite (TEXT)\n",
    "        date_str = pd.to_datetime(row['Date']).date().isoformat()\n",
    "    records.append((str(row.get('ID','')), str(row.get('Meal','')),\n",
    "                    str(row.get('Nutrient','')), float(row.get('Amount',0.0)), date_str))\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO food_log (ID, Meal, Nutrient, Amount, Date) VALUES (?, ?, ?, ?, ?)\",\n",
    "    records\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# Indexes for speed (filtering/grouper columns)\n",
    "cur.executescript(\n",
    "    \"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS idx_food_log_meal ON food_log(Meal);\n",
    "    CREATE INDEX IF NOT EXISTS idx_food_log_nutrient ON food_log(Nutrient);\n",
    "    CREATE INDEX IF NOT EXISTS idx_food_log_date ON food_log(Date);\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "print('Database ready:', db_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic_sql",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üîé Core SQL Queries\n",
    "Aggregate by **Meal √ó Nutrient**, then limit to the top few rows for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_basic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT Meal, Nutrient,\n",
    "       COUNT(*)         AS n,\n",
    "       ROUND(AVG(Amount), 2) AS avg_amount,\n",
    "       ROUND(SUM(Amount), 2) AS total_amount\n",
    "FROM food_log\n",
    "GROUP BY Meal, Nutrient\n",
    "ORDER BY Meal, Nutrient\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "date_queries",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìÖ Working with Dates\n",
    "SQLite stores dates as TEXT here; we can still filter by ISO strings, or cast to date with `DATE()` where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_dates",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT Date, Nutrient, ROUND(SUM(Amount),2) AS total_amount\n",
    "FROM food_log\n",
    "WHERE Date BETWEEN '2024-01-01' AND '2024-03-31'\n",
    "GROUP BY Date, Nutrient\n",
    "ORDER BY Date ASC, Nutrient ASC\n",
    "LIMIT 12;\n",
    "\"\"\"\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joins",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üîó Joins (dim tables)\n",
    "Let‚Äôs fabricate a tiny dimension table (nutrient units) and **join** it to `food_log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_dim_table",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur.executescript(\n",
    "    \"\"\"\n",
    "    DROP TABLE IF EXISTS dim_nutrient;\n",
    "    CREATE TABLE dim_nutrient (\n",
    "        Nutrient TEXT PRIMARY KEY,\n",
    "        Unit     TEXT NOT NULL\n",
    "    );\n",
    "    INSERT INTO dim_nutrient (Nutrient, Unit) VALUES\n",
    "      ('Iron','mg'),('Calcium','mg'),('Vitamin_D','¬µg'),('Protein','g');\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT f.Meal, f.Nutrient, d.Unit,\n",
    "       ROUND(AVG(f.Amount),2) AS avg_amount\n",
    "FROM food_log f\n",
    "LEFT JOIN dim_nutrient d USING(Nutrient)\n",
    "GROUP BY f.Meal, f.Nutrient\n",
    "ORDER BY f.Meal, f.Nutrient\n",
    "LIMIT 12;\n",
    "\"\"\"\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "windows",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ü™ü Window Functions\n",
    "Rank daily totals per nutrient, and compute a rolling-like **moving average** by partition. SQLite supports window functions (3.25+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_window",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH daily AS (\n",
    "  SELECT Date, Nutrient, SUM(Amount) AS total_amount\n",
    "  FROM food_log\n",
    "  WHERE Date IS NOT NULL\n",
    "  GROUP BY Date, Nutrient\n",
    ")\n",
    "SELECT *,\n",
    "       RANK() OVER (PARTITION BY Nutrient ORDER BY total_amount DESC) AS rank_in_nutrient,\n",
    "       ROUND(AVG(total_amount) OVER (\n",
    "           PARTITION BY Nutrient ORDER BY Date\n",
    "           ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
    "       ), 2) AS moving_avg_3\n",
    "FROM daily\n",
    "ORDER BY Nutrient, Date\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "param",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üîê Parameterised Queries (safe!)\n",
    "Never build SQL strings with user input. Use **parameters** to avoid SQL injection and parsing bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "param_query",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nutrient = 'Protein'\n",
    "start, end = '2024-01-01', '2024-01-15'\n",
    "q = (\n",
    "    \"SELECT Date, SUM(Amount) AS total_amount \"\n",
    "    \"FROM food_log WHERE Nutrient = ? AND Date BETWEEN ? AND ? \"\n",
    "    \"GROUP BY Date ORDER BY Date\"\n",
    ")\n",
    "pd.read_sql_query(q, conn, params=(nutrient, start, end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "views",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üëì Views (Reusable SQL)\n",
    "Create a view for **daily nutrient totals**, then query it like a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_view",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur.executescript(\n",
    "    \"\"\"\n",
    "    DROP VIEW IF EXISTS vw_daily_nutrient_totals;\n",
    "    CREATE VIEW vw_daily_nutrient_totals AS\n",
    "    SELECT Date, Nutrient, SUM(Amount) AS total_amount\n",
    "    FROM food_log\n",
    "    WHERE Date IS NOT NULL\n",
    "    GROUP BY Date, Nutrient;\n",
    "    \"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "pd.read_sql_query(\"SELECT * FROM vw_daily_nutrient_totals ORDER BY Date, Nutrient LIMIT 10;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sanity",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üß™ Sanity Checks\n",
    "Quick PRAGMA to confirm schema and indices; and a row count for the main table.\n",
    "\n",
    "<details><summary>Show PRAGMA</summary>\n",
    "Use `PRAGMA table_info(table)` and `PRAGMA index_list(table)`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pragma",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Schema:')\n",
    "display(pd.read_sql_query(\"PRAGMA table_info(food_log);\", conn))\n",
    "print('\\nIndexes:')\n",
    "display(pd.read_sql_query(\"PRAGMA index_list(food_log);\", conn))\n",
    "print('\\nRow count:')\n",
    "display(pd.read_sql_query(\"SELECT COUNT(*) AS n FROM food_log;\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üß© Exercises\n",
    "1) **Protein by Date**  \n",
    "   Write SQL to compute **total** `Amount` for *Protein* per `Date` and show the **top 10 dates** by total.\n",
    "\n",
    "2) **Meal Mix**  \n",
    "   For each `Meal`, compute the **share** of each `Nutrient` (nutrient total / meal total) on that date. (Hint: use a CTE with totals then join.)\n",
    "\n",
    "3) **Rolling 7-day**  \n",
    "   In `vw_daily_nutrient_totals`, compute a **7-day moving average** of `total_amount` per `Nutrient` with a window function.\n",
    "\n",
    "4) **Parameterised**  \n",
    "   From Python, write a parameterised query to get *Calcium* totals between two dates supplied as variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ‚úÖ Conclusion\n",
    "You created a SQLite database, defined a clean schema with indexes, and wrote SQL to summarise, join, and rank nutrition data. You also built views and parameterised queries to keep your analyses safe and reusable.\n",
    "\n",
    "<details><summary>Further reading</summary>\n",
    "- SQLite docs: https://www.sqlite.org/docs.html  \n",
    "- SQLite window functions: https://www.sqlite.org/windowfunctions.html  \n",
    "- pandas + SQL: https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}