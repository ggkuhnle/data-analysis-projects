{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# ü©∫ 4.7 Analysing a Simulated Clinical Trial\n",
        "\n",
        "In this notebook, we‚Äôll analyse a **simulated randomised clinical trial**‚Äîa common design in nutrition research to estimate causal effects.\n",
        "\n",
        "You will:\n",
        "- Simulate a trial with **randomisation**, baseline covariates, **adherence**, and **missingness**\n",
        "- Produce a **CONSORT-like flow** and a **Table 1** (with **standardised mean differences**, SMD)\n",
        "- Visualise distributions and balance (hist/KDE, **love plot**)\n",
        "- Estimate treatment effects: **Welch t-test**, **Mann‚ÄìWhitney**, **permutation test**, **Cohen‚Äôs d / Hedges‚Äô g**, **bootstrap CIs**\n",
        "- Adjust via **ANCOVA** (post ~ group + baseline + covariates) with robust SEs\n",
        "- Fit a **Bayesian ANCOVA** (PyMC) with posterior, HDIs, posterior predictive checks\n",
        "- Contrast **Intention-to-Treat (ITT)** vs **Per-Protocol (PP)**\n",
        "\n",
        "<details><summary>Why these pieces?</summary>\n",
        "- **SMDs** give scale-free balance checks after randomisation.\n",
        "- **ANCOVA** increases precision by adjusting for baseline.\n",
        "- **Permutation** & **bootstrap** add robustness when assumptions are shaky.\n",
        "- **Bayesian** analysis communicates uncertainty with posteriors & probabilities.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup_installs",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pandas numpy scipy statsmodels seaborn matplotlib pymc arviz scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.utils import resample\n",
        "import pymc as pm, arviz as az\n",
        "sns.set_theme()\n",
        "pd.set_option('display.max_columns', 60)\n",
        "rng = np.random.default_rng(42)\n",
        "print('Environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "simulate_title",
      "metadata": {},
      "source": [
        "## üß™ Step 1: Simulate the Trial\n",
        "\n",
        "We create a parallel-group RCT (1:1) with baseline **age**, **BMI**, **baseline outcome** `y0`, and **post outcome** `y1`. Treatment improves `y1` by ~1 unit on average; outcomes also depend on age/BMI. We add **adherence** and **missingness** to make it realistic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "simulate",
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 200\n",
        "ids = np.arange(1, n+1)\n",
        "group = rng.integers(0, 2, size=n)  # 0=Control, 1=Intervention\n",
        "\n",
        "# Baseline covariates\n",
        "age = rng.normal(45, 11, size=n)\n",
        "bmi = rng.normal(27, 4, size=n)\n",
        "\n",
        "# Baseline outcome (y0)\n",
        "y0 = rng.normal(0, 2, size=n)\n",
        "\n",
        "# Adherence (only matters in treatment); ~80% adherent if treated, 98% if control (placebo adherence)\n",
        "adherent = np.where(group==1, rng.random(n) < 0.80, rng.random(n) < 0.98).astype(int)\n",
        "\n",
        "# Treatment effect (on adherers), plus covariate drift and noise\n",
        "true_effect = 1.0\n",
        "mu = (0\n",
        "      + group * adherent * true_effect\n",
        "      + 0.15*y0  # regression to mean / persistence\n",
        "      + 0.01*(age-45)\n",
        "      + 0.03*(bmi-27))\n",
        "y1 = mu + rng.normal(0, 2.0, size=n)\n",
        "\n",
        "# Missingness: MCAR 5% on y1; slightly higher missing if non-adherent\n",
        "miss_base = 0.05\n",
        "miss_extra = np.where(adherent==0, 0.05, 0.0)\n",
        "mask_miss = rng.random(n) < (miss_base + miss_extra)\n",
        "y1_obs = y1.copy()\n",
        "y1_obs[mask_miss] = np.nan\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'participant_id': ids,\n",
        "    'group': group,                      # 0=Control, 1=Intervention\n",
        "    'adherent': adherent,                # 1=yes\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'y0': y0,                            # baseline\n",
        "    'y1': y1_obs                         # post (observed)\n",
        "})\n",
        "\n",
        "df['group_label'] = df['group'].map({0:'Control', 1:'Intervention'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "consort",
      "metadata": {},
      "source": [
        "## üßæ Step 1b: CONSORT-like Flow\n",
        "Counts at each stage help detect imbalance or data issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "consort_counts",
      "metadata": {},
      "outputs": [],
      "source": [
        "consort = {\n",
        "    'Randomised (N)': [len(df)],\n",
        "    'Allocated Control (N)': [(df['group']==0).sum()],\n",
        "    'Allocated Intervention (N)': [(df['group']==1).sum()],\n",
        "    'Adherent Control (N)': [((df['group']==0)&(df['adherent']==1)).sum()],\n",
        "    'Adherent Intervention (N)': [((df['group']==1)&(df['adherent']==1)).sum()],\n",
        "    'Observed y1 Control (N)': [((df['group']==0)&(df['y1'].notna())).sum()],\n",
        "    'Observed y1 Intervention (N)': [((df['group']==1)&(df['y1'].notna())).sum()],\n",
        "}\n",
        "pd.DataFrame(consort)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "table1_title",
      "metadata": {},
      "source": [
        "## üìã Step 2: Baseline Table (Table 1) with SMD\n",
        "\n",
        "**SMD (standardised mean difference)** is a scale-free balance metric (|SMD| < 0.1 is often considered negligible)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "table1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def smd_cont(x0, x1):\n",
        "    # Pooled SD\n",
        "    s2 = (np.nanvar(x0, ddof=1) + np.nanvar(x1, ddof=1))/2\n",
        "    return (np.nanmean(x1) - np.nanmean(x0)) / np.sqrt(s2) if s2>0 else np.nan\n",
        "\n",
        "vars_cont = ['age','bmi','y0']\n",
        "tbl = []\n",
        "for v in vars_cont:\n",
        "    x0 = df.loc[df['group']==0, v]\n",
        "    x1 = df.loc[df['group']==1, v]\n",
        "    row = {\n",
        "        'Variable': v,\n",
        "        'Control_mean': np.nanmean(x0),\n",
        "        'Control_sd': np.nanstd(x0, ddof=1),\n",
        "        'Intervention_mean': np.nanmean(x1),\n",
        "        'Intervention_sd': np.nanstd(x1, ddof=1),\n",
        "        'SMD': smd_cont(x0, x1)\n",
        "    }\n",
        "    tbl.append(row)\n",
        "table1 = pd.DataFrame(tbl)\n",
        "table1.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loveplot_title",
      "metadata": {},
      "source": [
        "### Love plot (SMDs)\n",
        "Visual balance check across baseline covariates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loveplot",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "order = table1.sort_values('SMD', key=lambda s: s.abs())\n",
        "plt.hlines(order['Variable'], xmin=0, xmax=order['SMD'])\n",
        "plt.plot(order['SMD'], order['Variable'], 'o')\n",
        "plt.axvline(0, ls='--', alpha=.5)\n",
        "plt.axvline(0.1, ls=':', alpha=.5, color='grey'); plt.axvline(-0.1, ls=':', alpha=.5, color='grey')\n",
        "plt.title('Standardised Mean Differences (baseline)')\n",
        "plt.xlabel('SMD'); plt.ylabel('')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "viz_title",
      "metadata": {},
      "source": [
        "## üìà Step 3: Visualise Outcomes\n",
        "We inspect **post** outcome (`y1`) and **change** (`y1 - y0`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['change'] = df['y1'] - df['y0']\n",
        "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
        "sns.histplot(data=df, x='y1', hue='group_label', kde=True, element='step', stat='density', common_norm=False, ax=axes[0])\n",
        "axes[0].set_title('Post outcome (y1)'); axes[0].set_xlabel('y1')\n",
        "sns.histplot(data=df, x='change', hue='group_label', kde=True, element='step', stat='density', common_norm=False, ax=axes[1])\n",
        "axes[1].set_title('Change (y1 - y0)'); axes[1].set_xlabel('change')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "estimators_title",
      "metadata": {},
      "source": [
        "## üìè Step 4: Frequentist Estimators (Unadjusted)\n",
        "\n",
        "Primary ITT analysis uses everyone with observed `y1` in their assigned group.\n",
        "\n",
        "- **Welch t-test** for mean difference (robust to unequal variances)\n",
        "- **Cohen‚Äôs d / Hedges‚Äô g** for effect size\n",
        "- **Mann‚ÄìWhitney U** and **Cliff‚Äôs delta** (non-parametric)\n",
        "- **Permutation test** (exact/randomisation-based inference)\n",
        "- **Bootstrap 95% CI** for mean difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "estimators",
      "metadata": {},
      "outputs": [],
      "source": [
        "itt = df.dropna(subset=['y1']).copy()\n",
        "y0_ = itt.loc[itt['group']==0, 'y1']\n",
        "y1_ = itt.loc[itt['group']==1, 'y1']\n",
        "mean_diff = y1_.mean() - y0_.mean()\n",
        "\n",
        "# Welch t-test\n",
        "t_w, p_w = stats.ttest_ind(y1_, y0_, equal_var=False)\n",
        "\n",
        "# Cohen's d and Hedges' g\n",
        "sd_pooled = np.sqrt(((y0_.var(ddof=1) + y1_.var(ddof=1))/2))\n",
        "cohen_d = (y1_.mean() - y0_.mean()) / sd_pooled\n",
        "J = 1 - 3/(4*(len(itt))-9)  # small sample correction\n",
        "hedges_g = J * cohen_d\n",
        "\n",
        "# Mann‚ÄìWhitney + Cliff's delta\n",
        "u, p_u = stats.mannwhitneyu(y1_, y0_, alternative='two-sided')\n",
        "def cliffs_delta(a, b):\n",
        "    a, b = np.asarray(a), np.asarray(b)\n",
        "    diffs = a.reshape(-1,1) - b.reshape(1,-1)\n",
        "    return (np.sum(diffs>0) - np.sum(diffs<0)) / (a.size*b.size)\n",
        "delta = cliffs_delta(y1_, y0_)\n",
        "\n",
        "# Permutation (difference in means)\n",
        "def perm_test(a, b, reps=2000, rng=rng):\n",
        "    obs = a.mean() - b.mean()\n",
        "    comb = np.concatenate([a,b])\n",
        "    n_a = len(a)\n",
        "    cnt = 0\n",
        "    for _ in range(reps):\n",
        "        rng.shuffle(comb)\n",
        "        da, db = comb[:n_a], comb[n_a:]\n",
        "        if abs(da.mean()-db.mean()) >= abs(obs):\n",
        "            cnt += 1\n",
        "    return obs, (cnt/reps)\n",
        "perm_diff, p_perm = perm_test(y1_.values.copy(), y0_.values.copy())\n",
        "\n",
        "# Bootstrap CI for mean difference\n",
        "def bootstrap_mean_diff(a, b, reps=5000, rng=rng):\n",
        "    diffs = np.empty(reps)\n",
        "    for i in range(reps):\n",
        "        da = resample(a, replace=True, random_state=rng.integers(0, 1e9))\n",
        "        db = resample(b, replace=True, random_state=rng.integers(0, 1e9))\n",
        "        diffs[i] = da.mean() - db.mean()\n",
        "    return np.quantile(diffs, [0.025, 0.975])\n",
        "ci_boot = bootstrap_mean_diff(y1_.values, y0_.values)\n",
        "\n",
        "print(f\"Mean difference (y1): {mean_diff:.2f}\")\n",
        "print(f\"Welch t: t={t_w:.2f}, p={p_w:.3f}\")\n",
        "print(f\"Cohen's d: {cohen_d:.2f}, Hedges' g: {hedges_g:.2f}\")\n",
        "print(f\"Mann‚ÄìWhitney U p={p_u:.3f}, Cliff's delta={delta:.2f}\")\n",
        "print(f\"Permutation p={p_perm:.3f}\")\n",
        "print(f\"Bootstrap 95% CI for mean diff: [{ci_boot[0]:.2f}, {ci_boot[1]:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ancova_title",
      "metadata": {},
      "source": [
        "## üßÆ Step 5: ANCOVA (Adjusted Analysis)\n",
        "Model **post outcome** with baseline and covariates: `y1 ~ group + y0 + age + bmi`.\n",
        "\n",
        "<details><summary>Why ANCOVA?</summary>\n",
        "Adjusting for baseline often yields tighter CIs (more power) under correct specification and preserves unbiasedness in RCTs.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ancova",
      "metadata": {},
      "outputs": [],
      "source": [
        "ancova_df = itt.copy()\n",
        "ancova_df['group'] = ancova_df['group'].astype(int)\n",
        "fit = smf.ols('y1 ~ group + y0 + age + bmi', data=ancova_df).fit(cov_type='HC3')\n",
        "print(fit.summary())\n",
        "coef = fit.params['group']\n",
        "ci = fit.conf_int().loc['group'].values\n",
        "print(f\"\\nAdjusted effect (group=Intervention vs Control): {coef:.2f}  CI95% [{ci[0]:.2f}, {ci[1]:.2f}] (HC3)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "itt_pp_title",
      "metadata": {},
      "source": [
        "## üîÅ Step 6: ITT vs Per-Protocol\n",
        "- **ITT**: analyse by assigned group regardless of adherence (primary)\n",
        "- **PP**: restrict to adherent participants (sensitivity)\n",
        "<details><summary>Caution</summary>\n",
        "PP can be biased if adherence relates to prognosis; use as a sensitivity check, not the main analysis.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "itt_pp",
      "metadata": {},
      "outputs": [],
      "source": [
        "pp = itt.query('adherent==1')\n",
        "y0_pp = pp.loc[pp['group']==0,'y1']; y1_pp = pp.loc[pp['group']==1,'y1']\n",
        "mean_diff_pp = y1_pp.mean() - y0_pp.mean()\n",
        "print(f\"ITT mean diff (y1): {mean_diff:.2f}\")\n",
        "print(f\"PP  mean diff (y1): {mean_diff_pp:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bayes_title",
      "metadata": {},
      "source": [
        "## üß† Step 7: Bayesian ANCOVA\n",
        "Model:  \n",
        "`y1 ~ Normal(mu, sigma)`  with  \n",
        "`mu = Œ± + Œ≤_group*group + Œ≤0*y0 + Œ≤_age*age + Œ≤_bmi*bmi`.\n",
        "\n",
        "We report the posterior for `Œ≤_group` (treatment effect), 95% **HDI**, and posterior probability `P(Œ≤_group > 0)`.\n",
        "\n",
        "<details><summary>Notes</summary>\n",
        "- Weakly-informative priors keep estimates stable while remaining non-committal.\n",
        "- Posterior predictive checks assess fit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bayes_model",
      "metadata": {},
      "outputs": [],
      "source": [
        "bdf = ancova_df.dropna(subset=['y1','y0','age','bmi']).copy()\n",
        "with pm.Model() as m:\n",
        "    alpha = pm.Normal('alpha', 0, 10)\n",
        "    b_group = pm.Normal('b_group', 0, 5)\n",
        "    b_y0 = pm.Normal('b_y0', 0, 2)\n",
        "    b_age = pm.Normal('b_age', 0, 0.1)\n",
        "    b_bmi = pm.Normal('b_bmi', 0, 0.2)\n",
        "    sigma = pm.HalfNormal('sigma', 2)\n",
        "    mu = (alpha\n",
        "          + b_group * bdf['group'].values\n",
        "          + b_y0 * bdf['y0'].values\n",
        "          + b_age * (bdf['age'].values-45)\n",
        "          + b_bmi * (bdf['bmi'].values-27))\n",
        "    y = pm.Normal('y', mu=mu, sigma=sigma, observed=bdf['y1'].values)\n",
        "    trace = pm.sample(1500, tune=1500, target_accept=0.9, random_seed=42, chains=2, cores=2, progressbar=True, return_inferencedata=True)\n",
        "    ppc = pm.sample_posterior_predictive(trace, model=m, random_seed=42)\n",
        "\n",
        "az.plot_posterior(trace, var_names=['b_group'], ref_val=0);\n",
        "plt.title('Posterior: treatment effect (Œ≤_group)'); plt.show()\n",
        "\n",
        "bg = trace.posterior['b_group'].values.flatten()\n",
        "hdi = az.hdi(bg, hdi_prob=0.95)\n",
        "print(f\"Posterior mean (Œ≤_group): {bg.mean():.2f} | 95% HDI [{hdi[0]:.2f}, {hdi[1]:.2f}]\")\n",
        "print(f\"P(Œ≤_group>0): {(bg>0).mean():.3f}\")\n",
        "\n",
        "# Posterior predictive check\n",
        "idata_ppc = az.from_pymc(posterior_predictive=ppc, model=m)\n",
        "az.plot_ppc(idata_ppc, num_pp_samples=200);\n",
        "plt.title('Posterior predictive check'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## üîÅ Optional Exercises\n",
        "1. **Stratified effects**: Add an interaction `group √ó (age>50)` in ANCOVA‚Äîdoes the effect differ by age strata?\n",
        "2. **Equivalence**: Define a ROPE (e.g., ¬±0.25 units) and compute `P(|Œ≤_group| < 0.25)` from the posterior.\n",
        "3. **Imputation**: Mean-impute missing `y1` *within group* and re-run ITT Welch test‚Äîhow do results shift?\n",
        "4. **Power (bonus)**: Loop over `n` to find sample size achieving ~80% power for Welch t-test given the simulated SD and effect.\n",
        "\n",
        "<details><summary>Hints</summary>\n",
        "- Interaction in OLS: `y1 ~ group*I(age>50) + y0 + age + bmi`\n",
        "- ROPE prob: `np.mean(np.abs(bg) < 0.25)`\n",
        "- Simple impute: `df.groupby('group')['y1'].transform(lambda s: s.fillna(s.mean()))`\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary\n",
        "You:\n",
        "- Simulated an RCT with realistic wrinkles (adherence, missingness)\n",
        "- Assessed baseline balance (SMDs) and visualised distributions\n",
        "- Estimated treatment effects with robust frequentist tools (Welch, MWU, permutation, bootstrap) and **ANCOVA**\n",
        "- Ran a **Bayesian ANCOVA**, reporting posteriors and predictive checks\n",
        "- Compared **ITT** and **PP**\n",
        "\n",
        "‚û°Ô∏è This workflow mirrors real trial analysis: pre-specify ITT primary, show adjusted analysis, and include sensitivity checks.\n",
        "\n",
        "<details><summary>Further reading</summary>\n",
        "- CONSORT: Randomised trials reporting\n",
        "- Senn S. *Statistical Issues in Drug Development* (ANCOVA in RCTs)\n",
        "- Gelman et al. *Bayesian Data Analysis* (posterior predictive checks)\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
