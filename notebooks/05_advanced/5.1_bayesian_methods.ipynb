{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# \ud83d\udcca 5.1 Bayesian Inference\n",
        "\n",
        "This notebook introduces Bayesian inference for analysing nutrient intakes, a robust method for nutrition research, such as NDNS studies. Bayesian methods integrate prior knowledge with observed data to estimate parameters with uncertainty.\n",
        "\n",
        "**Objectives**:\n",
        "- Understand Bayesian principles: priors, likelihoods, and posteriors.\n",
        "- Apply PyMC to model nutrient intake data.\n",
        "- Visualise and interpret posterior distributions.\n",
        "\n",
        "**Context**: Bayesian approaches are valuable for small datasets or when prior information (e.g., Recommended Dietary Allowances) is available. We will model iron intakes using `hippo_nutrients.csv`.\n",
        "\n",
        "<details>\n",
        "<summary>Advanced Note</summary>\n",
        "Bayesian methods offer advantages over frequentist approaches (covered in 4.4) for handling uncertainty.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Fun Fact</summary>\n",
        "Tracking nutrients is like a hippo logging its daily diet\u2014precision matters! \ud83e\udd9b\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Google Colab: Fetch datasets automatically or manually\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the module and dataset for this notebook\n",
        "MODULE = '05_advanced'\n",
        "DATASET = 'large_food_log.csv'\n",
        "DATASET_PATH = os.path.join('data', DATASET)\n",
        "\n",
        "# Step 1: Attempt to clone the repository (automatic method)\n",
        "try:\n",
        "    print('Attempting to clone repository...')\n",
        "    !git clone https://github.com/ggkuhnle/data-analysis-toolkit-FNS.git\n",
        "    os.chdir(f'/content/data-analysis-toolkit-FNS/notebooks/{MODULE}')\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f'Dataset found: {DATASET_PATH} \ud83e\udd9b')\n",
        "    else:\n",
        "        print(f'Error: Dataset {DATASET} not found after cloning.')\n",
        "        raise FileNotFoundError\n",
        "except Exception as e:\n",
        "    print(f'Cloning failed: {e}')\n",
        "    print('Falling back to manual upload option...')\n",
        "\n",
        "    # Step 2: Manual upload option\n",
        "    print(f'Please upload {DATASET} manually.')\n",
        "    print(f'1. Click the \"Choose Files\" button below.')\n",
        "    print(f'2. Select {DATASET} from your local machine.')\n",
        "    print(f'3. Ensure the file is placed in notebooks/{MODULE}/data/')\n",
        "    \n",
        "    # Create the data directory if it doesn't exist\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    \n",
        "    # Prompt user to upload the dataset\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Check if the dataset was uploaded\n",
        "    if DATASET in uploaded:\n",
        "        with open(DATASET_PATH, 'wb') as f:\n",
        "            f.write(uploaded[DATASET])\n",
        "        print(f'Successfully uploaded {DATASET} to {DATASET_PATH} \ud83e\udd9b')\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
        "\n",
        "# Install required packages for this notebook\n",
        "%pip install pandas numpy\n",
        "print('Python environment ready.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install pymc pandas numpy matplotlib arviz  # For Colab users\n",
        "import pymc as pm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "print('Bayesian analysis environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {},
      "source": [
        "## Data Preparation\n",
        "\n",
        "The `hippo_nutrients.csv` dataset contains simulated nutrient intakes, inspired by NDNS. We will extract iron data for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "load",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID Nutrient  Year  Value  Age Sex\n",
            "0  H1     Iron  2024    8.2   25   F\n",
            "1  H1     Iron  2025    8.5   26   F\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../data_handling/data/hippo_nutrients.csv')\n",
        "iron_data = df[df['Nutrient'] == 'Iron']['Value'].dropna()\n",
        "print(df.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bayesian",
      "metadata": {},
      "source": [
        "## Bayesian Model\n",
        "\n",
        "We model iron intake as a normal distribution with a prior mean of 8 mg (based on RDA). The model estimates the mean (`mu`) and standard deviation (`sigma`).\n",
        "\n",
        "**Exercise 1**: Run the model to estimate iron intake parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "model",
      "metadata": {},
      "outputs": [],
      "source": [
        "with pm.Model() as model:\n",
        "    mu = pm.Normal('mu', mu=8, sigma=2)  # Prior: mean ~ N(8, 2)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=1)  # Prior: std dev\n",
        "    obs = pm.Normal('obs', mu=mu, sigma=sigma, observed=iron_data)\n",
        "    trace = pm.sample(1000, return_inferencedata=True)\n",
        "\n",
        "# Visualise posterior distributions\n",
        "az.plot_posterior(trace, var_names=['mu', 'sigma'], hdi_prob=0.95)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Parameter Summary\n",
        "\n",
        "The table below summarizes the estimated parameters, including the mean and 95% highest density interval (HDI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "summary_table",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Mean  95% HDI Lower  95% HDI Upper\n",
            "mu      8.3           7.8           8.8\n",
            "sigma   1.1           0.9           1.3\n"
          ]
        }
      ],
      "source": [
        "summary = az.summary(trace, var_names=['mu', 'sigma'], hdi_prob=0.95)\n",
        "print(summary[['mean', 'hdi_2.5%', 'hdi_97.5%']].rename(columns={'mean': 'Mean', 'hdi_2.5%': '95% HDI Lower', 'hdi_97.5%': '95% HDI Upper'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercise",
      "metadata": {},
      "source": [
        "## Exercise 2: Interpret Results\n",
        "\n",
        "Examine the posterior plots and table. Document the estimated mean iron intake and its 95% HDI in a Markdown cell.\n",
        "\n",
        "**Guidance**: Use the plot\u2019s peak and HDI bounds to describe uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "your_answer",
      "metadata": {},
      "source": [
        "**Answer**:\n",
        "\n",
        "The estimated mean iron intake is approximately..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated Bayesian inference using PyMC to estimate nutrient intakes with uncertainty. You have learned:\n",
        "- Specifying priors and likelihoods.\n",
        "- Modelling and visualising posteriors.\n",
        "- Interpreting parameter estimates for nutrition research.\n",
        "\n",
        "**Next Steps**: Explore workflow automation in 5.2.\n",
        "\n",
        "**Resources**:\n",
        "- [PyMC Documentation](https://www.pymc.io/)\n",
        "- [Bayesian Methods for Nutrition](https://statswithr.com/book/bayesian-basics.html)\n",
        "- Repository: [github.com/ggkuhnle/data-analysis-toolkit-FNS](https://github.com/ggkuhnle/data-analysis-toolkit-FNS)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}