{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728eead0",
   "metadata": {},
   "source": [
    "# Handling Missing Data in Nutrition Science \n",
    "\n",
    "üß©üìäWelcome to this Jupyter notebook on handling missing data in nutrition science! Missing data is a common challenge in epidemiological studies, especially in nutrition research where variables like dietary intake or biomarkers may be incomplete. In this mini-project, we‚Äôll use the epidemiological dataset from our previous work (n=25,000, age range 45-80) to explore and address missing data.We‚Äôll:\n",
    "\n",
    "- **Explore missing data patterns** to understand their extent and impact üïµÔ∏è\n",
    "- **Apply common techniques**: listwise deletion, mean/mode imputation, multiple imputation, and a Bayesian approach üåê\n",
    "- **Compare their impact** on a simple analysis (linear regression for baseline BMI) üìàLet‚Äôs dive in and learn how to handle missing data effectively in nutrition science!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4143c1",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset and Libraries üì¶\n",
    "\n",
    "Let‚Äôs load the epidemiological dataset and the libraries we‚Äôll need for this analysis. The dataset includes variables like age, sex, smoking, physical activity, social class, BMI, blood pressure, sugar intake, SFA intake, and CVD incidence, with ~8% missing data per variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ad977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "# Set seaborn style for clean visuals\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data/epidemiological_study.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a100e6c",
   "metadata": {},
   "source": [
    "## Step 2: Explore Missing Data Patterns üîé\n",
    "\n",
    "Let‚Äôs start by examining the extent and patterns of missing data in our dataset. This will help us understand which variables are most affected and whether the missingness appears random or systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of missing data for each variable\n",
    "missing_data = data.isna().mean() * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing (%)': missing_data.round(2)\n",
    "})\n",
    "\n",
    "# Display missing data summary\n",
    "print(\"Missing Data Summary:\")\n",
    "print(missing_summary[missing_summary['Missing (%)'] > 0])\n",
    "\n",
    "# Visualize missing data patterns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.isna(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data Patterns (Yellow = Missing) üìâ')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Participants')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34372e49",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Data for Analysis üõ†Ô∏è\n",
    "\n",
    "We‚Äôll prepare the data for a simple analysis: predicting baseline BMI using age, sex, smoking, physical activity, social class, sugar intake, and SFA intake. First, we need to encode categorical variables and select the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for analysis\n",
    "analysis_data = data[['BMI_Baseline', 'Age', 'Sex', 'Smoking', 'Physical_Activity', 'Social_Class', 'Sugar_Intake', 'SFA_Intake']].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "analysis_data['Sex'] = le.fit_transform(analysis_data['Sex'].astype(str))\n",
    "analysis_data['Smoking'] = le.fit_transform(analysis_data['Smoking'].astype(str))\n",
    "analysis_data['Physical_Activity'] = analysis_data['Physical_Activity'].map({'Low': 0, 'Medium': 1, 'High': 2, np.nan: 0})\n",
    "analysis_data['Social_Class'] = analysis_data['Social_Class'].map({'A': 1, 'B': 2, 'C1': 3, 'C2': 4, 'D': 5, 'E': 6, np.nan: 3})\n",
    "\n",
    "# Define predictors and outcome\n",
    "X = analysis_data.drop('BMI_Baseline', axis=1)\n",
    "y = analysis_data['BMI_Baseline']\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd0e23",
   "metadata": {},
   "source": [
    "## Step 4: Technique 1 - Listwise Deletion üöÆ\n",
    "\n",
    "The simplest approach to handling missing data is **listwise deletion**, where we remove any row with at least one missing value. This method is easy but can lead to loss of data and potential bias if the missingness is not completely random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply listwise deletion\n",
    "X_listwise = X.dropna()\n",
    "y_listwise = y[X_listwise.index]\n",
    "\n",
    "# Check the number of rows remaining\n",
    "print(f\"Original dataset size: {X.shape[0]} rows\")\n",
    "print(f\"After listwise deletion: {X_listwise.shape[0]} rows\")\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_listwise = LinearRegression()\n",
    "model_listwise.fit(X_listwise, y_listwise)\n",
    "\n",
    "# Display coefficients\n",
    "coeffs_listwise = pd.DataFrame({\n",
    "    'Predictor': X_listwise.columns,\n",
    "    'Coefficient': model_listwise.coef_\n",
    "})\n",
    "print(\"\\nLinear Regression Results (Listwise Deletion):\")\n",
    "print(coeffs_listwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136efbe",
   "metadata": {},
   "source": [
    "## Step 5: Technique 2 - Mean/Mode Imputation üìè\n",
    "\n",
    "Another common method is **mean/mode imputation**, where we replace missing values with the mean (for numerical variables) or mode (for categorical variables). This preserves the sample size but can underestimate variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data for mean/mode imputation\n",
    "X_mean_mode = X.copy()\n",
    "\n",
    "# Impute numerical variables with mean\n",
    "numerical_vars = ['Age', 'Sugar_Intake', 'SFA_Intake']\n",
    "X_mean_mode[numerical_vars] = X_mean_mode[numerical_vars].fillna(X_mean_mode[numerical_vars].mean())\n",
    "\n",
    "# Impute categorical variables with mode\n",
    "categorical_vars = ['Sex', 'Smoking', 'Physical_Activity', 'Social_Class']\n",
    "X_mean_mode[categorical_vars] = X_mean_mode[categorical_vars].fillna(X_mean_mode[categorical_vars].mode().iloc[0])\n",
    "\n",
    "# Impute the outcome variable (BMI_Baseline)\n",
    "y_mean_mode = y.fillna(y.mean())\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_mean_mode = LinearRegression()\n",
    "model_mean_mode.fit(X_mean_mode, y_mean_mode)\n",
    "\n",
    "# Display coefficients\n",
    "coeffs_mean_mode = pd.DataFrame({\n",
    "    'Predictor': X_mean_mode.columns,\n",
    "    'Coefficient': model_mean_mode.coef_\n",
    "})\n",
    "print(\"Linear Regression Results (Mean/Mode Imputation):\")\n",
    "print(coeffs_mean_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0915c",
   "metadata": {},
   "source": [
    "## Step 6: Technique 3 - Multiple Imputation üîÑ\n",
    "\n",
    "A more sophisticated approach is **multiple imputation**, which creates multiple plausible datasets by imputing missing values, then combines the results. We‚Äôll use `IterativeImputer` from scikit-learn, which models each variable with missing values as a function of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictors and outcome for imputation\n",
    "combined_data = X.copy()\n",
    "combined_data['BMI_Baseline'] = y\n",
    "\n",
    "# Apply multiple imputation\n",
    "imputer = IterativeImputer(max_iter=10, random_state=11088)\n",
    "imputed_data = pd.DataFrame(imputer.fit_transform(combined_data), columns=combined_data.columns)\n",
    "\n",
    "# Separate predictors and outcome after imputation\n",
    "X_multiple = imputed_data.drop('BMI_Baseline', axis=1)\n",
    "y_multiple = imputed_data['BMI_Baseline']\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_multiple = LinearRegression()\n",
    "model_multiple.fit(X_multiple, y_multiple)\n",
    "\n",
    "# Display coefficients\n",
    "coeffs_multiple = pd.DataFrame({\n",
    "    'Predictor': X_multiple.columns,\n",
    "    'Coefficient': model_multiple.coef_\n",
    "})\n",
    "print(\"Linear Regression Results (Multiple Imputation):\")\n",
    "print(coeffs_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756dc39b",
   "metadata": {},
   "source": [
    "## Step 7: Technique 4 - Bayesian Imputation üåê\n",
    "\n",
    "Finally, let‚Äôs use a **Bayesian approach** to impute missing data. We‚Äôll model the data with PyMC, treating missing values as parameters to be estimated, and then use the imputed dataset for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55648a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data for Bayesian imputation\n",
    "X_bayesian = X.copy()\n",
    "y_bayesian = y.copy()\n",
    "\n",
    "# Identify missing values\n",
    "missing_mask_X = X_bayesian.isna()\n",
    "missing_mask_y = y_bayesian.isna()\n",
    "\n",
    "# Bayesian imputation model\n",
    "with pm.Model() as bayesian_imputation:\n",
    "    # Priors for observed data means\n",
    "    mu_age = pm.Normal('mu_age', mu=60, sigma=10)\n",
    "    mu_sugar = pm.Normal('mu_sugar', mu=50, sigma=10)\n",
    "    mu_sfa = pm.Normal('mu_sfa', mu=30, sigma=10)\n",
    "    mu_bmi = pm.Normal('mu_bmi', mu=27, sigma=5)\n",
    "\n",
    "    # Priors for standard deviations\n",
    "    sigma_age = pm.HalfNormal('sigma_age', sigma=5)\n",
    "    sigma_sugar = pm.HalfNormal('sigma_sugar', sigma=5)\n",
    "    sigma_sfa = pm.HalfNormal('sigma_sfa', sigma=5)\n",
    "    sigma_bmi = pm.HalfNormal('sigma_bmi', sigma=2)\n",
    "\n",
    "    # Impute missing numerical variables\n",
    "    age_imputed = pm.Normal('age_imputed', mu=mu_age, sigma=sigma_age, shape=X_bayesian.shape[0], observed=X_bayesian['Age'])\n",
    "    sugar_imputed = pm.Normal('sugar_imputed', mu=mu_sugar, sigma=sigma_sugar, shape=X_bayesian.shape[0], observed=X_bayesian['Sugar_Intake'])\n",
    "    sfa_imputed = pm.Normal('sfa_imputed', mu=mu_sfa, sigma=sigma_sfa, shape=X_bayesian.shape[0], observed=X_bayesian['SFA_Intake'])\n",
    "    bmi_imputed = pm.Normal('bmi_imputed', mu=mu_bmi, sigma=sigma_bmi, shape=y_bayesian.shape[0], observed=y_bayesian)\n",
    "\n",
    "    # Sample from posterior\n",
    "    trace = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
    "\n",
    "# Extract imputed values (use the mean of the posterior samples)\n",
    "X_bayesian['Age'] = trace.posterior['age_imputed'].mean(dim=['chain', 'draw']).values\n",
    "X_bayesian['Sugar_Intake'] = trace.posterior['sugar_imputed'].mean(dim=['chain', 'draw']).values\n",
    "X_bayesian['SFA_Intake'] = trace.posterior['sfa_imputed'].mean(dim=['chain', 'draw']).values\n",
    "y_bayesian = trace.posterior['bmi_imputed'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# For categorical variables, use mode imputation (already handled during preparation)\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_bayesian = LinearRegression()\n",
    "model_bayesian.fit(X_bayesian, y_bayesian)\n",
    "\n",
    "# Display coefficients\n",
    "coeffs_bayesian = pd.DataFrame({\n",
    "    'Predictor': X_bayesian.columns,\n",
    "    'Coefficient': model_bayesian.coef_\n",
    "})\n",
    "print(\"Linear Regression Results (Bayesian Imputation):\")\n",
    "print(coeffs_bayesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2fbf1f",
   "metadata": {},
   "source": [
    "## Step 8: Compare the Results üîç\n",
    "\n",
    "Let‚Äôs compare the regression coefficients from each method to see how the choice of imputation technique affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine coefficients from all methods\n",
    "comparison = pd.DataFrame({\n",
    "    'Predictor': X.columns,\n",
    "    'Listwise Deletion': coeffs_listwise['Coefficient'],\n",
    "    'Mean/Mode Imputation': coeffs_mean_mode['Coefficient'],\n",
    "    'Multiple Imputation': coeffs_multiple['Coefficient'],\n",
    "    'Bayesian Imputation': coeffs_bayesian['Coefficient']\n",
    "})\n",
    "\n",
    "# Display the comparison\n",
    "print(\"Comparison of Regression Coefficients Across Methods:\")\n",
    "print(comparison)\n",
    "\n",
    "# Visualize the comparison\n",
    "comparison.set_index('Predictor').plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Comparison of Regression Coefficients by Imputation Method üìä')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xlabel('Predictor')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c4cfd",
   "metadata": {},
   "source": [
    "## Step 9: Learning Points and Next Steps üéì\n",
    "\n",
    "### Learning Points\n",
    "\n",
    "- **Missing Data Patterns**: Visualizing and quantifying missing data helps us understand its extent and potential bias. In our dataset, ~8% of values were missing per variable, distributed randomly\n",
    "- **Listwise Deletion**: Simple but reduces sample size (e.g., from 25,000 to fewer rows), potentially introducing bias if missingness is not completely random.\n",
    "- **Mean/Mode Imputation**: Preserves sample size but underestimates variability, which can lead to overly confident estimates.\n",
    "- **Multiple Imputation**: A more robust method that accounts for uncertainty by creating multiple datasets, often yielding more reliable results.\n",
    "- **Bayesian Imputation**: Treats missing values as parameters, providing a probabilistic approach that can capture uncertainty and relationships between variables.\n",
    "- **Impact on Analysis**: Different methods led to slight variations in regression coefficients, highlighting the importance of choosing an appropriate technique.\n",
    " \n",
    "### Next Steps\n",
    " \n",
    "- **Explore Missingness Mechanisms**: Test if the missing data is Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing Not at Random (MNAR).\n",
    "- **Advanced Bayesian Models**: Use more complex Bayesian models to impute missing data, incorporating relationships between variables (e.g., hierarchical models).\n",
    "- **Sensitivity Analysis**: Compare results with different imputation methods to assess robustness.\n",
    "- **Apply to Other Analyses**: Use these techniques in other mini-projects (e.g., epidemiology case study) to improve data quality.\n",
    "- \n",
    "- *Keep exploring data handling techniques to ensure robust analyses in nutrition science! ü•ïüìâ*\n",
    " \n",
    "---\n",
    "\n",
    "### Setup Requirements\n",
    "\n",
    "1. **Install Libraries**:\n",
    "\n",
    "   ```bash\n",
    "   source ~/Documents/data-analysis-toolkit-FNS/venv/bin/activate\n",
    "   pip install numpy==1.26.4 pandas==2.2.3 matplotlib==3.9.2 seaborn==0.13.2 scipy==1.12.0 pymc==5.16.2 arviz==0.19.0 scikit-learn==1.5.2\n",
    "   ```\n",
    "   \n",
    "2. **Environment**: \n",
    "3. Python 3.9, compatible with Apple Silicon (MPS).\n",
    "4. **Dataset**: Ensure `data/epidemiological_study.csv` is available (generated by `create_epi_data.py`).\n",
    " \n",
    "### Expected Output\n",
    "\n",
    "- **Missing Data Summary**: Table and heatmap showing the extent of missing data.\n",
    "- **Regression Results**: Coefficients from linear regression using each imputation method.\n",
    "- **Comparison Plot**: Bar chart comparing coefficients across methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
