{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üéõÔ∏è 6.3 Thematic Coding & Reliability\n",
    "\n",
    "Build a **transparent coding workflow**: define a codebook, code excerpts, review co-occurrence patterns, and (optionally) compute **inter-coder reliability**.\n",
    "\n",
    "We‚Äôll start from the `qual_coding_sheet.csv` exported in 6.2, but you can also paste your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goals",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üéØ Objectives\n",
    "- Create and iterate a **codebook** (labels, definitions, examples).\n",
    "- Populate codes for each response (single or multi-label).\n",
    "- Summarise **code frequencies** and **co-occurrence**.\n",
    "- Calculate **Cohen‚Äôs Œ∫** for two coders on a subset.\n",
    "- Map codes ‚Üí **themes** and export a brief thematic summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46837cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "MODULE = '06_qualitative'\n",
    "DATASET = 'food_preferences.txt'\n",
    "BASE_PATH = '/content/data-analysis-projects'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join(MODULE_PATH, 'data', DATASET)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        print('Cloning repository...')\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
    "    os.chdir(MODULE_PATH)\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        raise FileNotFoundError('Dataset missing after clone.')\n",
    "    print('Dataset ready ‚úÖ')\n",
    "except Exception as e:\n",
    "    print('Setup fallback: upload file...')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    uploaded = files.upload()\n",
    "    if DATASET in uploaded:\n",
    "        with open(os.path.join('data', DATASET), 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print('Uploaded dataset ‚úÖ')\n",
    "    else:\n",
    "        raise FileNotFoundError('Upload food_preferences.txt to continue.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deps",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy scikit-learn seaborn matplotlib networkx\n",
    "\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, networkx as nx\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "sns.set_theme()\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì• Load coding sheet\n",
    "If you haven‚Äôt created one, run 6.2 to export `qual_coding_sheet.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_sheet",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "sheet = Path('qual_coding_sheet.csv')\n",
    "if not sheet.exists():\n",
    "    # Minimal fallback: create from raw file\n",
    "    raw = Path('data')/'food_preferences.txt'\n",
    "    responses = [r.strip() for r in raw.read_text(encoding='utf-8').splitlines() if r.strip()]\n",
    "    df = pd.DataFrame({'response_id': range(1, len(responses)+1), 'text': responses})\n",
    "    df['initial_code'] = ''; df['notes'] = ''\n",
    "    df.to_csv(sheet, index=False)\n",
    "df = pd.read_csv(sheet)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "codebook",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìö Codebook (living document)\n",
    "Start small, iterate. Keep labels short; include inclusion/exclusion rules and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codebook_table",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "codebook = pd.DataFrame({\n",
    "  'code': ['Preference:Fruit','Preference:Carrot','Preference:Grass','Texture:Crisp','Taste:Sweet','Barrier:Access','Context:Social'],\n",
    "  'definition': [\n",
    "    'Expressed liking for fruit (any type)',\n",
    "    'Specific mention of carrots as preferred',\n",
    "    'Preference or mention of grass as staple',\n",
    "    'Mentions of crisp/crunchy texture as desirable',\n",
    "    'Mentions of sweetness as desirable',\n",
    "    'Mentions of access/availability/cost barriers',\n",
    "    'Mentions of others/social influence (family/herd)'\n",
    "  ],\n",
    "  'example': [\n",
    "    '‚ÄúFruit is preferred on hot days.‚Äù',\n",
    "    '‚ÄúI enjoy crunchy carrots.‚Äù',\n",
    "    '‚ÄúGrass is acceptable‚Ä¶‚Äù',\n",
    "    '‚ÄúI like crunchy snacks.‚Äù',\n",
    "    '‚ÄúSweet foods are better.‚Äù',\n",
    "    '‚ÄúHard to find fresh produce.‚Äù',\n",
    "    '‚ÄúFriends influence what I eat.‚Äù'\n",
    "  ]\n",
    "})\n",
    "codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apply_codes",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üè∑Ô∏è Apply codes (single or multiple)\n",
    "For quick demos, we‚Äôll **auto-suggest** codes via keyword rules, then you can **edit manually**. In practice, codes should be applied by trained coders reading each excerpt.\n",
    "\n",
    "<details><summary>Auto-suggest rules (click)</summary>\n",
    "- If text contains *fruit* ‚Üí `Preference:Fruit`\n",
    "- *carrot* ‚Üí `Preference:Carrot` and `Texture:Crisp` if *crunchy* present\n",
    "- *grass* ‚Üí `Preference:Grass`\n",
    "- *crunchy|crisp* ‚Üí `Texture:Crisp`\n",
    "- *sweet* ‚Üí `Taste:Sweet`\n",
    "- *expensive|access|hard to find|cost* ‚Üí `Barrier:Access`\n",
    "- *friend|family|herd|group* ‚Üí `Context:Social`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rules",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def suggest_codes(text:str):\n",
    "    t = text.lower()\n",
    "    codes = []\n",
    "    if 'fruit' in t: codes.append('Preference:Fruit')\n",
    "    if 'carrot' in t: codes.append('Preference:Carrot')\n",
    "    if 'grass' in t: codes.append('Preference:Grass')\n",
    "    if re.search(r'crunchy|crisp', t): codes.append('Texture:Crisp')\n",
    "    if 'sweet' in t: codes.append('Taste:Sweet')\n",
    "    if re.search(r'expensive|access|hard to find|cost', t): codes.append('Barrier:Access')\n",
    "    if re.search(r'friend|family|herd|group', t): codes.append('Context:Social')\n",
    "    return sorted(set(codes))\n",
    "\n",
    "df['codes'] = df['text'].apply(suggest_codes)\n",
    "df[['response_id','text','codes']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edit_save",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ‚úçÔ∏è Manual editing\n",
    "Export to CSV, edit in Sheets/Excel (add/remove codes, add `theme` column if you like), re-import to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_edit",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('qual_coded_autosuggest.csv', index=False)\n",
    "print('Wrote qual_coded_autosuggest.csv ‚Äî edit if desired and re-load.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freqs",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìä Code frequencies & co-occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freqs_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def explode_codes(df):\n",
    "    dd = df[['response_id','codes']].explode('codes').dropna()\n",
    "    return dd\n",
    "\n",
    "exploded = explode_codes(df)\n",
    "freq = exploded['codes'].value_counts().rename_axis('code').reset_index(name='count')\n",
    "display(freq.head(10))\n",
    "\n",
    "# Co-occurrence matrix\n",
    "pairs = []\n",
    "for _, row in df.iterrows():\n",
    "    cs = sorted(set(row['codes']))\n",
    "    for a,b in combinations(cs, 2):\n",
    "        pairs.append((a,b))\n",
    "co = pd.DataFrame(pairs, columns=['code_a','code_b']).value_counts().reset_index(name='n')\n",
    "co.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "co_heat",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build symmetric matrix for heatmap\n",
    "codes = sorted(freq['code'].tolist())\n",
    "mat = pd.DataFrame(0, index=codes, columns=codes, dtype=int)\n",
    "for _, r in co.iterrows():\n",
    "    mat.loc[r['code_a'], r['code_b']] += r['n']\n",
    "    mat.loc[r['code_b'], r['code_a']] += r['n']\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(mat, annot=False, cmap='Blues')\n",
    "plt.title('Code co-occurrence'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network",
   "metadata": {
    "tags": []
   },
   "source": [
    "### üï∏Ô∏è Optional: co-occurrence network\n",
    "Edges weighted by co-occurrence counts (thicker = stronger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network_plot",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for c in codes: G.add_node(c, size=int(freq[freq['code']==c]['count']))\n",
    "for _, r in co.iterrows():\n",
    "    G.add_edge(r['code_a'], r['code_b'], weight=int(r['n']))\n",
    "pos = nx.spring_layout(G, seed=2)\n",
    "plt.figure(figsize=(7,6))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=[G.nodes[n]['size']*200 for n in G.nodes])\n",
    "nx.draw_networkx_edges(G, pos, width=[G.edges[e]['weight'] for e in G.edges])\n",
    "nx.draw_networkx_labels(G, pos, font_size=9)\n",
    "plt.title('Code co-occurrence network')\n",
    "plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliability",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ü§ù Inter-coder reliability (Cohen‚Äôs Œ∫)\n",
    "For a **subset** of responses, two coders independently assign a **single dominant code**. We‚Äôll demo Œ∫; use it judiciously (it fits some designs better than others‚Äîe.g., structured codebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kappa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate coder labels for a subset (replace with your real labels) \n",
    "subset = df.sample(min(30, len(df)), random_state=1).copy()\n",
    "\n",
    "def dominant_code(codes_list):\n",
    "    return codes_list[0] if isinstance(codes_list, list) and len(codes_list)>0 else 'None'\n",
    "\n",
    "# Coder A uses first auto-suggest; coder B mimics with noise\n",
    "subset['coderA'] = subset['codes'].apply(dominant_code)\n",
    "np.random.seed(1)\n",
    "def jitter(label):\n",
    "    if np.random.rand()<0.15: return 'None'\n",
    "    return label\n",
    "subset['coderB'] = subset['coderA'].apply(jitter)\n",
    "\n",
    "kappa = cohen_kappa_score(subset['coderA'], subset['coderB'])\n",
    "print('Cohen\\'s Œ∫ (demo):', round(kappa, 3))\n",
    "subset[['response_id','text','coderA','coderB']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "themes",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üß© Codes ‚Üí Themes\n",
    "Group codes into broader **themes**. Keep a table mapping to justify boundaries. This is where you *explain* patterns with excerpt evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "map_themes",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theme_map = {\n",
    "  'Preference:Fruit': 'Taste & Freshness',\n",
    "  'Preference:Carrot': 'Taste & Freshness',\n",
    "  'Preference:Grass': 'Habit & Staple Foods',\n",
    "  'Texture:Crisp': 'Sensory Qualities',\n",
    "  'Taste:Sweet': 'Sensory Qualities',\n",
    "  'Barrier:Access': 'Access & Environment',\n",
    "  'Context:Social': 'Social Influence'\n",
    "}\n",
    "\n",
    "exploded = df[['response_id','text','codes']].explode('codes').dropna()\n",
    "exploded['theme'] = exploded['codes'].map(theme_map).fillna('Other')\n",
    "theme_counts = exploded.groupby('theme')['response_id'].nunique().sort_values(ascending=False).reset_index(name='n_responses')\n",
    "display(theme_counts)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(data=theme_counts, x='n_responses', y='theme')\n",
    "plt.title('Theme coverage (responses with ‚â•1 code in theme)')\n",
    "plt.xlabel('Responses'); plt.ylabel('Theme'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì§ Export thematic summary pack\n",
    "- `qual_coded_autosuggest.csv` (or your edited file) ‚Äî coded excerpts\n",
    "- `codebook.csv` ‚Äî code labels/definitions\n",
    "- `theme_counts.csv` ‚Äî quick coverage table\n",
    "\n",
    "Use these to write your results with **excerpts** that illustrate each theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_pack",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "codebook.to_csv('codebook.csv', index=False)\n",
    "theme_counts.to_csv('theme_counts.csv', index=False)\n",
    "print('Wrote codebook.csv and theme_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üß© Exercises\n",
    "1) **Refine the codebook**: add 1‚Äì2 exclusion rules per code; add 1 more code.\n",
    "2) **Dual coding**: have a second coder label 20 responses; compute Œ∫ on *your* dominant codes.\n",
    "3) **Theme memo**: write 3‚Äì5 lines defining each theme + 1 illustrative quote (anonymised)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ‚úÖ Conclusion\n",
    "You built a transparent qualitative pipeline: codebook ‚Üí coding ‚Üí co-occurrence ‚Üí reliability (optional) ‚Üí themes. This supports credible, well-documented qualitative findings that complement your quantitative work.\n",
    "\n",
    "<details><summary>Further reading</summary>\n",
    "- Coding manuals and reflexive thematic analysis guides\n",
    "- Reporting standards for qualitative research\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
