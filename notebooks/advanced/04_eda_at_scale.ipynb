{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç 5.4 Exploratory Data Analysis at Scale
",
    "
",
    "When datasets grow too large for memory, we need tools like `dask` or `vaex`.
",
    "
",
    "## Why Not Just Use Pandas?
",
    "- Pandas loads everything into memory.
",
    "- Larger-than-RAM datasets can crash your notebook or slow performance.
",
    "
",
    "## Meet `dask`
",
    "
",
    "Dask enables scalable analysis with a pandas-like interface."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import dask.dataframe as dd
",
    "# Load a large CSV (e.g., NDNS simulated large)
",
    "# df = dd.read_csv('large_efsa_dataset.csv')  # Example only
",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Performance Tips
",
    "- Use `.sample(frac=0.1)` to inspect subsets.
",
    "- Summarise only what you need.
",
    "
",
    "## üß™ Exercise
",
    "- Create a random dataset with 1 million rows using `dask.dataframe`
",
    "- Group by food group and calculate mean energy content"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}