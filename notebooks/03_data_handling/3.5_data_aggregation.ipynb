{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# ðŸ“ˆ 3.5 Data Aggregation\n",
        "\n",
        "Aggregation turns **rows of measurements** into **concise summaries**. In nutrition science, that might mean mean iron intake by sex, median calcium by age-group, or % of hippos meeting a reference intake.\n",
        "\n",
        "This notebook gives you a practical tour of pandas aggregation: `groupby`, custom aggregations, weighted summaries, joining reference data, and avoiding common pitfalls.\n",
        "\n",
        "***\n",
        "## ðŸŽ¯ Objectives\n",
        "By the end you can:\n",
        "- Use `groupby(...).agg(...)` for multi-metric summaries (mean, median, count, SD, percentiles).\n",
        "- Compute **weighted** summaries (e.g., weight-adjusted averages).\n",
        "- Join tables (left / inner / right) safely and diagnose join issues.\n",
        "- Concatenate multiple datasets and add group labels.\n",
        "- Produce clean, analysis-ready summary tables.\n",
        "\n",
        "Weâ€™ll work with `hippo_nutrients.csv` and a small reference-intake table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Google Colab: Fetch datasets automatically or manually\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "MODULE = '03_data_handling'  # module folder\n",
        "DATASET = 'hippo_nutrients.csv'\n",
        "BASE_PATH = '/content/data-analysis-projects'\n",
        "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
        "DATASET_PATH = os.path.join('data', DATASET)\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
        "    os.chdir(MODULE_PATH)\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        raise FileNotFoundError(DATASET_PATH)\n",
        "    print(f'Dataset found: {DATASET_PATH} ðŸ¦›')\n",
        "except Exception as e:\n",
        "    print(f'Automatic clone failed: {e}')\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "    if DATASET in uploaded:\n",
        "        with open(DATASET_PATH, 'wb') as f:\n",
        "            f.write(uploaded[DATASET])\n",
        "        print(f'Successfully uploaded {DATASET} ðŸ¦›')\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051cc7e0",
      "metadata": {},
      "source": [
        "Install libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568e7244",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas numpy -q\n",
        "import pandas as pd, numpy as np\n",
        "pd.set_option('display.max_columns', 40)\n",
        "print('Environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {},
      "source": [
        "## 1) Load and Inspect\n",
        "Weâ€™ll start by loading the data and checking the structure. The columns should include `ID, Nutrient, Year, Value, Age, Sex`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/hippo_nutrients.csv')\n",
        "print(df.shape)\n",
        "display(df.head())\n",
        "display(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "groupby_basics",
      "metadata": {},
      "source": [
        "## 2) GroupBy Basics â€” The Splitâ€“Applyâ€“Combine Pattern\n",
        "`groupby` splits the data into groups, applies a function within each group, and combines the results.\n",
        "\n",
        "### Example: Mean `Value` by `Nutrient` and `Sex`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "groupby_mean",
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_by_ns = df.groupby(['Nutrient','Sex'], as_index=True)['Value'].mean()\n",
        "display(mean_by_ns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "multi_metric",
      "metadata": {},
      "source": [
        "### Multiple metrics at once\n",
        "You can compute several statistics in one go using `.agg` with a dict or list. Weâ€™ll compute **count**, **mean**, **median**, **std**, and a **90th percentile** (0.9 quantile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "agg_multi",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_multi = (\n",
        "    df.groupby(['Nutrient','Sex'])['Value']\n",
        "      .agg(count='count',\n",
        "           mean='mean',\n",
        "           median='median',\n",
        "           sd='std',\n",
        "           p90=lambda s: s.quantile(0.9))\n",
        ")\n",
        "display(summary_multi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flatten_columns",
      "metadata": {},
      "source": [
        "### Optional: Reset index and tidy column names\n",
        "When presenting results, itâ€™s often clearer to have a flat index and simple column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reset_names",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_tidy = summary_multi.reset_index()\n",
        "summary_tidy.columns = [c.replace(' ', '_') for c in summary_tidy.columns]\n",
        "display(summary_tidy.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weights_intro",
      "metadata": {},
      "source": [
        "## 3) Weighted Aggregation\n",
        "Sometimes a plain mean is misleading. Suppose we have body weights per hippo and want a **weight-adjusted average** nutrient value (purely illustrative). Weâ€™ll create a tiny weight table and compute a weighted mean by `Nutrient` and `Sex`.\n",
        "\n",
        "> Pedagogical note: In real analyses, choose weights that are defensible (e.g., sampling weights, exposure weights)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "weights_demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Toy weight data (kg) â€” in practice this would come from another table\n",
        "weights = pd.DataFrame({\n",
        "    'ID': df['ID'].drop_duplicates().head(6).tolist(),\n",
        "    'BodyWeight_kg': [2000, 2100, 1950, 2050, 1980, 2020][:len(df['ID'].drop_duplicates().head(6))]\n",
        "})\n",
        "display(weights.head())\n",
        "\n",
        "# Left-join weights into df\n",
        "df_w = df.merge(weights, on='ID', how='left')\n",
        "display(df_w.head())\n",
        "\n",
        "def weighted_mean(x, w):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    w = np.asarray(w, dtype=float)\n",
        "    m = np.isfinite(x) & np.isfinite(w)\n",
        "    if m.sum() == 0 or w[m].sum() == 0:\n",
        "        return np.nan\n",
        "    return np.sum(x[m] * w[m]) / np.sum(w[m])\n",
        "\n",
        "wm = (\n",
        "    df_w.groupby(['Nutrient','Sex'])\n",
        "       .apply(lambda g: weighted_mean(g['Value'], g['BodyWeight_kg']),\n",
        "       include_groups=False)\n",
        "       .rename('weighted_mean')\n",
        "       .reset_index()\n",
        ")\n",
        "display(wm.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "joins_intro",
      "metadata": {},
      "source": [
        "## 4) Joining Reference Data (Left/Inner/Right)\n",
        "Letâ€™s define a small **reference intake** table (illustrative), join it to our nutrient data, and compute % of reference achieved.\n",
        "\n",
        "Weâ€™ll use **left joins** to keep our rows, and demonstrate **inner joins** (keep matching rows only) for comparison.\n",
        "\n",
        "### Good practice when joining\n",
        "- Inspect **key uniqueness** (e.g., each Nutrient appears once in the reference table).\n",
        "- Check row counts before/after joins.\n",
        "- Consider **anti-joins** to find non-matching rows (rows with no partner)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "join_ref",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference intakes (illustrative values)\n",
        "ref = pd.DataFrame({\n",
        "    'Nutrient': ['Iron','Calcium','Vitamin_D'],\n",
        "    'ReferenceValue': [15.0, 1200.0, 10.0],  # units aligned with df['Value']\n",
        "    'Units': ['mg/day','mg/day','Âµg/day']\n",
        "})\n",
        "display(ref)\n",
        "\n",
        "# Check key uniqueness in ref\n",
        "assert ref['Nutrient'].is_unique, 'Reference Nutrient keys should be unique'\n",
        "\n",
        "# Aggregate df first (e.g., mean by Nutrient and Sex), then join reference\n",
        "mean_by_ns = df.groupby(['Nutrient','Sex'], as_index=False)['Value'].mean()\n",
        "left_joined = mean_by_ns.merge(ref, on='Nutrient', how='left')\n",
        "left_joined['Pct_of_Ref'] = 100 * left_joined['Value'] / left_joined['ReferenceValue']\n",
        "display(left_joined)\n",
        "\n",
        "# Inner join (only rows with a matching Nutrient in ref)\n",
        "inner_joined = mean_by_ns.merge(ref, on='Nutrient', how='inner')\n",
        "display(inner_joined.head())\n",
        "\n",
        "# Anti-join: which Nutrients in our data are missing from ref?\n",
        "missing_in_ref = (\n",
        "    mean_by_ns[~mean_by_ns['Nutrient'].isin(ref['Nutrient'])]\n",
        ")\n",
        "display(missing_in_ref.drop_duplicates(subset=['Nutrient']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "concat_intro",
      "metadata": {},
      "source": [
        "## 5) Concatenation (Stacking Datasets)\n",
        "If you receive multiple similar files (e.g., **two cohorts** or **two years**), you can **stack** them with `pd.concat`.\n",
        "\n",
        "- Ensure **columns align** (same names and types).\n",
        "- Optionally add a column to track the dataset (`source`, `cohort`, `year`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "concat_demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Small synthetic split: first half vs second half\n",
        "half = len(df)//2\n",
        "df_a = df.iloc[:half].copy(); df_a['source'] = 'A'\n",
        "df_b = df.iloc[half:].copy(); df_b['source'] = 'B'\n",
        "\n",
        "stacked = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
        "display(stacked[['source','Nutrient','Value']].head())\n",
        "\n",
        "# Aggregate by source to compare\n",
        "by_source = stacked.groupby(['source','Nutrient'])['Value'].agg(mean='mean', n='count').reset_index()\n",
        "display(by_source.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "binning_intro",
      "metadata": {},
      "source": [
        "## 6) Binning and Aggregating (Age Bands)\n",
        "Sometimes itâ€™s useful to summarise by **bands** (e.g., age groups). Use `pd.cut` to create categories and aggregate by them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "binning_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'Age' in df.columns:\n",
        "    bins = [0, 20, 30, 40, 200]\n",
        "    labels = ['<20','20â€“29','30â€“39','40+']\n",
        "    df['AgeBand'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
        "    by_band = (\n",
        "        df.groupby(['Nutrient','AgeBand'], observed=True)['Value']\n",
        "          .agg(n='count', mean='mean', median='median')\n",
        "          .reset_index()\n",
        "    )\n",
        "    display(by_band.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pivot_and_ci",
      "metadata": {},
      "source": [
        "## 7) Presenting Results: Pivot and Confidence Intervals (quick)\n",
        "You can pivot summaries for a compact view, and optionally add simple **standard errors** and **approximate 95% CIs** (for teaching purposes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ci_demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "g = df.groupby(['Nutrient','Sex'])['Value']\n",
        "\n",
        "ci_tbl = (\n",
        "    g.agg(\n",
        "        mean = 'mean',\n",
        "        n    = 'count',\n",
        "        sd   = lambda s: s.std(ddof=1)\n",
        "    )\n",
        "    .assign(\n",
        "        se  = lambda d: d['sd'] / np.sqrt(d['n']).where(d['n'] > 0, np.nan),\n",
        "        low = lambda d: d['mean'] - 1.96 * d['se'],\n",
        "        high= lambda d: d['mean'] + 1.96 * d['se']\n",
        "    )\n",
        "    .drop(columns='sd')\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(ci_tbl.head())\n",
        "\n",
        "ci_pivot = ci_tbl.pivot_table(index='Nutrient', columns='Sex', values='mean')\n",
        "display(ci_pivot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "common_pitfalls",
      "metadata": {},
      "source": [
        "## 8) Common Pitfalls (and fixes)\n",
        "- **Missing values**: By default, many aggregations ignore NaNs; check `count` vs the expected sample size.\n",
        "- **Unequal groups**: When comparing means across groups with very different `n`, consider medians, robust measures, or report CIs.\n",
        "- **Joins that multiply rows**: Many-to-many joins can inflate data. Inspect key uniqueness before joining.\n",
        "- **Units**: Ensure units match before comparing or aggregating across tables (e.g., mg vs Âµg).\n",
        "- **MultiIndex outputs**: Flatten columns or `reset_index()` for presentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## ðŸ§ª Exercises\n",
        "1) **Multi-metric summary**  \n",
        "   - For each `(Nutrient, Year)`, compute: `n`, `mean`, `median`, `sd`, `min`, `max`.  \n",
        "   - Present as a tidy table (no MultiIndex).\n",
        "\n",
        "2) **Weighted summary**  \n",
        "   - Create a new weighting scheme (e.g., `Age` as a simple weight proxy).  \n",
        "   - Compute a weighted mean `Value` by `(Nutrient, Sex)` and compare to the unweighted mean.\n",
        "\n",
        "3) **Join with reference**  \n",
        "   - Add a column `% of reference` for each `(Nutrient, Sex)` at **Year 2025** only.  \n",
        "   - Which nutrient and sex combination is furthest below reference?\n",
        "\n",
        "4) **Concatenate and label**  \n",
        "   - Split the dataset into two random halves, label each half, `concat`, and compute the mean `Value` by `(source, Nutrient)`.  \n",
        "   - Are the differences meaningful or just sampling noise?\n",
        "\n",
        "5) **Age bands**  \n",
        "   - Define your own custom age bands and summarise `Value` by `(Nutrient, AgeBand, Sex)`.  \n",
        "   - Report the top 3 `(Nutrient, AgeBand)` pairs by mean `Value`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## âœ… Conclusion\n",
        "Youâ€™ve practised core aggregation patterns:\n",
        "- `groupby` with multiple metrics and tidy outputs.\n",
        "- Weighted means where appropriate.\n",
        "- Safe joins against reference intake tables, with diagnostics.\n",
        "- Concatenation and labelling of multiple datasets.\n",
        "- Clear presentation (pivot, CIs) for reporting.\n",
        "\n",
        "ðŸ‘‰ Next: move into **04 Data Analysis** for visualisation, correlation, and modelling.\n",
        "\n",
        "***\n",
        "**Resources**  \n",
        "- Pandas GroupBy: https://pandas.pydata.org/docs/user_guide/groupby.html  \n",
        "- Aggregation & Transform: https://pandas.pydata.org/docs/user_guide/groupby.html#aggregation  \n",
        "- Merge/Join: https://pandas.pydata.org/docs/user_guide/merging.html  \n",
        "- Reshaping (pivot/melt): https://pandas.pydata.org/docs/user_guide/reshaping.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
