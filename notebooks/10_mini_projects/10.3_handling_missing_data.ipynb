{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸ§©ðŸ“Š Handling Missing Data in Nutrition Science\n",
    "\n",
    "Weâ€™ll use a large cohort (nâ‰ˆ25,000; age 45â€“80) to explore missingness and compare four approaches on the same target model:\n",
    "\n",
    "**Outcome**: `BMI_Baseline`\n",
    "\n",
    "**Predictors**: Age, Sex, Smoking, Physical_Activity, Social_Class (UK A/B/C1/C2/D/E), Sugar_Intake, SFA_Intake\n",
    "\n",
    "Methods compared:\n",
    "1) Listwise deletion\n",
    "2) Mean/Mode imputation\n",
    "3) Multiple Imputation (m=5) with Rubinâ€™s rules\n",
    "4) Bayesian joint model (numeric missings latent; weakly-informative priors)\n",
    "\n",
    "The notebook loads `data/epidemiological_study.csv` **or simulates** a realistic dataset (seed=11088)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Environment\n",
    "Uncomment installs if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install pandas numpy matplotlib seaborn scipy scikit-learn statsmodels pymc arviz\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "sns.set_context('notebook'); sns.set_style('whitegrid')\n",
    "RANDOM_SEED = 11088\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "DATA_DIR = Path('data'); DATA_DIR.mkdir(exist_ok=True)\n",
    "DATA_PATH = DATA_DIR / 'epidemiological_study.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Simulate Dataset\n",
    "If the CSV is missing, we simulate a cohort with ~5â€“10% MCAR per variable and plausible nutrition/CVD structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulate",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_epidemiology(n=25_000, seed=RANDOM_SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    age = rng.normal(62, 8.5, n).clip(45, 85)\n",
    "    sex = rng.choice(['Female','Male'], n)\n",
    "    smoking = rng.choice(['Non-smoker','Smoker'], n, p=[0.7,0.3])\n",
    "    activity = rng.choice(['Low','Medium','High'], n, p=[0.3,0.45,0.25])\n",
    "    social = rng.choice(['A','B','C1','C2','D','E'], n, p=[0.08,0.15,0.22,0.22,0.2,0.13])\n",
    "    sugar = rng.normal(90, 35, n).clip(10, 250)\n",
    "    sfa = rng.normal(28, 10, n).clip(5, 80)\n",
    "    x_male = (sex=='Male').astype(int)\n",
    "    x_act = pd.Series(activity).map({'Low':0,'Medium':1,'High':2}).values\n",
    "    bmi0 = (rng.normal(27, 3.5, n) + 0.08*(age-62) + 0.6*x_male - 0.5*x_act + 0.015*(sugar-90))\n",
    "    bp0 = rng.normal(132, 14, n) + 0.12*(age-62) + 1.2*(bmi0-27)\n",
    "    df = pd.DataFrame({\n",
    "        'ID': np.arange(1, n+1), 'Age': age.round(1), 'Sex': sex, 'Smoking': smoking,\n",
    "        'Physical_Activity': activity, 'Social_Class': social,\n",
    "        'Sugar_Intake': sugar.round(1), 'SFA_Intake': sfa.round(1),\n",
    "        'BMI_Baseline': bmi0.round(2), 'BP_Baseline': bp0.round(1)\n",
    "    })\n",
    "    miss_cols = ['Sugar_Intake','SFA_Intake','Physical_Activity','Social_Class','BMI_Baseline','BP_Baseline','Age']\n",
    "    for c in miss_cols:\n",
    "        m = rng.random(len(df)) < rng.uniform(0.05,0.10)\n",
    "        df.loc[m, c] = np.nan\n",
    "    return df\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    data = simulate_epidemiology()\n",
    "    data.to_csv(DATA_PATH, index=False)\n",
    "    print(f\"Simulated and saved to {DATA_PATH}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missingness",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 â€” Explore Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missingness_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "miss_pct = (data.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "display(miss_pct[miss_pct>0].to_frame('Missing_%'))\n",
    "plt.figure(figsize=(10,6));\n",
    "sns.heatmap(data.sample(min(2000,len(data))).isna(), cbar=False)\n",
    "plt.title('Missingness heatmap (sample rows)'); plt.xlabel('Variables'); plt.ylabel('Participants'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 â€” Prepare Model Matrices\n",
    "Target model (for all methods):\n",
    "\n",
    "**BMI_Baseline ~ Age + Sex + Smoking + Physical_Activity + Social_Class + Sugar_Intake + SFA_Intake**\n",
    "\n",
    "We avoid `LabelEncoder`; weâ€™ll either use a formula with `C()` or one-hot dummies with references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['BMI_Baseline','Age','Sex','Smoking','Physical_Activity','Social_Class','Sugar_Intake','SFA_Intake']\n",
    "dfm = data[cols].copy()\n",
    "# set explicit category orders (stable references)\n",
    "dfm['Physical_Activity'] = dfm['Physical_Activity'].astype('category').cat.set_categories(['Low','Medium','High'])\n",
    "dfm['Social_Class'] = dfm['Social_Class'].astype('category').cat.set_categories(['A','B','C1','C2','D','E'])\n",
    "dfm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listwise",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3 â€” Listwise Deletion\n",
    "Drop rows with any missing in the model variables; fit OLS by formula (gives CIs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listwise_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lw = dfm.dropna().copy()\n",
    "formula = 'BMI_Baseline ~ Age + C(Sex) + C(Smoking) + C(Physical_Activity, Treatment(reference=\"Medium\")) + C(Social_Class, Treatment(reference=\"C1\")) + Sugar_Intake + SFA_Intake'\n",
    "ols_lw = smf.ols(formula, data=lw).fit()\n",
    "print(f\"Rows kept: {len(lw)} / {len(dfm)}\")\n",
    "lw_tab = pd.concat([ols_lw.params, ols_lw.conf_int()], axis=1)\n",
    "lw_tab.columns = ['coef','2.5%','97.5%']\n",
    "lw_tab.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meanmode",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4 â€” Mean/Mode Imputation\n",
    "Mean for numeric; mode for categoricals. Then OLS by formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meanmode_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mm = dfm.copy()\n",
    "for c in ['BMI_Baseline','Age','Sugar_Intake','SFA_Intake']:\n",
    "    mm[c] = mm[c].fillna(mm[c].mean())\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    mm[c] = mm[c].fillna(mm[c].mode().iloc[0])\n",
    "ols_mm = smf.ols(formula, data=mm).fit()\n",
    "mm_tab = pd.concat([ols_mm.params, ols_mm.conf_int()], axis=1)\n",
    "mm_tab.columns = ['coef','2.5%','97.5%']\n",
    "mm_tab.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mi",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5 â€” Multiple Imputation (m=5) with Rubinâ€™s Rules\n",
    "We use `IterativeImputer` with posterior sampling and different seeds to create m datasets, fit the **same OLS**, and pool estimates and variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mi_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_once(df, seed):\n",
    "    # Build a numeric-friendly frame: model.matrix via patsy formula\n",
    "    # Use get_dummies for predictors; keep outcome separate to avoid dummying it\n",
    "    base = df.copy()\n",
    "    # Build dummy design with explicit references matching the formula\n",
    "    X_cat = pd.get_dummies(base[['Sex','Smoking','Physical_Activity','Social_Class']], drop_first=True)\n",
    "    X_num = base[['Age','Sugar_Intake','SFA_Intake']]\n",
    "    y = base[['BMI_Baseline']]\n",
    "    Z = pd.concat([y, X_num, X_cat], axis=1)\n",
    "    imp = IterativeImputer(random_state=seed, sample_posterior=True, max_iter=20)\n",
    "    Zi = pd.DataFrame(imp.fit_transform(Z), columns=Z.columns)\n",
    "    # reconstruct a data frame close to original for formula fit\n",
    "    out = base.copy()\n",
    "    out['BMI_Baseline'] = Zi['BMI_Baseline']\n",
    "    out['Age'] = Zi['Age']; out['Sugar_Intake'] = Zi['Sugar_Intake']; out['SFA_Intake'] = Zi['SFA_Intake']\n",
    "    # For categoricals, fallback to original with any remaining missings filled by mode (IterativeImputer worked on dummies only)\n",
    "    for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "        out[c] = out[c].fillna(out[c].mode().iloc[0])\n",
    "    return out\n",
    "\n",
    "def rubins_rules(estimates, covs):\n",
    "    # estimates: list of params Series; covs: list of covariance DataFrames\n",
    "    params = estimates[0].index\n",
    "    m = len(estimates)\n",
    "    Qbar = pd.concat(estimates, axis=1).mean(axis=1)\n",
    "    Ubar = sum(covs)/m\n",
    "    B = pd.concat([(e - Qbar).to_frame() for e in estimates], axis=1)\n",
    "    B = (B.pow(2)).mean(axis=1)\n",
    "    T = Ubar.values.diagonal() + (1 + 1/m) * B.values\n",
    "    se = np.sqrt(T)\n",
    "    pooled = pd.DataFrame({'coef': Qbar, 'SE': se}, index=params)\n",
    "    pooled['2.5%'] = pooled['coef'] - 1.96*pooled['SE']\n",
    "    pooled['97.5%'] = pooled['coef'] + 1.96*pooled['SE']\n",
    "    return pooled\n",
    "\n",
    "M = 5\n",
    "ests, covs = [], []\n",
    "for i in range(M):\n",
    "    seed = RANDOM_SEED + i\n",
    "    mi_df = impute_once(dfm, seed)\n",
    "    fit = smf.ols(formula, data=mi_df).fit()\n",
    "    ests.append(fit.params)\n",
    "    covs.append(fit.cov_params())\n",
    "\n",
    "mi_tab = rubins_rules(ests, covs).round(3)\n",
    "mi_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bayes",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6 â€” Bayesian Joint Model with Latent Missing Values\n",
    "We fit a Bayesian linear model for BMI with **weakly informative priors**. For *numeric* predictors (`Age`, `Sugar_Intake`, `SFA_Intake`, and `BMI_Baseline` if needed), we treat missing entries as latent variables.\n",
    "\n",
    "Categorical missings are imputed with mode for simplicity (students can extend to categorical models). Numeric predictors are standardised to help sampling geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bayes_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Design matrix (categoricals -> dummies; numeric kept for latent imputation) ---\n",
    "bx = dfm.copy()\n",
    "for c in ['Sex','Smoking','Physical_Activity','Social_Class']:\n",
    "    bx[c] = bx[c].fillna(bx[c].mode().iloc[0])\n",
    "\n",
    "X_dum = pd.get_dummies(\n",
    "    bx[['Sex','Smoking','Physical_Activity','Social_Class']],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Numeric arrays with NaNs preserved for latent imputation\n",
    "age   = dfm['Age'].to_numpy(dtype=float)\n",
    "sugar = dfm['Sugar_Intake'].to_numpy(dtype=float)\n",
    "sfa   = dfm['SFA_Intake'].to_numpy(dtype=float)\n",
    "y_bmi = dfm['BMI_Baseline'].to_numpy(dtype=float)\n",
    "\n",
    "# Standardise with NaN support; guard zero variance\n",
    "def z_with_nan(x):\n",
    "    m = np.nanmean(x)\n",
    "    s = np.nanstd(x)\n",
    "    if not np.isfinite(s) or s == 0:\n",
    "        s = 1.0\n",
    "    return (x - m) / s, (m, s)\n",
    "\n",
    "age_z,   age_stats   = z_with_nan(age)\n",
    "sugar_z, sugar_stats = z_with_nan(sugar)\n",
    "sfa_z,   sfa_stats   = z_with_nan(sfa)\n",
    "\n",
    "X_fix   = X_dum.astype(float).to_numpy()\n",
    "fix_names = X_dum.columns.tolist()\n",
    "N = X_fix.shape[0]\n",
    "\n",
    "coords = {\"obs\": np.arange(N), \"fix\": fix_names}\n",
    "\n",
    "with pm.Model(coords=coords) as bim:\n",
    "    # Fixed (non-imputed) design part for categoricals\n",
    "    X_fix_data = pm.Data('X_fix', X_fix, dims=('obs','fix'))\n",
    "\n",
    "    # Latent z-scores for missing numeric predictors (length N each)\n",
    "    age_lat   = pm.Normal('Age_z',   mu=0, sigma=1, dims=('obs',))\n",
    "    sugar_lat = pm.Normal('Sugar_z', mu=0, sigma=1, dims=('obs',))\n",
    "    sfa_lat   = pm.Normal('SFA_z',   mu=0, sigma=1, dims=('obs',))\n",
    "\n",
    "    # Use observed z-scores where available; otherwise latent\n",
    "    age_obs   = pt.as_tensor_variable(age_z)\n",
    "    sugar_obs = pt.as_tensor_variable(sugar_z)\n",
    "    sfa_obs   = pt.as_tensor_variable(sfa_z)\n",
    "\n",
    "    age_use   = pt.where(pt.isnan(age_obs),   age_lat,   age_obs)\n",
    "    sugar_use = pt.where(pt.isnan(sugar_obs), sugar_lat, sugar_obs)\n",
    "    sfa_use   = pt.where(pt.isnan(sfa_obs),   sfa_lat,   sfa_obs)\n",
    "\n",
    "    # Priors\n",
    "    beta0     = pm.Normal('Intercept', 27, 5)\n",
    "    beta_age  = pm.Normal('b_age',   0, 1)\n",
    "    beta_sug  = pm.Normal('b_sugar', 0, 1)\n",
    "    beta_sfa  = pm.Normal('b_sfa',   0, 1)\n",
    "    beta_fix  = pm.Normal('Beta_fix', 0, 1, dims=('fix',))\n",
    "    sigma     = pm.HalfNormal('Sigma', 3)\n",
    "\n",
    "    # Linear predictor\n",
    "    mu = beta0 + beta_age*age_use + beta_sug*sugar_use + beta_sfa*sfa_use + pm.math.dot(X_fix_data, beta_fix)\n",
    "\n",
    "    # Likelihood (allow missing y via masked array)\n",
    "    y_masked = np.ma.masked_invalid(y_bmi)\n",
    "    pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_masked)\n",
    "\n",
    "    trace_bim = pm.sample(\n",
    "        draws=1500, tune=1000, target_accept=0.9,\n",
    "        random_seed=RANDOM_SEED, return_inferencedata=True\n",
    "    )\n",
    "\n",
    "print(az.summary(trace_bim, var_names=['Intercept','b_age','b_sugar','b_sfa','Beta_fix','Sigma'], hdi_prob=0.95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 7 â€” Compare Estimates Across Methods\n",
    "We harmonise coefficients for shared terms across methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Frequentist tables (unchanged) ---\n",
    "def tidy(res):\n",
    "    out = pd.concat([res.params, res.conf_int()], axis=1)\n",
    "    out.columns = ['coef','2.5%','97.5%']\n",
    "    return out.rename(index={'const': 'Intercept'})\n",
    "\n",
    "lw_tab2 = tidy(ols_lw)\n",
    "mm_tab2 = tidy(ols_mm)\n",
    "mi_tab2 = mi_tab[['coef','2.5%','97.5%']].rename(index={'const':'Intercept'})\n",
    "\n",
    "# --- Bayesian table from raw samples (no ArviZ summary/HDI) ---\n",
    "def et_ci(samples, q=(0.025, 0.975)):\n",
    "    \"\"\"Equal-tailed CI for 1D numpy samples.\"\"\"\n",
    "    lo, hi = np.quantile(samples, q)\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Scalars first\n",
    "for var, label in [\n",
    "    ('Intercept','Intercept'),\n",
    "    ('b_age','Age'),\n",
    "    ('b_sugar','Sugar_Intake'),\n",
    "    ('b_sfa','SFA_Intake'),\n",
    "]:\n",
    "    s = trace_bim.posterior[var].values.reshape(-1)   # [chains*draws]\n",
    "    m = float(np.mean(s))\n",
    "    lo, hi = et_ci(s)\n",
    "    rows.append((label, m, lo, hi))\n",
    "\n",
    "# Vector of dummy/fixed effects: handle either 'Beta_fix' or 'Beta'\n",
    "beta_var = 'Beta_fix' if 'Beta_fix' in trace_bim.posterior.data_vars else 'Beta'\n",
    "beta_da  = trace_bim.posterior[beta_var]                       # dims: chain, draw, <coefdim>\n",
    "coefdim  = [d for d in beta_da.dims if d not in ('chain','draw')][0]\n",
    "coef_idx = beta_da[coefdim].values.tolist()                    # names\n",
    "\n",
    "# stack chains/draws -> samples per coefficient\n",
    "beta_samples = (beta_da\n",
    "                .stack(sample=('chain','draw'))                # dims: <coefdim>, sample\n",
    "                .transpose(coefdim, 'sample')\n",
    "                .values)                                       # shape: [n_coef, n_samples]\n",
    "\n",
    "beta_mean = beta_samples.mean(axis=1)\n",
    "beta_lo, beta_hi = np.quantile(beta_samples, [0.025, 0.975], axis=1)\n",
    "\n",
    "for name, m, lo, hi in zip(coef_idx, beta_mean, beta_lo, beta_hi):\n",
    "    rows.append((name, float(m), float(lo), float(hi)))\n",
    "\n",
    "bayes_tab = pd.DataFrame(rows, columns=['term','coef','2.5%','97.5%']).set_index('term')\n",
    "\n",
    "# --- Align and compare ---\n",
    "common = (lw_tab2.index\n",
    "          .intersection(mm_tab2.index)\n",
    "          .intersection(mi_tab2.index)\n",
    "          .intersection(bayes_tab.index))\n",
    "\n",
    "cmp = pd.DataFrame({\n",
    "    'Listwise':  lw_tab2.loc[common, 'coef'],\n",
    "    'Mean/Mode': mm_tab2.loc[common, 'coef'],\n",
    "    'MI (m=5)':  mi_tab2.loc[common, 'coef'],\n",
    "    'Bayesian':  bayes_tab.loc[common, 'coef'],\n",
    "}).sort_index()\n",
    "\n",
    "cmp.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_cmp",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "cmp.plot(kind='bar', figsize=(12,6))\n",
    "plt.title('Coefficient comparison across methods')\n",
    "plt.ylabel('Estimate')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning Points\n",
    "- **Listwise deletion**: simple, but reduces n and can bias if not MCAR.\n",
    "- **Mean/Mode**: preserves n but underestimates uncertainty and shrinks relationships.\n",
    "- **Multiple Imputation**: reflects imputation uncertainty; pooled CIs via Rubinâ€™s rules.\n",
    "- **Bayesian joint**: treats missings as unknowns; returns posterior for model parameters and latent values.\n",
    "\n",
    "### Extensions for students\n",
    "- Replace mean/mode for categoricals with multinomial imputation.\n",
    "- Add **interactions** and **non-linearities** (splines) to the BMI model.\n",
    "- Use diagnostics (e.g., posterior predictive checks) to assess imputation plausibility.\n",
    "- Compare MI with different `m` and different imputation models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
