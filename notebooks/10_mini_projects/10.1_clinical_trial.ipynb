{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9064aff",
   "metadata": {},
   "source": [
    "\n",
    "üß™ Clinical Trial: Hipponol Intervention Study\n",
    "==============================================\n",
    "\n",
    "This notebook explores data from a simulated 2-year clinical trial testing the effects of a novel nutrient, **Hipponol**, on blood pressure and survival.\n",
    "\n",
    "# Methodology\n",
    "## Study Design\n",
    "\n",
    "- **Population**: 1000 participants, aged 40‚Äì70, male/female, smokers and non-smokers.\n",
    "- **Design**: Randomised controlled trial (RCT), 1:1 allocation to Hipponol vs. placebo.\n",
    "- **Blinding**: Double-blind.\n",
    "- **Duration**: 2-year follow-up.\n",
    "- **Outcomes**:\n",
    "  - **Primary**: Survival at 2 years.\n",
    "  - **Secondary**: Change in systolic blood pressure (SBP) from baseline to follow-up.\n",
    "\n",
    "## Analysis Plan\n",
    "\n",
    "This notebook will follow key elements of the **CONSORT guidelines** for RCT reporting.\n",
    "\n",
    "### üîç Descriptive Analysis (Baseline)\n",
    "\n",
    "- Generate a **Table 1** comparing baseline characteristics (age, sex, smoking status, baseline SBP) between groups.\n",
    "- Use appropriate statistical tests:\n",
    "  - Continuous variables: t-test or Mann‚ÄìWhitney U\n",
    "  - Categorical variables: Chi-squared test\n",
    "\n",
    "### üìâ Outcome Analysis\n",
    "\n",
    "Analysis of results using **Bayesian** and **Frequentist** methods\n",
    "\n",
    "### Primary endpoint\n",
    "\n",
    "- **Survival**:\n",
    "  - Logistic regression\n",
    "  - Kaplan‚ÄìMeier survival curves by group.\n",
    "  - Log-rank test and Cox proportional hazards model.\n",
    "\n",
    "\n",
    "- **Blood Pressure**:\n",
    "  - Compare change in SBP using paired and unpaired t-tests.\n",
    "  - Adjust for baseline covariates using linear regression.\n",
    "\n",
    "\n",
    "### üìå Notes\n",
    "\n",
    "- Missing data handling: listwise deletion for simplicity.\n",
    "- Sensitivity analyses optional (not shown in basic notebook).\n",
    "- Assumptions for all statistical models will be checked.\n",
    "\n",
    "<details>\n",
    "<summary>ü¶õ Fun Fact</summary>\n",
    "The nutrient Hipponol is purely fictional‚Äîbut if hippos had trials, we bet they'd run them by CONSORT too!\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad31eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab: Fetch datasets automatically or manually\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Define the module and dataset for this notebook\n",
    "MODULE = '10_mini_projects'  \n",
    "DATASET = 'hipponol_trial_data.csv'\n",
    "BASE_PATH = '/content/data-analysis-toolkit-FNS'\n",
    "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
    "DATASET_PATH = os.path.join('data', DATASET)\n",
    "\n",
    "# Step 1: Attempt to clone the repository (automatic method)\n",
    "# Note: If you encounter a cloning error (e.g., 'fatal: destination path already exists'),\n",
    "#       reset the runtime (Runtime > Restart runtime) and run this cell again.\n",
    "try:\n",
    "    print('Attempting to clone repository...')\n",
    "    if os.path.exists(BASE_PATH):\n",
    "        print('Repository already exists, skipping clone.')\n",
    "    else:\n",
    "        !git clone https://github.com/ggkuhnle/data-analysis-toolkit-FNS.git\n",
    "    \n",
    "    # Debug: Print directory structure\n",
    "    print('Listing repository contents:')\n",
    "    !ls {BASE_PATH}\n",
    "    print(f'Listing notebooks directory contents:')\n",
    "    !ls {BASE_PATH}/notebooks\n",
    "    \n",
    "    # Check if the module directory exists\n",
    "    if not os.path.exists(MODULE_PATH):\n",
    "        raise FileNotFoundError(f'Module directory {MODULE_PATH} not found. Check the repository structure.')\n",
    "    \n",
    "    # Set working directory to the notebook's folder\n",
    "    os.chdir(MODULE_PATH)\n",
    "    \n",
    "    # Verify dataset is accessible\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        print(f'Dataset found: {DATASET_PATH} ü¶õ')\n",
    "    else:\n",
    "        print(f'Error: Dataset {DATASET} not found after cloning.')\n",
    "        raise FileNotFoundError\n",
    "except Exception as e:\n",
    "    print(f'Cloning failed: {e}')\n",
    "    print('Falling back to manual upload option...')\n",
    "\n",
    "    # Step 2: Manual upload option\n",
    "    print(f'Please upload {DATASET} manually.')\n",
    "    print(f'1. Click the \"Choose Files\" button below.')\n",
    "    print(f'2. Select {DATASET} from your local machine.')\n",
    "    print(f'3. Ensure the file is placed in notebooks/{MODULE}/data/')\n",
    "    \n",
    "    # Create the data directory if it doesn't exist\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Prompt user to upload the dataset\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Check if the dataset was uploaded\n",
    "    if DATASET in uploaded:\n",
    "        with open(DATASET_PATH, 'wb') as f:\n",
    "            f.write(uploaded[DATASET])\n",
    "        print(f'Successfully uploaded {DATASET} to {DATASET_PATH} ü¶õ')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'Upload failed. Please ensure you uploaded {DATASET}.')\n",
    "\n",
    "# Install required packages for this notebook\n",
    "%pip install pandas numpy\n",
    "print('Python environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc73f7",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Step 1: Setting Up Python for the Hipponol Trial\n",
    "\n",
    "This section ensures you're ready to run the analyses in Google Colab or a local environment.\n",
    "\n",
    "## ‚úÖ Requirements\n",
    "\n",
    "\n",
    "You need the following Python packages:\n",
    "- `pandas`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `scipy`\n",
    "- `lifelines` (for survival analysis)\n",
    "- `cmdstanpy` (for Bayesian analysis, optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3195c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "%pip install lifelines\n",
    "%pip install pymc\n",
    "%pip install arviz\n",
    "\n",
    "\n",
    "# Import libraries for data manipulation, visualisation, and statistical analysis\n",
    "import pandas as pd            # For data manipulation and analysis\n",
    "import numpy as np             # For numerical operations\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import seaborn as sns          # For enhanced statistical visualisations\n",
    "from scipy.stats import ttest_ind, chi2_contingency  # For hypothesis testing\n",
    "\n",
    "# Import Bayesian modelling and visualisation libraries\n",
    "import pymc as pm              # For Bayesian statistical modelling\n",
    "import arviz as az             # For Bayesian inference visualisation\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import patsy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079da23",
   "metadata": {},
   "source": [
    "# üìä Baseline Comparison: Table 1\n",
    "\n",
    "This section generates a **Table 1** summary of participant characteristics by study group (Hipponol vs Control), including:\n",
    "\n",
    "- Means and standard deviations for continuous variables  \n",
    "- Frequencies and percentages for categorical variables  \n",
    "- Statistical comparison (t-test or chi-squared)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (adjust path as needed)\n",
    "df = pd.read_csv(\"data/hipponol_trial_data.csv\")\n",
    "\n",
    "# Create a copy to avoid modifying original\n",
    "df1 = df.copy()\n",
    "\n",
    "# Display first few rows\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbabef3",
   "metadata": {},
   "source": [
    "## üîç Table 1: Summary Function\n",
    "\n",
    "This cell builds a summary table comparing baseline characteristics across treatment groups using **standard Python libraries**:\n",
    "\n",
    "- **Numerical variables** (e.g., age, baseline BP) are compared using independent t-tests. We report mean ¬± standard deviation.\n",
    "- **Categorical variables** (e.g., gender, smoker) are compared using chi-squared tests, and shown as counts with percentages.\n",
    "\n",
    "The function `create_table1()`:\n",
    "\n",
    "- Takes the dataset and grouping column (e.g., \"`group`\") as input.\n",
    "- Returns a DataFrame summarising each variable by group, along with p-values for between-group comparisons.\n",
    "\n",
    "This approach is useful when you want:\n",
    "\n",
    "- Full control over what‚Äôs included in the table.\n",
    "- Clear, interpretable formatting for reports or publications.\n",
    "\n",
    "To avoid installing additional packages (e.g., tableone).\n",
    "\n",
    "üõ†Ô∏è This method aligns with **CONSORT guidelines** for reporting baseline characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8799368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table1_clean(data, group_col):\n",
    "    \"\"\"Create a clean Table 1: baseline characteristics by group.\"\"\"\n",
    "    if group_col not in data.columns:\n",
    "        raise KeyError(f\"Grouping column '{group_col}' not found in DataFrame.\")\n",
    "    \n",
    "    group_names = data[group_col].unique()\n",
    "    if len(group_names) != 2:\n",
    "        raise ValueError(\"This function currently supports exactly two groups.\")\n",
    "\n",
    "    group1, group2 = group_names\n",
    "    summary = []\n",
    "\n",
    "    numeric_cols = ['Age', 'Baseline_SBP']\n",
    "    cat_cols = ['Sex', 'SmokingStatus']\n",
    "\n",
    "    # Continuous variables\n",
    "    for col in numeric_cols:\n",
    "        vals1 = data[data[group_col] == group1][col].dropna()\n",
    "        vals2 = data[data[group_col] == group2][col].dropna()\n",
    "        mean1, std1 = vals1.mean(), vals1.std()\n",
    "        mean2, std2 = vals2.mean(), vals2.std()\n",
    "        t_stat, p_val = ttest_ind(vals1, vals2)\n",
    "\n",
    "        summary.append({\n",
    "            'Variable': col,\n",
    "            f'{group1} (Mean ¬± SD)': f'{mean1:.1f} ¬± {std1:.1f}',\n",
    "            f'{group2} (Mean ¬± SD)': f'{mean2:.1f} ¬± {std2:.1f}',\n",
    "            'p-value': f'{p_val:.3f}'\n",
    "        })\n",
    "\n",
    "    # Categorical variables\n",
    "    for col in cat_cols:\n",
    "        cont_table = pd.crosstab(data[col], data[group_col])\n",
    "        chi2, p_val, _, _ = chi2_contingency(cont_table)\n",
    "\n",
    "        for i, cat in enumerate(cont_table.index):\n",
    "            row = {\n",
    "                'Variable': f\"{col} = {cat}\",\n",
    "                f'{group1} (Count %)': f\"{cont_table.loc[cat, group1]} ({cont_table.loc[cat, group1] / cont_table[group1].sum() * 100:.1f}%)\",\n",
    "                f'{group2} (Count %)': f\"{cont_table.loc[cat, group2]} ({cont_table.loc[cat, group2] / cont_table[group2].sum() * 100:.1f}%)\",\n",
    "                'p-value': f\"{p_val:.3f}\" if i == 0 else ''\n",
    "            }\n",
    "            summary.append(row)\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "\n",
    "# Create and show Table 1\n",
    "\n",
    "table1_df = create_table1_clean(df1, group_col='Group')\n",
    "display(table1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46912033",
   "metadata": {},
   "source": [
    "## üìä Exploring Distributions\n",
    "Before diving into inferential statistics, it's crucial to understand the **distribution** of our variables. This helps us:\n",
    "\n",
    "- Check whether groups are comparable\n",
    "- Identify outliers or skewed data\n",
    "- Decide which statistical tests are appropriate (e.g., parametric vs. non-parametric)\n",
    "\n",
    "### üéØ Focus: Baseline Blood Pressure and Age\n",
    "\n",
    "For this study, we‚Äôll explore:\n",
    "\n",
    "- **Age**\n",
    "- **Baseline Systolic Blood Pressure (SBP)**\n",
    "\n",
    "These continuous variables should ideally be similarly distributed across the control and intervention groups if randomisation was successful.\n",
    "\n",
    "--- \n",
    "\n",
    "## üîç Visualising Distributions\n",
    "\n",
    "We can use the following plots to explore the distribution:\n",
    "\n",
    "- **Histogram**: Shows the shape of the distribution (e.g. normal, skewed)\n",
    "- **Boxplot**: Useful for comparing groups and spotting outliers\n",
    "- **Violin plot (*optional*)**: Combines boxplot with a kernel density estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5de39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot: Distribution of Age\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(data=df1, x='Age', hue='Group', kde=True, bins=20)\n",
    "plt.title('Age Distribution by Group')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Plot: Baseline Systolic BP\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df1, x='Group', y='Baseline_SBP')\n",
    "plt.title('Baseline Systolic Blood Pressure by Group')\n",
    "plt.ylabel('Systolic BP (mmHg)')\n",
    "plt.xlabel('')\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Violin plot of Baseline Systolic BP\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.violinplot(data=df1, x='Group', y='Baseline_SBP', inner='box')\n",
    "plt.title('Violin Plot: Baseline Systolic Blood Pressure by Group')\n",
    "plt.ylabel('Systolic BP (mmHg)')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b8701",
   "metadata": {},
   "source": [
    "### üí° Interpretation Tips\n",
    "\n",
    "- Look for symmetry or skewness.\n",
    "\n",
    "- Check for group overlap‚Äîsimilar distributions are a good sign of effective randomisation.\n",
    "\n",
    "- Use this to support your interpretation of Table 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555223c",
   "metadata": {},
   "source": [
    "# Primary endpoint\n",
    "## üß¨ Analysing Survival Outcomes\n",
    "\n",
    "The primary endpoint of the Hipponol trial is **2-year survival**, coded as:\n",
    "\n",
    "- 1 = **Survived\n",
    "- 0 = **Died during follow-up**\n",
    "\n",
    "Survival data is binary and typically analysed using methods suited to categorical outcomes or time-to-event data (e.g. Cox models, Kaplan‚ÄìMeier). In our case, we assume **binary survival** at 2 years, so logistic regression is appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64bcd57",
   "metadata": {},
   "source": [
    "### üß™ Quick Check: Chi-squared Test for Survival\n",
    "Before diving into regression models, we can start with a simple comparison of survival rates between the Hipponol and Control groups using a Chi-squared test.\n",
    "\n",
    "‚úÖ Why use it?\n",
    "\n",
    "- It's a straightforward way to compare **proportions** between two groups.\n",
    "- Useful for **binary outcomes** like survival (1 = survived, 0 = died).\n",
    "- Helps confirm whether survival rates differ **significantly** between the two groups.\n",
    "\n",
    "üßæ Method\n",
    "\n",
    "We use a **contingency table** to count survivors and non-survivors in each group, then apply the **Chi-squared test of independence**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency = pd.crosstab(df1['Group'], df1['Survival'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency)\n",
    "print(f\"Chi-squared test p-value: {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf8f9a",
   "metadata": {},
   "source": [
    "üìå Interpretation\n",
    "\n",
    "- A **small p-value** (typically < 0.05) suggests a **statistically significant** difference in survival between groups.\n",
    "- This test **does not account for confounders** like age or smoking ‚Äî use logistic regression for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bb0ff",
   "metadata": {},
   "source": [
    "## üîé Logistic Regression\n",
    "\n",
    "Once we‚Äôve done a basic comparison (like a Chi-squared test), the next step is a **logistic regression**. This lets us model the probability of survival while also:\n",
    "\n",
    "- Controlling for other variables (e.g. age, smoking)\n",
    "- Estimating odds ratios, which are easier to interpret than raw coefficients\n",
    "\n",
    "### üí° What is logistic regression?\n",
    "\n",
    "Logistic regression is used when your outcome is **binary** ‚Äî in this case, survival (`1`) vs. death (`0`). It models the log-odds of survival as a function of one or more predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Fit a logistic regression model\n",
    "logit_model = smf.logit('Survival ~ Group', data=df1).fit()\n",
    "\n",
    "# Print summary\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29148c5d",
   "metadata": {},
   "source": [
    "üîÅ From log-odds to odds ratio\n",
    "\n",
    "The model estimates **log-odds**, which are not intuitive. We convert them to **odds ratios** using the exponential function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratios = logit_model.params.apply(np.exp)\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c5363",
   "metadata": {},
   "source": [
    "An odds ratio (OR):\n",
    "\n",
    "- = 1 means no effect\n",
    "- > 1 means increased odds (e.g. Hipponol improves survival)\n",
    "- < 1 means reduced odds (e.g. Hipponol worsens survival)\n",
    "\n",
    "### üìå Example Interpretation\n",
    "\n",
    "If `Group[T.Hipponol]` has an OR of `1.6`:\n",
    "\n",
    "> \"Participants in the Hipponol group had 60% higher odds of surviving the 2-year follow-up compared to the control group.\"\n",
    "\n",
    "### üìé Optional: Add other variables\n",
    "\n",
    "You can also control for age, sex, and smoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86001f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_full = smf.logit('Survival ~ Group + Age + C(Sex) + C(SmokingStatus)', data=df1).fit()\n",
    "print(logit_full.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14edf2f",
   "metadata": {},
   "source": [
    "This gives you adjusted odds ratios ‚Äî a better estimate when multiple factors influence the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942bd92",
   "metadata": {},
   "source": [
    "### üìè Confidence Intervals for Odds Ratios\n",
    "\n",
    "When you run a logistic regression, the model provides **standard errors** for the coefficients. You can use these to calculate a 95% confidence interval (CI) for each odds ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confidence intervals for the log-odds\n",
    "conf = logit_model.conf_int()\n",
    "conf.columns = ['2.5%', '97.5%']\n",
    "\n",
    "# Add odds ratios\n",
    "conf_exp = np.exp(conf)\n",
    "conf_exp['Odds Ratio'] = np.exp(logit_model.params)\n",
    "\n",
    "print(conf_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007860f",
   "metadata": {},
   "source": [
    "### üß† How to interpret this:\n",
    "\n",
    "If the 95% CI for an odds ratio:\n",
    "- Includes 1, the result is **not statistically significant** at p < 0.05\n",
    "- Excludes 1, then the effect is **statistically significant**\n",
    "\n",
    "### üìå Example:\n",
    "\n",
    "| Variable         | OR   | 2.5% | 97.5% |\n",
    "|------------------|------|------|-------|\n",
    "| Group[T.Hipponol] | 1.62 | 1.02 | 2.58  |\n",
    "\n",
    "---\n",
    "\n",
    "> _\"The odds of survival in the Hipponol group are 62% higher than in the control group (95% CI: 1.02‚Äì2.58).\"\n",
    "\n",
    "This suggests a **statistically significant effect**, as the interval does not include 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79d3c1",
   "metadata": {},
   "source": [
    "## Bayesian Logistic Regression ‚Äì Survival\n",
    "\n",
    "In this section, we apply **Bayesian logistic regression** to evaluate whether assignment to the **Hipponol** group affects the **probability of survival** compared to the **Control** group.\n",
    "\n",
    "This analysis complements the Frequentist approach by offering a full **posterior distribution** of the treatment effect, providing a probabilistic interpretation of results rather than just point estimates and p-values.\n",
    "\n",
    "### üßÆ Why Bayesian?\n",
    "\n",
    "Bayesian modelling is particularly useful when:\n",
    "\n",
    "- You want **probabilistic interpretations** of effect size.\n",
    "- You have **prior knowledge** you wish to incorporate. \n",
    "- You want a **posterior distribution** instead of a point estimate.\n",
    "- You're dealing with **small samples**, where Frequentist power is limited.\n",
    "\n",
    "In our case, we use **weakly informative** priors (e.g. Normal(0, 10)) to express general uncertainty without strong assumptions.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Goal\n",
    "\n",
    "We aim to:\n",
    "\n",
    "- Estimate the **posterior probability distribution** of the survival effect due to Hipponol.\n",
    "- Quantify the **uncertainty** in this effect.\n",
    "- Calculate the **posterior odds ratio** for survival in the Hipponol group compared to Control.\n",
    "\n",
    "Bayesian inference allows us to express the result as:\n",
    "\n",
    "> _‚ÄúThere is a XX% probability that Hipponol increases survival compared to control.‚Äù_\n",
    "\n",
    "This is fundamentally different from the Frequentist interpretation, which only tells us the probability of observing our data under the null hypothesis.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Define Predictor and Outcome\n",
    "\n",
    "To build our model, we first define the **predictor** (treatment group) and **outcome** (survival).\n",
    "\n",
    "- `X`: A binary predictor indicating group membership  \n",
    "  `0 = Control`, `1 = Hipponol`\n",
    "\n",
    "- `y`: A binary outcome  \n",
    "  `0 = Did not survive`, `1 = Survived`\n",
    "\n",
    "This mirrors the structure required for **Bernoulli trials**, where each observation represents a binary outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert group to numeric: 0 = Control, 1 = Hipponol\n",
    "X = (df['Group'] == 'Hipponol').astype(int).values\n",
    "\n",
    "# Survival outcome: already coded as 0 = no, 1 = yes\n",
    "y = df['Survival'].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d992e20",
   "metadata": {},
   "source": [
    "Next, we build and fit the Bayesian model using PyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c3a7b",
   "metadata": {},
   "source": [
    "## üîß Step-by-Step: Bayesian Logistic Regression in PyMC\n",
    "\n",
    "We now construct and sample from a **Bayesian logistic regression model** using `PyMC`. This model estimates the effect of group assignment (Hipponol vs Control) on the probability of survival.\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Model Structure\n",
    "\n",
    "1. **Data**:  \n",
    "   - `x_shared`: Encodes treatment group (0 = Control, 1 = Hipponol)  \n",
    "   - `y_shared`: Binary survival outcome (0 = no, 1 = yes)\n",
    "\n",
    "2. **Priors**:  \n",
    "   - `Intercept`: Prior belief about survival probability in the Control group.  \n",
    "     ‚Üí Set as `Normal(0, 10)` to reflect wide uncertainty.\n",
    "   - `Beta_Group`: Prior for the effect of the Hipponol group.  \n",
    "     ‚Üí Also `Normal(0, 10)` (can be tightened if prior knowledge exists).\n",
    "\n",
    "3. **Logistic function**:  \n",
    "   - Computes log-odds: `logit_p = intercept + beta_group * x_shared`  \n",
    "   - Converts to probability via sigmoid: `p = sigmoid(logit_p)`\n",
    "\n",
    "4. **Likelihood**:  \n",
    "   - Models observed survival data as a Bernoulli trial with success probability `p`.\n",
    "\n",
    "5. **Sampling**:  \n",
    "   - We use Hamiltonian Monte Carlo (HMC) via the NUTS sampler.  \n",
    "   - 4 chains √ó 2000 draws each, with 1000 tuning samples per chain.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ PyMC Model Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Data containers (for flexibility in updating)\n",
    "    x_shared = pm.Data(\"x_shared\", X)\n",
    "    y_shared = pm.Data(\"y_shared\", y)\n",
    "\n",
    "    # Priors\n",
    "    intercept = pm.Normal(\"Intercept\", mu=0, sigma=10)\n",
    "    beta_group = pm.Normal(\"Beta_Group\", mu=0, sigma=10)\n",
    "\n",
    "    # Logistic function\n",
    "    logit_p = intercept + beta_group * x_shared\n",
    "    p = pm.Deterministic(\"p\", pm.math.sigmoid(logit_p))\n",
    "\n",
    "    # Likelihood\n",
    "    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=y_shared)\n",
    "\n",
    "    # Sampling from the posterior\n",
    "    trace = pm.sample(2000, tune=1000, target_accept=0.95, return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3b002",
   "metadata": {},
   "source": [
    "üîç Next Steps\n",
    "After sampling, we will:\n",
    "\n",
    "- **Inspect the posterior** of Beta_Group to assess the treatment effect.\n",
    "- **Convert** this to an **odds ratio** (by exponentiating Beta_Group).\n",
    "- **Visualise** the posterior distribution using `arviz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510711a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior for Beta_Group\n",
    "az.plot_posterior(trace, var_names=['Beta_Group'], ref_val=0)\n",
    "plt.title(\"Posterior Distribution: Group Effect (log-odds)\")\n",
    "plt.show()\n",
    "\n",
    "# Convert to odds ratio\n",
    "odds_ratios = np.exp(trace.posterior['Beta_Group'].values.flatten())\n",
    "\n",
    "# Plot posterior odds ratio\n",
    "az.plot_posterior(odds_ratios, ref_val=1)\n",
    "plt.title(\"Posterior Odds Ratio: Hipponol vs Control\")\n",
    "plt.xlabel(\"Odds Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15081ef",
   "metadata": {},
   "source": [
    "### üß† Interpretation\n",
    "\n",
    "- If the **posterior** of Beta_Group is mostly above 0 ‚Üí **Hipponol increases odds of survival**.\n",
    "- If the **95% credible interval (HDI)** for odds_ratios excludes 1 ‚Üí **strong evidence for a difference**.\n",
    "\n",
    "You can compute az.hdi() for numeric intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.hdi(odds_ratios, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9bb2ed",
   "metadata": {},
   "source": [
    "‚úÖ This Bayesian approach allows for **direct probability statements**:\n",
    "\n",
    "‚ÄúThere is a 95% probability that Hipponol increases the odds of survival by X‚ÄìY%.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d913833",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Kaplan‚ÄìMeier Survival Curves\n",
    "\n",
    "To visualise how survival changes over time in each group, we use **Kaplan‚ÄìMeier survival estimates**. These curves provide a non-parametric estimate of the survival function, which reflects the probability of survival beyond a given time point.\n",
    "\n",
    "### üîç Why Kaplan‚ÄìMeier?\n",
    "\n",
    "Kaplan‚ÄìMeier curves are ideal for visualising time-to-event data because they:\n",
    "\n",
    "- Handle censored data (participants who didn‚Äôt experience the event by the end of follow-up)\n",
    "- Show the proportion of participants surviving over time\n",
    "- Allow intuitive comparison between groups (e.g. Hipponol vs Control)\n",
    "\n",
    "### üìò Interpretation\n",
    "\n",
    "Each drop in the curve corresponds to an event (e.g. death). A steeper decline indicates more frequent events, whereas a flat curve suggests stable survival.\n",
    "\n",
    "If the curves for the two groups diverge:\n",
    "\n",
    "- **Wider separation** may indicate a meaningful difference in survival.\n",
    "- **Overlap** suggests similar survival patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "df_control = df[df['Group'] == 'Control']\n",
    "df_hipponol = df[df['Group'] == 'Hipponol']\n",
    "\n",
    "# Initialise fitter\n",
    "kmf_control = KaplanMeierFitter()\n",
    "kmf_hipponol = KaplanMeierFitter()\n",
    "\n",
    "# Fit and plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "kmf_control.fit(durations=df_control['Time_to_Event'],\n",
    "                event_observed=df_control['Survival'],\n",
    "                label='Control')\n",
    "kmf_control.plot_survival_function(ci_show=True)\n",
    "\n",
    "kmf_hipponol.fit(durations=df_hipponol['Time_to_Event'],\n",
    "                 event_observed=df_hipponol['Survival'],\n",
    "                 label='Hipponol')\n",
    "kmf_hipponol.plot_survival_function(ci_show=True)\n",
    "\n",
    "plt.title(\"Kaplan‚ÄìMeier Survival Curves by Group\")\n",
    "plt.xlabel(\"Time to Event (months)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a42062",
   "metadata": {},
   "source": [
    "## üß™ Compare groups statistically ‚Äì Log-rank test\n",
    "This checks whether the survival distributions are significantly different between the groups.\n",
    "\n",
    "### üîç What is the Log-Rank Test?\n",
    "The **log-rank test** is a non-parametric statistical test used to compare the survival distributions of two or more groups. It's particularly useful in clinical trials or studies with time-to-event data.\n",
    "\n",
    "‚úÖ What it does:\n",
    "\n",
    "- Compares the observed number of events in each group to the expected number under the null hypothesis (that all groups have the same survival curve).\n",
    "- It handles **censored data** properly.\n",
    "- Outputs a **p-value**: if this is small (typically < 0.05), it suggests the survival curves differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Filter your data\n",
    "df_control = df[df[\"Group\"] == \"Control\"]\n",
    "df_hipponol = df[df[\"Group\"] == \"Hipponol\"]\n",
    "\n",
    "# Run the log-rank test\n",
    "results = logrank_test(\n",
    "    df_control[\"Time_to_Event\"], df_hipponol[\"Time_to_Event\"],\n",
    "    event_observed_A=df_control[\"Survival\"],\n",
    "    event_observed_B=df_hipponol[\"Survival\"]\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"üìà Log-rank test between Control and Hipponol:\")\n",
    "print(f\"Test statistic: {results.test_statistic:.3f}\")\n",
    "print(f\"p-value: {results.p_value:.4f}\")\n",
    "\n",
    "# Optional: simple interpretation\n",
    "if results.p_value < 0.05:\n",
    "    print(\"‚ö†Ô∏è There is a significant difference in survival between groups.\")\n",
    "else:\n",
    "    print(\"‚úÖ No significant difference in survival between groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9713a",
   "metadata": {},
   "source": [
    "### üß™ When to Use:\n",
    "Use this when:\n",
    "\n",
    "- You‚Äôve plotted Kaplan-Meier curves and want to **test if the difference is significant**.\n",
    "- You‚Äôre evaluating **intervention effects** in RCTs or cohort studies.\n",
    "- You want a simple test without assuming specific hazard functions (unlike Cox models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bf3cb",
   "metadata": {},
   "source": [
    "\n",
    "## Cox Proportional Hazards Model: A Detailed Guide\n",
    "\n",
    "### ‚úÖ What Is the Cox Proportional Hazards Model?\n",
    "\n",
    "The **Cox PH model** is a **semi-parametric regression model** used in survival analysis. It relates the time that passes before an event occurs to **one or more covariates**.\n",
    "\n",
    "### Core idea:\n",
    "It models the **hazard rate** at time *t* as:\n",
    "\n",
    "\\[\n",
    "h(t|X) = h_0(t) \\cdot \\exp(\\beta_1X_1 + \\beta_2X_2 + \\ldots + \\beta_pX_p)\n",
    "\\]\n",
    "\n",
    "- \\( h_0(t) \\) is the **baseline hazard** (unspecified)\n",
    "- \\( X_i \\) are the covariates (e.g. Group, Age, Sex)\n",
    "- \\( \\beta_i \\) are coefficients estimated from the data\n",
    "\n",
    "The model makes the **proportional hazards assumption**: the ratio of hazards between groups is constant over time.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è 2. How to Fit It in Python (with `lifelines`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b016fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Select relevant columns only\n",
    "df_cox = df[[\"Age\", \"Sex\", \"SmokingStatus\", \"Group\", \"Time_to_Event\", \"Survival\"]].copy()\n",
    "\n",
    "# One-hot encode categorical variables, dropping first category to avoid multicollinearity\n",
    "df_cox = pd.get_dummies(df_cox, drop_first=True)\n",
    "\n",
    "# Fit the Cox model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_cox, duration_col=\"Time_to_Event\", event_col=\"Survival\")\n",
    "\n",
    "# Print the summary\n",
    "cph.print_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaec304",
   "metadata": {},
   "source": [
    "\n",
    "### üìè How to Interpret the Output\n",
    "\n",
    "The summary table includes:\n",
    "\n",
    "- `coef`: log of the hazard ratio (HR)\n",
    "- `exp(coef)`: the **hazard ratio**\n",
    "- `p`: p-value testing if the coefficient is significantly different from 0\n",
    "- `-log2(p)`: significance in a log-scale\n",
    "- `95% CI`: confidence intervals for the HR\n",
    "\n",
    "### Example Interpretation:\n",
    "\n",
    "| Variable              | exp(coef) | p-value | Interpretation |\n",
    "|----------------------|-----------|---------|----------------|\n",
    "| Group_Hipponol       | 0.65      | 0.001   | Hipponol **reduces** the hazard by 35% vs. Control |\n",
    "| Age                  | 1.02      | 0.050   | Each year of age **increases** hazard by 2% |\n",
    "| Sex_Male             | 1.10      | 0.200   | No significant difference vs. Female |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Test the Proportional Hazards (PH) Assumption\n",
    "\n",
    "This is **essential** because if PH is violated, your hazard ratios are **not valid over time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40dc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check proportional hazards assumption\n",
    "cph.check_assumptions(df_cox, p_value_threshold=0.05, show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15ebf9",
   "metadata": {},
   "source": [
    "\n",
    "- Print a test result for each covariate\n",
    "- Show **Schoenfeld residuals** plots:\n",
    "  - If residuals show **systematic trends**, PH is **likely violated**\n",
    "  - Flat residuals = good\n",
    "\n",
    "### If PH is violated:\n",
    "- Add **interaction terms with time**\n",
    "- Use **stratified Cox models**\n",
    "- Split time into intervals (time-dependent covariates)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b282a11",
   "metadata": {},
   "source": [
    "\n",
    "### üß™ 5. (Optional) Predict or Visualise\n",
    "\n",
    "You can predict survival curves for a given profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1097f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a base profile (mean age, female, non-smoker)\n",
    "base = pd.DataFrame({\n",
    "    'Age': [df['Age'].mean()],\n",
    "    'Sex_Male': [0],\n",
    "    'SmokingStatus_Smoker': [0],\n",
    "    'Group_Hipponol': [0]  # Control group\n",
    "})\n",
    "\n",
    "# Copy and modify for Hipponol\n",
    "hipponol = base.copy()\n",
    "hipponol['Group_Hipponol'] = 1  # Switch to Hipponol group\n",
    "\n",
    "# Predict survival curves\n",
    "sf_control = cph.predict_survival_function(base)\n",
    "sf_hipponol = cph.predict_survival_function(hipponol)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sf_control, label=\"Control\")\n",
    "plt.plot(sf_hipponol, label=\"Hipponol\")\n",
    "plt.title(\"Predicted Survival Curve for Control vs. Hipponol\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01b494",
   "metadata": {},
   "source": [
    "# üß™ Secondary Endpoint: Blood Pressure Change\n",
    "\n",
    "This section explores how to compare systolic blood pressure (SBP) outcomes between the treatment group (`Hipponol`) and the control group. SBP is treated as a          ‚Ü™continuous variable, and we are particularly interested in:\n",
    "\n",
    "- Whether there are baseline differences\n",
    "- Whether the groups differ at follow-up\n",
    "- Whether **Hipponol** leads to a greater reduction in SBP than the control\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üé® Visual Exploration of Distributions\n",
    "\n",
    "Before diving into formal tests, it's useful to examine the data visually. You can compare the SBP distributions for the two groups at:\n",
    "\n",
    "### Baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cdc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up SBP distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(data=df, x='Baseline_SBP', hue='Group', fill=True, common_norm=False, alpha=0.4)\n",
    "plt.title(\"Follow-up SBP Distribution by Group\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da03f4",
   "metadata": {},
   "source": [
    "### Follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up SBP distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(data=df, x='Followup_SBP', hue='Group', fill=True, common_norm=False, alpha=0.4)\n",
    "plt.title(\"Follow-up SBP Distribution by Group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025a6bc",
   "metadata": {},
   "source": [
    "### Change in Blood Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SBP_change'] = df['Followup_SBP'] - df['Baseline_SBP']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(data=df, x='SBP_change', hue='Group', fill=True, common_norm=False, alpha=0.4)\n",
    "plt.title(\"Change in SBP (Follow-up ‚Äì Baseline) by Group\")\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eae18a",
   "metadata": {},
   "source": [
    "\n",
    "## üîç t-Test for Comparing Change in SBP Between Two Groups\n",
    "\n",
    "### What is it?\n",
    "\n",
    "A **two-sample t-test** (also called an **independent samples t-test**) is used to determine whether there is a **statistically significant difference** in the **means  ‚Ü™of a continuous variable** between two **independent groups**.\n",
    "\n",
    "In this case, we're interested in:\n",
    "\n",
    "> **Is the average change in SBP significantly different between participants in the Control group and those in the Hipponol group?**\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ When to use it\n",
    "\n",
    "Use a two-sample t-test when:\n",
    "- The outcome variable (here: `SBP change = Followup_SBP ‚àí Baseline_SBP`) is continuous.\n",
    "- The two groups are **independent** (no participant is in both groups).\n",
    "- The data are approximately **normally distributed** in each group.\n",
    "- Variances are assumed to be **equal** (although Welch's correction can be used otherwise).\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Hypotheses\n",
    "\n",
    "Let:\n",
    "- \\( \\mu_1 \\): mean change in SBP in the **Control** group\n",
    "- \\( \\mu_2 \\): mean change in SBP in the **Hipponol** group\n",
    "\n",
    "Then:\n",
    "\n",
    "- **Null hypothesis \\( H_0 \\)**: \\( \\mu_1 = \\mu_2 \\) (no difference)\n",
    "- **Alternative hypothesis \\( H_A \\)**: \\( \\mu_1 \\ne \\mu_2 \\) (there is a difference)\n",
    "\n",
    "You can also use a **one-sided test** if you expect Hipponol to reduce SBP.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23674baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hip = df[df['Group'] == 'Hipponol']['SBP_change']\n",
    "con = df[df['Group'] == 'Control']['SBP_change']\n",
    "con = df[df['Group'] == 'Control']['SBP_change']\n",
    "\n",
    "# Mean difference\n",
    "diff = hip.mean() - con.mean()\n",
    "\n",
    "# Standard error of the difference\n",
    "se_diff = np.sqrt(hip.var(ddof=1)/len(hip) + con.var(ddof=1)/len(con))\n",
    "\n",
    "# 95% Confidence Interval\n",
    "dof = len(hip) + len(con) - 2\n",
    "ci = stats.t.interval(0.95, dof, loc=diff, scale=se_diff)\n",
    "\n",
    "# t-test\n",
    "t_stat, p_val = ttest_ind(hip, con)\n",
    "\n",
    "print(f\"Mean difference: {diff:.2f} mmHg\")\n",
    "print(f\"95% CI: {ci}\")\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880a5b0",
   "metadata": {},
   "source": [
    "\n",
    "## üßæ Interpreting results\n",
    "\n",
    "- A **small p-value** (typically < 0.05) means you reject the null hypothesis and conclude that **SBP change differs significantly** between the groups.\n",
    "- A **large p-value** suggests that the observed difference might be due to chance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9363441",
   "metadata": {},
   "source": [
    "## üß™ ANOVA and ANCOVA\n",
    "\n",
    "### Analysis of Variance (ANOVA)\n",
    "\n",
    "**ANOVA** is used to determine whether there are statistically significant differences in the means of a continuous variable across two or more groups.\n",
    "\n",
    "In our case, we can use **one-way ANOVA** to compare the change in systolic blood pressure (SBP) between the `Control` and `Hipponol` groups.\n",
    "\n",
    "### üîç Assumptions:\n",
    "- Independence of observations\n",
    "- Normally distributed SBP changes within each group\n",
    "- Homogeneity of variances across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df is your DataFrame and has already loaded the dataset\n",
    "df['SBP_Change'] = df['Followup_SBP'] - df['Baseline_SBP']\n",
    "\n",
    "# Split by group\n",
    "control = df[df['Group'] == 'Control']['SBP_Change']\n",
    "hipponol = df[df['Group'] == 'Hipponol']['SBP_Change']\n",
    "\n",
    "# Run one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(control, hipponol)\n",
    "\n",
    "print(\"One-way ANOVA\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a185e6",
   "metadata": {},
   "source": [
    "### üß™ Comparison: t-test vs. ANOVA\n",
    "\n",
    "| Feature                        | **t-test**                                  | **ANOVA (one-way)**                         |\n",
    "|-------------------------------|---------------------------------------------|---------------------------------------------|\n",
    "| **Use case**                  | Comparing **two** group means               | Designed for comparing **three or more**    |\n",
    "| **Statistic reported**        | *t*-statistic                               | *F*-statistic                               |\n",
    "| **P-value**                   | Same as ANOVA when only 2 groups            | Same as t-test when only 2 groups           |\n",
    "| **Interpretation**            | Mean difference                             | Variance between vs. within groups          |\n",
    "| **Extension**                 | Needs other models for >2 groups            | Naturally extends to >2 group comparisons   |\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Mathematical Note\n",
    "\n",
    "When there are exactly **two groups**, the relationship between the statistics is:\n",
    "\n",
    "\\\\[\n",
    "F = t^2\n",
    "\\\\]\n",
    "\n",
    "So the numerical **p-value** and the result will be identical ‚Äî the difference is in the formulation.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use Each?\n",
    "\n",
    "- ‚úÖ **Use t-test**: when you are only comparing two groups and want the simplest approach.\n",
    "- ‚úÖ **Use ANOVA**: when you are planning to include more than two groups in future or need consistency in your analysis framework.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Practical Implication\n",
    "\n",
    "For the SBP change analysis with just Control and Hipponol:\n",
    "- Both methods are valid and will return the same **p-value**.\n",
    "- ANOVA provides more flexibility later (e.g., adjusting for other factors via ANCOVA or general linear models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c536241",
   "metadata": {},
   "source": [
    "### Analysis of Covariance (ANCOVA)\n",
    "\n",
    "**ANCOVA** extends ANOVA by including one or more **continuous covariates** that may influence the dependent variable. This is particularly useful when there are baseline differences between groups (e.g. in baseline SBP).\n",
    "\n",
    "In our context, ANCOVA allows us to compare the **Follow-up SBP**, adjusting for **Baseline SBP** as a covariate.\n",
    "\n",
    "#### üí° Why use ANCOVA?\n",
    "\n",
    "- It reduces residual variance, improving statistical power\n",
    "- It adjusts for potential imbalances in baseline values\n",
    "\n",
    "#### üîç Assumptions:\n",
    "\n",
    "- Same as ANOVA, plus:\n",
    "  - Linearity between covariate and outcome\n",
    "  - Homogeneity of regression slopes (no interaction between group and covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Group to categorical if needed\n",
    "df['Group'] = df['Group'].astype('category')\n",
    "\n",
    "# Fit ANCOVA model\n",
    "model = smf.ols('Followup_SBP ~ Group + Baseline_SBP + Age + Sex + SmokingStatus', data=df).fit()\n",
    "\n",
    "# Show summary\n",
    "print(model.summary())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a57c4",
   "metadata": {},
   "source": [
    "üìä Notes\n",
    "\n",
    "- ANOVA checks whether the mean changes in SBP differ between groups.\n",
    "- ANCOVA goes further by adjusting for baseline SBP, increasing statistical power and controlling for initial differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f222f",
   "metadata": {},
   "source": [
    "\n",
    "# Regression Analysis: Blood Pressure Change\n",
    "\n",
    "To assess the relationship between treatment group and change in systolic blood pressure (SBP), a linear regression model can be used. This allows us to estimate the **magnitude** of the treatment effect while optionally adjusting for **confounders** like age, sex, and smoking status.\n",
    "\n",
    "#### üì¶ Step 1: Compute SBP Change\n",
    "#### üîß Step 2: Encode the Treatment Group\n",
    "\n",
    "To use `Group` in regression, convert it into a numeric variable. We'll use **0 = Control**, **1 = Hipponol**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SBP_Change'] = df['Followup_SBP'] - df['Baseline_SBP']\n",
    "df['Treatment'] = (df['Group'] == 'Hipponol').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b8241",
   "metadata": {},
   "source": [
    "#### üìä Step 3: Fit the regression model\n",
    "\n",
    "This will estimate the **mean difference in SBP change** between the two groups. The intercept represents the mean change in the Control group, and the coefficient for `Treatment` represents the **additional change** for the Hipponol group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = smf.ols('SBP_Change ~ Treatment', data=df).fit()\n",
    "\n",
    "# Show results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5d548",
   "metadata": {},
   "source": [
    "\n",
    "## üßÆ Step 4: Regression with Covariates (Optional)\n",
    "\n",
    "To adjust for potential confounders.\n",
    "\n",
    "Note: `Sex` and `SmokingStatus` should be treated as categorical variables. You may need to encode them using `C()` in the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_adj = smf.ols('SBP_Change ~ Treatment + Age + C(Sex) + C(SmokingStatus)', data=df).fit()\n",
    "print(model_adj.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061fd38",
   "metadata": {},
   "source": [
    "#### üìà Step 5: Visualise the Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode group as binary treatment (if not already done)\n",
    "df['Treatment'] = (df['Group'] == 'Hipponol').astype(int)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Add jittered individual points\n",
    "sns.stripplot(x='Treatment', y='SBP_Change', data=df,\n",
    "              jitter=0.2, size=5, alpha=0.6, color='grey')\n",
    "\n",
    "# Add group means and error bars (95% CI)\n",
    "sns.pointplot(x='Treatment', y='SBP_Change', data=df,\n",
    "              linestyle='none', capsize=0.1, err_kws={'linewidth': 1.5}, color='blue')\n",
    "\n",
    "# Customise axes\n",
    "plt.xticks([0, 1], ['Control', 'Hipponol'])\n",
    "plt.title('Change in Systolic Blood Pressure by Treatment Group')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.ylabel('Change in SBP (mmHg)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f584a",
   "metadata": {},
   "source": [
    "### üß† Interpretation\n",
    "\n",
    "- A **negative coefficient** for `Treatment` implies a greater **reduction** in SBP in the Hipponol group.\n",
    "- The **p-value** tells you whether this difference is statistically significant.\n",
    "- The **adjusted R¬≤** provides an indication of how much variance in SBP change is explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6005d",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Bayesian Regression Analysis (SBP Change)\n",
    "\n",
    "This section uses a Bayesian approach to model the effect of treatment (`Hipponol` vs `Control`) on the change in systolic blood pressure (SBP), while adjusting for age, sex, and smoking status.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßπ Step 1: Data Preparation\n",
    "\n",
    "First, we calculate the change in SBP and encode the categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Step 2: Model Specification\n",
    "\n",
    "We model SBP change as a linear function of:\n",
    "\n",
    "- Age (standardised)\n",
    "- Sex (Female as reference)\n",
    "- Smoking Status (Non-smoker as reference)\n",
    "- Group (Control as reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_column(df, column, method='zscore'):\n",
    "    \"\"\"\n",
    "    Scales a column in the dataframe using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column: name of the column to scale\n",
    "    - method: 'zscore', 'minmax', 'robust', or 'maxabs'\n",
    "    \n",
    "    Returns:\n",
    "    - A pandas Series with the scaled values\n",
    "    \"\"\"\n",
    "    x = df[column]\n",
    "\n",
    "    if method == 'zscore':\n",
    "        return (x - x.mean()) / x.std()\n",
    "    elif method == 'minmax':\n",
    "        return (x - x.min()) / (x.max() - x.min())\n",
    "    elif method == 'robust':\n",
    "        median = x.median()\n",
    "        iqr = x.quantile(0.75) - x.quantile(0.25)\n",
    "        return (x - median) / iqr\n",
    "    elif method == 'maxabs':\n",
    "        return x / x.abs().max()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown scaling method. Choose 'zscore', 'minmax', 'robust', or 'maxabs'.\")\n",
    "\n",
    "\n",
    "\n",
    "# Assume df is already loaded\n",
    "df['SBP_Change'] = df['Followup_SBP'] - df['Baseline_SBP']\n",
    "\n",
    "# Ensure proper one-hot encoding\n",
    "df_encoded = pd.get_dummies(df[['SBP_Change', 'Age', 'Sex', 'SmokingStatus', 'Group']], drop_first=True)\n",
    "\n",
    "# Standardise age\n",
    "df_encoded['Age_Standardised'] = scale_column(df_encoded, 'Age')\n",
    "\n",
    "# Drop the unstandardised 'Age' column if not needed\n",
    "df_encoded = df_encoded.drop(columns='Age')\n",
    "\n",
    "# Ensure all columns are float (important for PyMC)\n",
    "X = df_encoded.drop(columns=['SBP_Change']).astype(float)\n",
    "y = df_encoded['SBP_Change'].astype(float)\n",
    "\n",
    "predictor_names = X.columns.tolist()\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Data containers\n",
    "    predictors = pm.Data(\"predictors\", X)\n",
    "    outcome = pm.Data(\"outcome\", y)\n",
    "\n",
    "    # Priors\n",
    "    intercept = pm.Normal(\"Intercept\", mu=0, sigma=10)\n",
    "    beta = pm.Normal(\"Beta\", mu=0, sigma=1, shape=len(predictor_names))\n",
    "    sigma = pm.HalfNormal(\"Sigma\", sigma=5)\n",
    "\n",
    "    # Linear model\n",
    "    mu = intercept + pm.math.dot(predictors, beta)\n",
    "\n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=outcome)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(2000, tune=1000, target_accept=0.95, return_inferencedata=True)\n",
    "\n",
    "trace.posterior = trace.posterior.rename({'Beta_dim_0': 'variable'})\n",
    "trace.posterior['variable'] = ('variable', predictor_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54830658",
   "metadata": {},
   "source": [
    "#### üìä Step 3: Posterior Summary\n",
    "\n",
    "After sampling from the posterior distribution using PyMC, we now have a large collection of samples (called the trace) representing the joint posterior distribution of the model parameters.\n",
    "\n",
    "The posterior summary allows us to understand:\n",
    "\n",
    "- **Central tendency** (e.g., mean or median of each parameter estimate)\n",
    "- **Uncertainty** (e.g., standard deviation or credible intervals)\n",
    "- **Effect direction and strength** (is the coefficient consistently above/below zero?)\n",
    "\n",
    "Here‚Äôs how to examine this in Python using arviz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, var_names=[\"Intercept\", \"Beta\", \"Sigma\"], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c486ed",
   "metadata": {},
   "source": [
    "- **Mean**: Posterior mean (expected value)\n",
    "- **SD**: Posterior standard deviation\n",
    "- **HDI (Highest Density Interval)**: The most credible interval containing 95% of the posterior probability mass. If this interval excludes 0, the effect is considered statistically credible (akin to 'significant').\n",
    "\n",
    "üß≠ How to interpret:\n",
    "- If the **HDI excludes zero**, it suggests a consistent effect (e.g., a real impact of the treatment).\n",
    "- If the **HDI includes zero**, there's high uncertainty about whether that variable truly affects the outcome.\n",
    "\n",
    "---\n",
    "üìà Plotting the posterior:\n",
    "\n",
    "Visualising the posterior is an intuitive way to understand the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55289fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace, var_names=[\"Beta\"], combined=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2af1f",
   "metadata": {},
   "source": [
    "## ‚úÖ Interpretation\n",
    "\n",
    "The key output here is the coefficient for `Group_Hipponol`. If its 95% Highest Posterior Density Interval (HDI) does not overlap with zero, there's strong evidence that `Hipponol` affects SBP change compared to control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5575c",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ Comparing Treatment Effects on SBP Change\n",
    "\n",
    "We evaluated the effect of the Hipponol intervention on the change in **systolic blood pressure (SBP)** using three different analytical approaches: a standard independent samples **T-test**, a classical **Ordinary Least Squares (OLS) regression**, and a **Bayesian regression model**. Each method provides an estimate of the mean difference in SBP change between the treatment (Hipponol) and control groups, along with a measure of uncertainty.\n",
    "\n",
    "## üîπ T-test\n",
    "The T-test compares the mean SBP change directly between the two groups, assuming equal variance. The estimated mean difference was statistically significant, indicating that the SBP change in the Hipponol group was different from the control group. This method provides a straightforward test of the null hypothesis with a confidence interval for the mean difference.\n",
    "\n",
    "- **Advantage**: Simple and easy to interpret.\n",
    "- **Limitation**: Does not adjust for potential confounders such as age, sex, or smoking status.\n",
    "\n",
    "## üîπ ANCOVA\n",
    "The Analysis of Covariance (ANCOVA) extends the OLS model by including baseline covariates‚Äîsuch as age, sex, and smoking status‚Äîto control for confounding and improve precision. This method adjusts the treatment effect for baseline imbalances and provides a more accurate estimate.\n",
    "\n",
    "- **Advantage**: Adjusts for potential confounders, improving estimate precision.\n",
    "- **Limitation**: Requires linear relationships between covariates and outcome, and assumes homogeneity of regression slopes.\n",
    "\n",
    "## üîπ OLS Regression\n",
    "The OLS regression treated group membership as a binary predictor for SBP change. The estimate from this model was numerically identical to the T-test result because no additional covariates were included. However, regression frameworks allow for the extension to multiple covariates and interaction terms.\n",
    "\n",
    "- **Advantage**: Can be extended to include confounders or interactions.\n",
    "- **Limitation**: Assumes linear relationships and homoscedasticity.\n",
    "\n",
    "## üîπ Bayesian Regression\n",
    "The Bayesian model estimated the treatment effect using probabilistic priors and provided a full posterior distribution for the treatment coefficient. The 95% Highest Density Interval (HDI) offers a Bayesian analogue to the confidence interval, interpreted as the range within which the true effect lies with 95% probability.\n",
    "\n",
    "- **Advantage**: Flexibility, intuitive probabilistic interpretation, and explicit incorporation of prior beliefs.\n",
    "- **Limitation**: Requires computational resources and careful choice of priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Assume df is already loaded and processed\n",
    "df['SBP_Change'] = df['Followup_SBP'] - df['Baseline_SBP']\n",
    "df['Treatment'] = (df['Group'] == 'Hipponol').astype(int)\n",
    "\n",
    "# --- T-test ---\n",
    "control = df[df['Treatment'] == 0]['SBP_Change']\n",
    "hipponol = df[df['Treatment'] == 1]['SBP_Change']\n",
    "\n",
    "t_stat, t_pval = stats.ttest_ind(hipponol, control)\n",
    "mean_diff = hipponol.mean() - control.mean()\n",
    "ci_low, ci_high = stats.t.interval(\n",
    "    0.95, df=len(control) + len(hipponol) - 2,\n",
    "    loc=mean_diff,\n",
    "    scale=stats.sem(np.concatenate([hipponol.values, -control.values]))\n",
    ")\n",
    "\n",
    "# --- OLS Regression ---\n",
    "model_adj = smf.ols('SBP_Change ~ Treatment + Age + C(Sex) + C(SmokingStatus)', data=df).fit()\n",
    "ols_estimate = model_adj.params['Treatment']\n",
    "ols_ci_low, ols_ci_high = model_adj.conf_int().loc['Treatment']\n",
    "\n",
    "\n",
    "# ANCOVA: Adjusting for age, sex, smoking\n",
    "df_ancova = df.copy()\n",
    "df_ancova = pd.get_dummies(df_ancova, columns=['Sex', 'SmokingStatus'], drop_first=True)\n",
    "formula = \"SBP_Change ~ Treatment + Age + Sex_Male + SmokingStatus_Smoker\"\n",
    "y_ancova, X_ancova = patsy.dmatrices(formula, data=df_ancova, return_type='dataframe')\n",
    "ancova_model = sm.OLS(y_ancova, X_ancova).fit()\n",
    "ancova_estimate = ancova_model.params['Treatment']\n",
    "ancova_ci_low, ancova_ci_high = ancova_model.conf_int().loc['Treatment']\n",
    "\n",
    "\n",
    "# --- Bayesian Regression ---\n",
    "with pm.Model() as model:\n",
    "    beta_0 = pm.Normal(\"Intercept\", mu=0, sigma=10)\n",
    "    beta_1 = pm.Normal(\"Treatment\", mu=0, sigma=5)\n",
    "    sigma = pm.HalfNormal(\"Sigma\", sigma=5)\n",
    "\n",
    "    mu = beta_0 + beta_1 * df['Treatment'].values\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=df['SBP_Change'])\n",
    "\n",
    "    trace = pm.sample(2000, tune=1000, target_accept=0.95, return_inferencedata=True)\n",
    "\n",
    "bayes_summary = az.summary(trace, var_names=[\"Treatment\"], hdi_prob=0.95)\n",
    "bayes_estimate = bayes_summary.loc[\"Treatment\", \"mean\"]\n",
    "bayes_hdi_low = bayes_summary.loc[\"Treatment\", \"hdi_2.5%\"]\n",
    "bayes_hdi_high = bayes_summary.loc[\"Treatment\", \"hdi_97.5%\"]\n",
    "\n",
    "# --- Comparison Table with Formatting ---\n",
    "effect_df = pd.DataFrame({\n",
    "    \"Method\": [\"T-test\", \"OLS regression\", \"ANCOVA\", \"Bayesian regression\"],\n",
    "    \"Estimate (mmHg)\": [mean_diff, ols_estimate, ancova_estimate, bayes_estimate],\n",
    "    \"95% CI Lower\": [ci_low, ols_ci_low, ancova_ci_low, bayes_hdi_low],\n",
    "    \"95% CI Upper\": [ci_high, ols_ci_high, ancova_ci_high, bayes_hdi_high]\n",
    "})\n",
    "\n",
    "# Round values for presentation\n",
    "effect_df = effect_df.round(2)\n",
    "\n",
    "print(effect_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08060c",
   "metadata": {},
   "source": [
    "\n",
    "### üîÑ Relationship Between ANCOVA and OLS Regression\n",
    "\n",
    "In this instance, **Analysis of Covariance (ANCOVA)** and **Ordinary Least Squares (OLS) regression** provide **identical results**‚Äîbut why is that the case?\n",
    "\n",
    "#### üß† Conceptual Overlap\n",
    "\n",
    "ANCOVA is essentially a special case of linear regression. Specifically, it combines:\n",
    "\n",
    "- **ANOVA**: for testing differences between categorical groups (e.g. treatment vs. control), and  \n",
    "- **Regression**: for adjusting these comparisons based on continuous or additional categorical covariates (e.g. age, sex, smoking status).\n",
    "\n",
    "Thus, ANCOVA is not a fundamentally different statistical method but rather a **framework for interpreting a linear model** that includes both categorical and continuous predictors. When implemented in software such as Python‚Äôs `statsmodels`, ANCOVA is conducted via the **same OLS regression engine** as any standard linear regression model.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìä Technical Equivalence\n",
    "\n",
    "The following model, framed as an OLS regression:\n",
    "\n",
    "```python\n",
    "model = smf.ols('SBP_Change ~ Treatment + Age + C(Sex) + C(SmokingStatus)', data=df).fit()\n",
    "```\n",
    "\n",
    "‚Ä¶is analytically identical to an ANCOVA testing the **effect of Treatment on SBP change**, **adjusting for Age, Sex, and Smoking Status**. The categorical variables are automatically dummy-coded, and the model estimates group differences while controlling for the covariates.\n",
    "\n",
    "Both approaches:\n",
    "- Estimate coefficients using least squares\n",
    "- Provide p-values, confidence intervals, and model diagnostics\n",
    "- Are suitable for continuous outcomes (like SBP change)\n",
    "\n",
    "---\n",
    "\n",
    "#### üßæ Summary\n",
    "\n",
    "| Term        | What it Emphasises                | Underlying Method |\n",
    "|-------------|-----------------------------------|-------------------|\n",
    "| **ANCOVA**  | Group comparison **with adjustment** | Linear regression |\n",
    "| **OLS Regression** | Flexible modelling of continuous outcomes | Linear regression |\n",
    "\n",
    "**‚úÖ Conclusion:**  \n",
    "Whether you call it ANCOVA or OLS regression, you're using the **same statistical engine**. The terminology difference mostly reflects **intent and interpretation**, not implementation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
