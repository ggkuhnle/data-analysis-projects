{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# üéõÔ∏è 6.3 Thematic Coding & Reliability\n",
        "\n",
        "Build a **transparent coding workflow**: define a codebook, code excerpts, review co-occurrence patterns, and (optionally) compute **inter-coder reliability**.\n",
        "\n",
        "We‚Äôll start from the `qual_coding_sheet.csv` exported in 6.2, but you can also paste your own."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "goals",
      "metadata": {},
      "source": [
        "## üéØ Objectives\n",
        "- Create and iterate a **codebook** (labels, definitions, examples).\n",
        "- Populate codes for each response (single or multi-label).\n",
        "- Summarise **code frequencies** and **co-occurrence**.\n",
        "- Calculate **Cohen‚Äôs Œ∫** for two coders on a subset.\n",
        "- Map codes ‚Üí **themes** and export a brief thematic summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deps",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pandas numpy scikit-learn seaborn matplotlib networkx",
        "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, networkx as nx",
        "from sklearn.metrics import cohen_kappa_score",
        "sns.set_theme()",
        "print('Environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load",
      "metadata": {},
      "source": [
        "## üì• Load coding sheet\n",
        "If you haven‚Äôt created one, run 6.2 to export `qual_coding_sheet.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "read_sheet",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path",
        "sheet = Path('qual_coding_sheet.csv')",
        "if not sheet.exists():",
        "    # Minimal fallback: create from raw file",
        "    raw = Path('data')/'food_preferences.txt'",
        "    responses = [r.strip() for r in raw.read_text(encoding='utf-8').splitlines() if r.strip()]",
        "    df = pd.DataFrame({'response_id': range(1, len(responses)+1), 'text': responses})",
        "    df['initial_code'] = ''; df['notes'] = ''",
        "    df.to_csv(sheet, index=False)",
        "df = pd.read_csv(sheet)",
        "df.head(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "codebook",
      "metadata": {},
      "source": [
        "## üìö Codebook (living document)\n",
        "Start small, iterate. Keep labels short; include inclusion/exclusion rules and examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "codebook_table",
      "metadata": {},
      "outputs": [],
      "source": [
        "codebook = pd.DataFrame({\n",
        "  'code': ['Preference:Fruit','Preference:Carrot','Preference:Grass','Texture:Crisp','Taste:Sweet','Barrier:Access','Context:Social'],\n",
        "  'definition': [\n",
        "    'Expressed liking for fruit (any type)',\n",
        "    'Specific mention of carrots as preferred',\n",
        "    'Preference or mention of grass as staple',\n",
        "    'Mentions of crisp/crunchy texture as desirable',\n",
        "    'Mentions of sweetness as desirable',\n",
        "    'Mentions of access/availability/cost barriers',\n",
        "    'Mentions of others/social influence (family/herd)'\n",
        "  ],\n",
        "  'example': [\n",
        "    '‚ÄúFruit is preferred on hot days.‚Äù',\n",
        "    '‚ÄúI enjoy crunchy carrots.‚Äù',\n",
        "    '‚ÄúGrass is acceptable‚Ä¶‚Äù',\n",
        "    '‚ÄúI like crunchy snacks.‚Äù',\n",
        "    '‚ÄúSweet foods are better.‚Äù',\n",
        "    '‚ÄúHard to find fresh produce.‚Äù',\n",
        "    '‚ÄúFriends influence what I eat.‚Äù'\n",
        "  ]\n",
        "})\n",
        "codebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apply_codes",
      "metadata": {},
      "source": [
        "## üè∑Ô∏è Apply codes (single or multiple)\n",
        "For quick demos, we‚Äôll **auto-suggest** codes via keyword rules, then you can **edit manually**. In practice, codes should be applied by trained coders reading each excerpt.\n",
        "\n",
        "<details><summary>Auto-suggest rules (click)</summary>\n",
        "- If text contains *fruit* ‚Üí `Preference:Fruit`\n",
        "- *carrot* ‚Üí `Preference:Carrot` and `Texture:Crisp` if *crunchy* present\n",
        "- *grass* ‚Üí `Preference:Grass`\n",
        "- *crunchy|crisp* ‚Üí `Texture:Crisp`\n",
        "- *sweet* ‚Üí `Taste:Sweet`\n",
        "- *expensive|access|hard to find|cost* ‚Üí `Barrier:Access`\n",
        "- *friend|family|herd|group* ‚Üí `Context:Social`\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rules",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re",
        "def suggest_codes(text:str):",
        "    t = text.lower()",
        "    codes = []",
        "    if 'fruit' in t: codes.append('Preference:Fruit')",
        "    if 'carrot' in t: codes.append('Preference:Carrot')",
        "    if 'grass' in t: codes.append('Preference:Grass')",
        "    if re.search(r'crunchy|crisp', t): codes.append('Texture:Crisp')",
        "    if 'sweet' in t: codes.append('Taste:Sweet')",
        "    if re.search(r'expensive|access|hard to find|cost', t): codes.append('Barrier:Access')",
        "    if re.search(r'friend|family|herd|group', t): codes.append('Context:Social')",
        "    return sorted(set(codes))",
        "",
        "df['codes'] = df['text'].apply(suggest_codes)",
        "df[['response_id','text','codes']].head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edit_save",
      "metadata": {},
      "source": [
        "### ‚úçÔ∏è Manual editing\n",
        "Export to CSV, edit in Sheets/Excel (add/remove codes, add `theme` column if you like), re-import to continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export_edit",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('qual_coded_autosuggest.csv', index=False)",
        "print('Wrote qual_coded_autosuggest.csv ‚Äî edit if desired and re-load.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "freqs",
      "metadata": {},
      "source": [
        "## üìä Code frequencies & co-occurrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "freqs_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import combinations",
        "",
        "def explode_codes(df):",
        "    dd = df[['response_id','codes']].explode('codes').dropna()",
        "    return dd",
        "",
        "exploded = explode_codes(df)",
        "freq = exploded['codes'].value_counts().rename_axis('code').reset_index(name='count')",
        "display(freq.head(10))",
        "",
        "# Co-occurrence matrix",
        "pairs = []",
        "for _, row in df.iterrows():",
        "    cs = sorted(set(row['codes']))",
        "    for a,b in combinations(cs, 2):",
        "        pairs.append((a,b))",
        "co = pd.DataFrame(pairs, columns=['code_a','code_b']).value_counts().reset_index(name='n')",
        "co.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "co_heat",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build symmetric matrix for heatmap",
        "codes = sorted(freq['code'].tolist())",
        "mat = pd.DataFrame(0, index=codes, columns=codes, dtype=int)",
        "for _, r in co.iterrows():",
        "    mat.loc[r['code_a'], r['code_b']] += r['n']",
        "    mat.loc[r['code_b'], r['code_a']] += r['n']",
        "plt.figure(figsize=(7,6))",
        "sns.heatmap(mat, annot=False, cmap='Blues')",
        "plt.title('Code co-occurrence'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "network",
      "metadata": {},
      "source": [
        "### üï∏Ô∏è Optional: co-occurrence network\n",
        "Edges weighted by co-occurrence counts (thicker = stronger)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "network_plot",
      "metadata": {},
      "outputs": [],
      "source": [
        "G = nx.Graph()",
        "for c in codes: G.add_node(c, size=int(freq[freq['code']==c]['count']))",
        "for _, r in co.iterrows():",
        "    G.add_edge(r['code_a'], r['code_b'], weight=int(r['n']))",
        "pos = nx.spring_layout(G, seed=2)",
        "plt.figure(figsize=(7,6))",
        "nx.draw_networkx_nodes(G, pos, node_size=[G.nodes[n]['size']*200 for n in G.nodes])",
        "nx.draw_networkx_edges(G, pos, width=[G.edges[e]['weight'] for e in G.edges])",
        "nx.draw_networkx_labels(G, pos, font_size=9)",
        "plt.title('Code co-occurrence network')",
        "plt.axis('off'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reliability",
      "metadata": {},
      "source": [
        "## ü§ù Inter-coder reliability (Cohen‚Äôs Œ∫)\n",
        "For a **subset** of responses, two coders independently assign a **single dominant code**. We‚Äôll demo Œ∫; use it judiciously (it fits some designs better than others‚Äîe.g., structured codebooks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kappa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate coder labels for a subset (replace with your real labels) ",
        "subset = df.sample(min(30, len(df)), random_state=1).copy()",
        "",
        "def dominant_code(codes_list):",
        "    return codes_list[0] if isinstance(codes_list, list) and len(codes_list)>0 else 'None'",
        "",
        "# Coder A uses first auto-suggest; coder B mimics with noise",
        "subset['coderA'] = subset['codes'].apply(dominant_code)",
        "np.random.seed(1)",
        "def jitter(label):",
        "    if np.random.rand()<0.15: return 'None'",
        "    return label",
        "subset['coderB'] = subset['coderA'].apply(jitter)",
        "",
        "kappa = cohen_kappa_score(subset['coderA'], subset['coderB'])",
        "print('Cohen\\'s Œ∫ (demo):', round(kappa, 3))",
        "subset[['response_id','text','coderA','coderB']].head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "themes",
      "metadata": {},
      "source": [
        "## üß© Codes ‚Üí Themes\n",
        "Group codes into broader **themes**. Keep a table mapping to justify boundaries. This is where you *explain* patterns with excerpt evidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "map_themes",
      "metadata": {},
      "outputs": [],
      "source": [
        "theme_map = {\n",
        "  'Preference:Fruit': 'Taste & Freshness',\n",
        "  'Preference:Carrot': 'Taste & Freshness',\n",
        "  'Preference:Grass': 'Habit & Staple Foods',\n",
        "  'Texture:Crisp': 'Sensory Qualities',\n",
        "  'Taste:Sweet': 'Sensory Qualities',\n",
        "  'Barrier:Access': 'Access & Environment',\n",
        "  'Context:Social': 'Social Influence'\n",
        "}\n",
        "",
        "exploded = df[['response_id','text','codes']].explode('codes').dropna()",
        "exploded['theme'] = exploded['codes'].map(theme_map).fillna('Other')",
        "theme_counts = exploded.groupby('theme')['response_id'].nunique().sort_values(ascending=False).reset_index(name='n_responses')",
        "display(theme_counts)",
        "",
        "plt.figure(figsize=(7,4))",
        "sns.barplot(data=theme_counts, x='n_responses', y='theme')",
        "plt.title('Theme coverage (responses with ‚â•1 code in theme)')",
        "plt.xlabel('Responses'); plt.ylabel('Theme'); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "export",
      "metadata": {},
      "source": [
        "## üì§ Export thematic summary pack\n",
        "- `qual_coded_autosuggest.csv` (or your edited file) ‚Äî coded excerpts\n",
        "- `codebook.csv` ‚Äî code labels/definitions\n",
        "- `theme_counts.csv` ‚Äî quick coverage table\n",
        "\n",
        "Use these to write your results with **excerpts** that illustrate each theme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export_pack",
      "metadata": {},
      "outputs": [],
      "source": [
        "codebook.to_csv('codebook.csv', index=False)",
        "theme_counts.to_csv('theme_counts.csv', index=False)",
        "print('Wrote codebook.csv and theme_counts.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## üß© Exercises\n",
        "1) **Refine the codebook**: add 1‚Äì2 exclusion rules per code; add 1 more code.\n",
        "2) **Dual coding**: have a second coder label 20 responses; compute Œ∫ on *your* dominant codes.\n",
        "3) **Theme memo**: write 3‚Äì5 lines defining each theme + 1 illustrative quote (anonymised)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## ‚úÖ Conclusion\n",
        "You built a transparent qualitative pipeline: codebook ‚Üí coding ‚Üí co-occurrence ‚Üí reliability (optional) ‚Üí themes. This supports credible, well-documented qualitative findings that complement your quantitative work.\n",
        "\n",
        "<details><summary>Further reading</summary>\n",
        "- Coding manuals and reflexive thematic analysis guides\n",
        "- Reporting standards for qualitative research\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3.9"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

