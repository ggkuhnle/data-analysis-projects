{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "frontmatter",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Logistic Regression and Survival Analysis\"\n",
        "output-file: \"04_logistic_and_survival.html\"\n",
        "format: html\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# ðŸ“Š 4.6 Logistic Regression and Survival Analysis\n",
        "\n",
        "Classical tools for **binary outcomes** and **time-to-event** questions. Weâ€™ll model the probability of improvement with logistic regression and the time to improvement with survival methods.\n",
        "\n",
        "## ðŸŽ¯ Objectives\n",
        "- Fit, evaluate, and interpret **logistic regression** (with odds ratios + CIs)\n",
        "- Add **interaction** terms and **regularisation**\n",
        "- Plot **ROC**, **PR**, **calibration**; compute confusion matrix and classification report\n",
        "- Estimate **Kaplanâ€“Meier** curves; run the **log-rank** test\n",
        "- Fit a **Cox proportional hazards** model and check PH assumptions\n",
        "\n",
        "<details><summary>Fun fact</summary>\n",
        "Hippos donâ€™t do RCTs, but their vitamin D data powers our models ðŸ¦›\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colab_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for Google Colab: Fetch datasets automatically or manually\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "MODULE = '04_data_analysis'\n",
        "DATASET = 'vitamin_trial.csv'\n",
        "BASE_PATH = '/content/data-analysis-projects'\n",
        "MODULE_PATH = os.path.join(BASE_PATH, 'notebooks', MODULE)\n",
        "DATASET_PATH = os.path.join('data', DATASET)\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        !git clone https://github.com/ggkuhnle/data-analysis-projects.git\n",
        "    os.chdir(MODULE_PATH)\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f'Dataset found: {DATASET_PATH} ðŸ¦›')\n",
        "    else:\n",
        "        raise FileNotFoundError('Dataset missing after clone.')\n",
        "except Exception as e:\n",
        "    print(f'Cloning failed: {e}')\n",
        "    print('Falling back to manual upload ...')\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "    if DATASET in uploaded:\n",
        "        with open(DATASET_PATH, 'wb') as f:\n",
        "            f.write(uploaded[DATASET])\n",
        "        print(f'Successfully uploaded {DATASET} ðŸ¦›')\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Upload failed. Please upload {DATASET}.')\n",
        "\n",
        "%pip install -q pandas numpy scikit-learn lifelines matplotlib seaborn statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, roc_curve,\n",
        "                             precision_recall_curve, confusion_matrix, classification_report,\n",
        "                             brier_score_loss)\n",
        "from sklearn.calibration import calibration_curve\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
        "from lifelines.statistics import logrank_test\n",
        "\n",
        "sns.set_theme()\n",
        "pd.set_option('display.max_columns', 50)\n",
        "print('Environment ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {},
      "source": [
        "## ðŸ“¥ Data Preparation\n",
        "\n",
        "`vitamin_trial.csv` columns (simulated):\n",
        "- `ID`: participant\n",
        "- `Group`: Control / Treatment\n",
        "- `Vitamin_D`: serum vitamin D level (units as per dataset)\n",
        "- `Time`: time to outcome (months)\n",
        "- `Outcome`: Normal / Improved\n",
        "\n",
        "Weâ€™ll create:\n",
        "- `Improved` = 1 if Outcome==\"Improved\", else 0\n",
        "- Train/test split (70/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_df",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/vitamin_trial.csv')\n",
        "df['Improved'] = (df['Outcome'] == 'Improved').astype(int)\n",
        "print('Shape:', df.shape)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "logistic_basics",
      "metadata": {},
      "source": [
        "## 1) Logistic Regression â€” Baseline\n",
        "\n",
        "Weâ€™ll predict `Improved` from `Vitamin_D` and `Group`. Start with a simple, interpretable model and evaluate on a **test** set.\n",
        "\n",
        "<details><summary>Why not only accuracy?</summary>\n",
        "Class imbalance and thresholding can make accuracy misleading. We report **ROC-AUC**, **PR-AUC**, and show calibration.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "logistic_train_test",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Design matrix\n",
        "X = pd.get_dummies(df[['Vitamin_D','Group']], drop_first=True)\n",
        "y = df['Improved']\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)  # with_mean=False keeps sparse-compatible; safe here too\n",
        "X_trs = scaler.fit_transform(X_tr)\n",
        "X_tes = scaler.transform(X_te)\n",
        "\n", 
        "clf = LogisticRegression(max_iter=200, solver='lbfgs')\n",
        "clf.fit(X_trs, y_tr)\n",
        "\n",
        "pred_prob = clf.predict_proba(X_tes)[:,1]\n",
        "pred_lbl = (pred_prob >= 0.5).astype(int)\n",
        "\n",
        "roc_auc = roc_auc_score(y_te, pred_prob)\n",
        "pr_auc = average_precision_score(y_te, pred_prob)\n",
        "cm = confusion_matrix(y_te, pred_lbl)\n",
        "\n",
        "print('ROC-AUC:', round(roc_auc,3), '| PR-AUC:', round(pr_auc,3))\n",
        "print('\\nConfusion matrix (@0.5):\\n', cm)\n",
        "print('\\nClassification report:\\n', classification_report(y_te, pred_lbl))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "curves",
      "metadata": {},
      "source": [
        "### Curves: ROC, Precisionâ€“Recall, Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot_curves",
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_te, pred_prob)\n",
        "prec, rec, _ = precision_recall_curve(y_te, pred_prob)\n",
        "prob_true, prob_pred = calibration_curve(y_te, pred_prob, n_bins=10)\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(15,4))\n",
        "ax[0].plot(fpr, tpr); ax[0].plot([0,1],[0,1],'--')\n",
        "ax[0].set_title('ROC'); ax[0].set_xlabel('FPR'); ax[0].set_ylabel('TPR')\n",
        "ax[1].plot(rec, prec)\n",
        "ax[1].set_title('Precisionâ€“Recall'); ax[1].set_xlabel('Recall'); ax[1].set_ylabel('Precision')\n",
        "ax[2].plot(prob_pred, prob_true, marker='o'); ax[2].plot([0,1],[0,1],'--')\n",
        "ax[2].set_title('Calibration'); ax[2].set_xlabel('Pred prob'); ax[2].set_ylabel('Observed freq')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "print('Brier score (lower is better):', round(brier_score_loss(y_te, pred_prob), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "or_ci",
      "metadata": {},
      "source": [
        "## 2) Odds Ratios (+ 95% CI) with `statsmodels`\n",
        "\n",
        "Scikit-learn is great for prediction; `statsmodels` gives easy **ORs**, **CIs**, and **p-values** for interpretation. We also include an **interaction** term: `Vitamin_D Ã— Group_Treatment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statsmodels_logit",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sm = df.copy()\n",
        "df_sm = pd.get_dummies(df_sm, columns=['Group'], drop_first=True)\n",
        "formula = 'Improved ~ Vitamin_D + Group_Treatment + Vitamin_D:Group_Treatment'\n",
        "logit = smf.logit(formula, data=df_sm).fit(disp=False)\n",
        "print(logit.summary())\n",
        "\n",
        "params = logit.params\n",
        "conf = logit.conf_int()\n",
        "or_tbl = pd.DataFrame({\n",
        "    'OR': np.exp(params),\n",
        "    'low': np.exp(conf[0]),\n",
        "    'high': np.exp(conf[1])\n",
        "})\n",
        "display(or_tbl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regularised",
      "metadata": {},
      "source": [
        "## 3) Regularised Logistic (cross-validated)\n",
        "\n",
        "Regularisation (penalty) controls overfitting and helps when predictors are correlated. Below we tune `C` via internal CV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "logitcv",
      "metadata": {},
      "outputs": [],
      "source": [
        "logit_cv = LogisticRegressionCV(\n",
        "    Cs=10, cv=5, scoring='roc_auc', max_iter=500, solver='lbfgs')\n",
        "logit_cv.fit(X_trs, y_tr)\n",
        "pp = logit_cv.predict_proba(X_tes)[:,1]\n",
        "print('CV-logistic ROC-AUC (test):', round(roc_auc_score(y_te, pp),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "survival_km",
      "metadata": {},
      "source": [
        "## 4) Kaplanâ€“Meier Survival Curves + Log-Rank Test\n",
        "\n",
        "We consider **event = improvement**. Survival here means *not yet improved*. We compare Control vs Treatment with **log-rank**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "km_logrank",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Event'] = (df['Outcome'] == 'Improved').astype(int)\n",
        "km = KaplanMeierFitter()\n",
        "plt.figure(figsize=(7,5))\n",
        "for g in ['Control','Treatment']:\n",
        "    mask = df['Group']==g\n",
        "    km.fit(durations=df.loc[mask,'Time'], event_observed=df.loc[mask,'Event'], label=g)\n",
        "    km.plot_survival_function()\n",
        "plt.title('Kaplanâ€“Meier: Time to Improvement')\n",
        "plt.xlabel('Time (months)'); plt.ylabel('Survival (not improved)')\n",
        "plt.grid(True, alpha=.3); plt.show()\n",
        "\n",
        "lr = logrank_test(\n",
        "    df.loc[df['Group']=='Control','Time'],\n",
        "    df.loc[df['Group']=='Treatment','Time'],\n",
        "    event_observed_A=df.loc[df['Group']=='Control','Event'],\n",
        "    event_observed_B=df.loc[df['Group']=='Treatment','Event']\n",
        ")\n",
        "print('Log-rank p-value:', lr.p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cox",
      "metadata": {},
      "source": [
        "## 5) Cox Proportional Hazards Model\n",
        "\n",
        "CoxPH estimates **hazard ratios** (HR). HR > 1 means faster time to improvement (higher hazard). We include `Vitamin_D` and `Group`.\n",
        "\n",
        "<details><summary>Assumption</summary>\n",
        "The **proportional hazards (PH)** assumption: hazard ratios are constant over time. Weâ€™ll run basic checks.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cox_fit",
      "metadata": {},
      "outputs": [],
      "source": [
        "cox_df = df[['Time','Event','Vitamin_D','Group']].copy()\n",
        "cox_df = pd.get_dummies(cox_df, columns=['Group'], drop_first=True)\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(cox_df, duration_col='Time', event_col='Event')\n",
        "cph.print_summary()  # HR, CI, p\n",
        "\n",
        "# PH assumption checks (prints warnings/tables; may raise plots if available)\n",
        "try:\n",
        "    cph.check_assumptions(cox_df, p_value_threshold=0.05, show_plots=False)\n",
        "except Exception as e:\n",
        "    print('PH check note:', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises",
      "metadata": {},
      "source": [
        "## ðŸ§ª Exercises\n",
        "1) **Threshold tuning**: Choose a decision threshold that maximises F1 (or Youdenâ€™s J) on the validation set; recompute the confusion matrix.\n",
        "2) **Extended model**: Add an interaction to the **Cox** model (`Vitamin_D Ã— Group_Treatment`) and interpret the HR.\n",
        "3) **Calibration**: Use quantile bins (e.g., deciles) to compare predicted vs observed improvement rates; comment on miscalibration.\n",
        "4) **Sensitivity analysis**: Refit logistic with `StandardScaler(with_mean=True)` on dense features (drop one-hot first) and compare coefficients and AUC.\n",
        "\n",
        "<details><summary>Hints</summary>\n",
        "- For 1): grid thresholds from 0.1 to 0.9 and pick argmax of F1.\n",
        "- For 2): add `Vitamin_D:Group_Treatment` column in `cox_df` before fitting.\n",
        "- For 3): `pd.qcut(pred_prob, 10)` then groupby to get observed means.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrap",
      "metadata": {},
      "source": [
        "## âœ… Conclusion\n",
        "You built interpretable classifiers (logistic with ORs and CIs), assessed predictive performance (ROC/PR/calibration), and analysed time-to-event outcomes (KM/log-rank/Cox with PH checks).\n",
        "\n",
        "ðŸ‘‰ Next: **4.7 Clinical Trial Analysis** â€” put everything together for effect sizes and reporting.\n",
        "\n",
        "<details><summary>More reading</summary>\n",
        "- Scikit-learn: Classification metrics & calibration\n",
        "- statsmodels: Logit / GLM binomial\n",
        "- lifelines: Kaplanâ€“Meier, CoxPH, log-rank tests\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

